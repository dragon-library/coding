<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutorials on Library</title>
    <link>https://dragon-library.github.io/coding/tutorials/</link>
    <description>Recent content in Tutorials on Library</description>
    <generator>Source Themes academia (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    
	    <atom:link href="https://dragon-library.github.io/coding/tutorials/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Python Data Science Handbook</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/intro/_index/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/intro/_index/</guid>
      <description>

&lt;p&gt;&lt;em&gt;Jake VanderPlas&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../PDSH-cover.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This is the Jupyter notebook version of the &lt;a href=&#34;http://shop.oreilly.com/product/0636920034919.do&#34; target=&#34;_blank&#34;&gt;Python Data Science Handbook&lt;/a&gt; by Jake VanderPlas; the content is available &lt;a href=&#34;https://github.com/jakevdp/PythonDataScienceHandbook&#34; target=&#34;_blank&#34;&gt;on GitHub&lt;/a&gt;.*
The text is released under the &lt;a href=&#34;https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode&#34; target=&#34;_blank&#34;&gt;CC-BY-NC-ND license&lt;/a&gt;, and code is released under the &lt;a href=&#34;https://opensource.org/licenses/MIT&#34; target=&#34;_blank&#34;&gt;MIT license&lt;/a&gt;. If you find this content useful, please consider supporting the work by &lt;a href=&#34;http://shop.oreilly.com/product/0636920034919.do&#34; target=&#34;_blank&#34;&gt;buying the book&lt;/a&gt;!&lt;/p&gt;

&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h2&gt;

&lt;h3 id=&#34;preface-00-00-preface-ipynb&#34;&gt;&lt;a href=&#34;00.00-Preface.ipynb&#34; target=&#34;_blank&#34;&gt;Preface&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&#34;1-ipython-beyond-normal-python-01-00-ipython-beyond-normal-python-ipynb&#34;&gt;&lt;a href=&#34;01.00-IPython-Beyond-Normal-Python.ipynb&#34; target=&#34;_blank&#34;&gt;1. IPython: Beyond Normal Python&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;01.01-Help-And-Documentation.ipynb&#34; target=&#34;_blank&#34;&gt;Help and Documentation in IPython&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;01.02-Shell-Keyboard-Shortcuts.ipynb&#34; target=&#34;_blank&#34;&gt;Keyboard Shortcuts in the IPython Shell&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;01.03-Magic-Commands.ipynb&#34; target=&#34;_blank&#34;&gt;IPython Magic Commands&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;01.04-Input-Output-History.ipynb&#34; target=&#34;_blank&#34;&gt;Input and Output History&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;01.05-IPython-And-Shell-Commands.ipynb&#34; target=&#34;_blank&#34;&gt;IPython and Shell Commands&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;01.06-Errors-and-Debugging.ipynb&#34; target=&#34;_blank&#34;&gt;Errors and Debugging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;01.07-Timing-and-Profiling.ipynb&#34; target=&#34;_blank&#34;&gt;Profiling and Timing Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;01.08-More-IPython-Resources.ipynb&#34; target=&#34;_blank&#34;&gt;More IPython Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;2-introduction-to-numpy-02-00-introduction-to-numpy-ipynb&#34;&gt;&lt;a href=&#34;02.00-Introduction-to-NumPy.ipynb&#34; target=&#34;_blank&#34;&gt;2. Introduction to NumPy&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;02.01-Understanding-Data-Types.ipynb&#34; target=&#34;_blank&#34;&gt;Understanding Data Types in Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;02.02-The-Basics-Of-NumPy-Arrays.ipynb&#34; target=&#34;_blank&#34;&gt;The Basics of NumPy Arrays&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;02.03-Computation-on-arrays-ufuncs.ipynb&#34; target=&#34;_blank&#34;&gt;Computation on NumPy Arrays: Universal Functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;02.04-Computation-on-arrays-aggregates.ipynb&#34; target=&#34;_blank&#34;&gt;Aggregations: Min, Max, and Everything In Between&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;02.05-Computation-on-arrays-broadcasting.ipynb&#34; target=&#34;_blank&#34;&gt;Computation on Arrays: Broadcasting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;02.06-Boolean-Arrays-and-Masks.ipynb&#34; target=&#34;_blank&#34;&gt;Comparisons, Masks, and Boolean Logic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;02.07-Fancy-Indexing.ipynb&#34; target=&#34;_blank&#34;&gt;Fancy Indexing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;02.08-Sorting.ipynb&#34; target=&#34;_blank&#34;&gt;Sorting Arrays&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;02.09-Structured-Data-NumPy.ipynb&#34; target=&#34;_blank&#34;&gt;Structured Data: NumPy&amp;rsquo;s Structured Arrays&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;3-data-manipulation-with-pandas-03-00-introduction-to-pandas-ipynb&#34;&gt;&lt;a href=&#34;03.00-Introduction-to-Pandas.ipynb&#34; target=&#34;_blank&#34;&gt;3. Data Manipulation with Pandas&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;03.01-Introducing-Pandas-Objects.ipynb&#34; target=&#34;_blank&#34;&gt;Introducing Pandas Objects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;03.02-Data-Indexing-and-Selection.ipynb&#34; target=&#34;_blank&#34;&gt;Data Indexing and Selection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;03.03-Operations-in-Pandas.ipynb&#34; target=&#34;_blank&#34;&gt;Operating on Data in Pandas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;03.04-Missing-Values.ipynb&#34; target=&#34;_blank&#34;&gt;Handling Missing Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;03.05-Hierarchical-Indexing.ipynb&#34; target=&#34;_blank&#34;&gt;Hierarchical Indexing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;03.06-Concat-And-Append.ipynb&#34; target=&#34;_blank&#34;&gt;Combining Datasets: Concat and Append&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;03.07-Merge-and-Join.ipynb&#34; target=&#34;_blank&#34;&gt;Combining Datasets: Merge and Join&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;03.08-Aggregation-and-Grouping.ipynb&#34; target=&#34;_blank&#34;&gt;Aggregation and Grouping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;03.09-Pivot-Tables.ipynb&#34; target=&#34;_blank&#34;&gt;Pivot Tables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;03.10-Working-With-Strings.ipynb&#34; target=&#34;_blank&#34;&gt;Vectorized String Operations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;03.11-Working-with-Time-Series.ipynb&#34; target=&#34;_blank&#34;&gt;Working with Time Series&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;03.12-Performance-Eval-and-Query.ipynb&#34; target=&#34;_blank&#34;&gt;High-Performance Pandas: eval() and query()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;03.13-Further-Resources.ipynb&#34; target=&#34;_blank&#34;&gt;Further Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;4-visualization-with-matplotlib-04-00-introduction-to-matplotlib-ipynb&#34;&gt;&lt;a href=&#34;04.00-Introduction-To-Matplotlib.ipynb&#34; target=&#34;_blank&#34;&gt;4. Visualization with Matplotlib&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;04.01-Simple-Line-Plots.ipynb&#34; target=&#34;_blank&#34;&gt;Simple Line Plots&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;04.02-Simple-Scatter-Plots.ipynb&#34; target=&#34;_blank&#34;&gt;Simple Scatter Plots&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;04.03-Errorbars.ipynb&#34; target=&#34;_blank&#34;&gt;Visualizing Errors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;04.04-Density-and-Contour-Plots.ipynb&#34; target=&#34;_blank&#34;&gt;Density and Contour Plots&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;04.05-Histograms-and-Binnings.ipynb&#34; target=&#34;_blank&#34;&gt;Histograms, Binnings, and Density&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;04.06-Customizing-Legends.ipynb&#34; target=&#34;_blank&#34;&gt;Customizing Plot Legends&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;04.07-Customizing-Colorbars.ipynb&#34; target=&#34;_blank&#34;&gt;Customizing Colorbars&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;04.08-Multiple-Subplots.ipynb&#34; target=&#34;_blank&#34;&gt;Multiple Subplots&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;04.09-Text-and-Annotation.ipynb&#34; target=&#34;_blank&#34;&gt;Text and Annotation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;04.10-Customizing-Ticks.ipynb&#34; target=&#34;_blank&#34;&gt;Customizing Ticks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;04.11-Settings-and-Stylesheets.ipynb&#34; target=&#34;_blank&#34;&gt;Customizing Matplotlib: Configurations and Stylesheets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;04.12-Three-Dimensional-Plotting.ipynb&#34; target=&#34;_blank&#34;&gt;Three-Dimensional Plotting in Matplotlib&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;04.13-Geographic-Data-With-Basemap.ipynb&#34; target=&#34;_blank&#34;&gt;Geographic Data with Basemap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;04.14-Visualization-With-Seaborn.ipynb&#34; target=&#34;_blank&#34;&gt;Visualization with Seaborn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;04.15-Further-Resources.ipynb&#34; target=&#34;_blank&#34;&gt;Further Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;5-machine-learning-05-00-machine-learning-ipynb&#34;&gt;&lt;a href=&#34;05.00-Machine-Learning.ipynb&#34; target=&#34;_blank&#34;&gt;5. Machine Learning&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;05.01-What-Is-Machine-Learning.ipynb&#34; target=&#34;_blank&#34;&gt;What Is Machine Learning?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;05.02-Introducing-Scikit-Learn.ipynb&#34; target=&#34;_blank&#34;&gt;Introducing Scikit-Learn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;05.03-Hyperparameters-and-Model-Validation.ipynb&#34; target=&#34;_blank&#34;&gt;Hyperparameters and Model Validation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;05.04-Feature-Engineering.ipynb&#34; target=&#34;_blank&#34;&gt;Feature Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;05.05-Naive-Bayes.ipynb&#34; target=&#34;_blank&#34;&gt;In Depth: Naive Bayes Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;05.06-Linear-Regression.ipynb&#34; target=&#34;_blank&#34;&gt;In Depth: Linear Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;05.07-Support-Vector-Machines.ipynb&#34; target=&#34;_blank&#34;&gt;In-Depth: Support Vector Machines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;05.08-Random-Forests.ipynb&#34; target=&#34;_blank&#34;&gt;In-Depth: Decision Trees and Random Forests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;05.09-Principal-Component-Analysis.ipynb&#34; target=&#34;_blank&#34;&gt;In Depth: Principal Component Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;05.10-Manifold-Learning.ipynb&#34; target=&#34;_blank&#34;&gt;In-Depth: Manifold Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;05.11-K-Means.ipynb&#34; target=&#34;_blank&#34;&gt;In Depth: k-Means Clustering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;05.12-Gaussian-Mixtures.ipynb&#34; target=&#34;_blank&#34;&gt;In Depth: Gaussian Mixture Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;05.13-Kernel-Density-Estimation.ipynb&#34; target=&#34;_blank&#34;&gt;In-Depth: Kernel Density Estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;05.14-Image-Features.ipynb&#34; target=&#34;_blank&#34;&gt;Application: A Face Detection Pipeline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;05.15-Learning-More.ipynb&#34; target=&#34;_blank&#34;&gt;Further Machine Learning Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;appendix-figure-code-06-00-figure-code-ipynb&#34;&gt;&lt;a href=&#34;06.00-Figure-Code.ipynb&#34; target=&#34;_blank&#34;&gt;Appendix: Figure Code&lt;/a&gt;&lt;/h3&gt;
</description>
    </item>
    
    <item>
      <title>Pandas Tutorials</title>
      <link>https://dragon-library.github.io/coding/tutorials/quickguide/</link>
      <pubDate>Wed, 17 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/quickguide/</guid>
      <description>

&lt;h2 id=&#34;environment-setup&#34;&gt;Environment Setup&lt;/h2&gt;

&lt;p&gt;Standard Python distribution doesn&amp;rsquo;t come bundled with Pandas module. A lightweight alternative is to install NumPy using popular Python package installer,  &lt;strong&gt;pip.&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;pip install pandas
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you install Anaconda Python package, Pandas will be installed by default with the following −&lt;/p&gt;

&lt;h2 id=&#34;windows&#34;&gt;Windows&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Anaconda&lt;/strong&gt;  (from  &lt;a href=&#34;https://www.continuum.io/&#34; target=&#34;_blank&#34;&gt;https://www.continuum.io&lt;/a&gt;) is a free Python distribution for SciPy stack. It is also available for Linux and Mac.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Canopy&lt;/strong&gt;  (&lt;a href=&#34;https://www.enthought.com/products/canopy&#34; target=&#34;_blank&#34;&gt;https://www.enthought.com/products/canopy/&lt;/a&gt;) is available as free as well as commercial distribution with full SciPy stack for Windows, Linux and Mac.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Python&lt;/strong&gt;  (x,y) is a free Python distribution with SciPy stack and Spyder IDE for Windows OS. (Downloadable from  &lt;a href=&#34;http://python-xy.github.io/&#34; target=&#34;_blank&#34;&gt;http://python-xy.github.io/&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;linux&#34;&gt;Linux&lt;/h2&gt;

&lt;p&gt;Package managers of respective Linux distributions are used to install one or more packages in SciPy stack.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For Ubuntu Users&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;sudo apt-get install python-numpy python-scipy python-matplotlibipythonipythonnotebook
python-pandas python-sympy python-nose
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;For Fedora Users&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;sudo yum install numpyscipy python-matplotlibipython python-pandas sympy
python-nose atlas-devel
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;dataframe&#34;&gt;DataFrame&lt;/h2&gt;

&lt;p&gt;A Data frame is a two-dimensional data structure, i.e., data is aligned in a tabular fashion in rows and columns.&lt;/p&gt;

&lt;h3 id=&#34;features-of-dataframe&#34;&gt;Features of DataFrame&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Potentially columns are of different types&lt;/li&gt;
&lt;li&gt;Size – Mutable&lt;/li&gt;
&lt;li&gt;Labeled axes (rows and columns)&lt;/li&gt;
&lt;li&gt;Can Perform Arithmetic operations on rows and columns&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;structure&#34;&gt;Structure&lt;/h3&gt;

&lt;p&gt;Let us assume that we are creating a data frame with student’s data.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.tutorialspoint.com/python_pandas/images/structure_table.jpg&#34; alt=&#34;Structure Table&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can think of it as an SQL table or a spreadsheet data representation.&lt;/p&gt;

&lt;h2 id=&#34;pandas-dataframe&#34;&gt;pandas.DataFrame&lt;/h2&gt;

&lt;p&gt;A pandas DataFrame can be created using the following constructor −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;pandas.DataFrame( data, index, columns, dtype, copy)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The parameters of the constructor are as follows −&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Sr.No&lt;/th&gt;
&lt;th&gt;Parameter &amp;amp; Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;data&lt;/strong&gt; data takes various forms like ndarray, series, map, lists, dict, constants and also another DataFrame.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;index&lt;/strong&gt; For the row labels, the Index to be used for the resulting frame is Optional Default np.arange(n) if no index is passed.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;columns&lt;/strong&gt;  For column labels, the optional default syntax is - np.arange(n). This is only true if no index is passed.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;dtype&lt;/strong&gt;  Data type of each column.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;copy&lt;/strong&gt;  This command (or whatever it is) is used for copying of data, if the default is False.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;create-dataframe&#34;&gt;Create DataFrame&lt;/h2&gt;

&lt;p&gt;A pandas DataFrame can be created using various inputs like −&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Lists&lt;/li&gt;
&lt;li&gt;dict&lt;/li&gt;
&lt;li&gt;Series&lt;/li&gt;
&lt;li&gt;Numpy ndarrays&lt;/li&gt;
&lt;li&gt;Another DataFrame&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the subsequent sections of this chapter, we will see how to create a DataFrame using these inputs.&lt;/p&gt;

&lt;h2 id=&#34;create-an-empty-dataframe&#34;&gt;Create an Empty DataFrame&lt;/h2&gt;

&lt;p&gt;A basic DataFrame, which can be created is an Empty Dataframe.&lt;/p&gt;

&lt;h3 id=&#34;example&#34;&gt;Example&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;#import the pandas library and aliasing as pd  import pandas as pd
df = pd.DataFrame()  print df
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;Empty DataFrame
Columns: []
Index: []
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;create-a-dataframe-from-lists&#34;&gt;Create a DataFrame from Lists&lt;/h2&gt;

&lt;p&gt;The DataFrame can be created using a single list or a list of lists.&lt;/p&gt;

&lt;h3 id=&#34;example-1&#34;&gt;Example 1&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import pandas as pd
data =  [1,2,3,4,5] 
df = pd.DataFrame(data)  
print df
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;     0
0    1
1    2
2    3
3    4
4    5
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;example-2&#34;&gt;Example 2&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import pandas as pd
data =  [[&#39;Alex&#39;,10],[&#39;Bob&#39;,12],[&#39;Clarke&#39;,13]] 
df = pd.DataFrame(data,columns=[&#39;Name&#39;,&#39;Age&#39;])  
print (df)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;      Name      Age
0     Alex      10
1     Bob       12
2     Clarke    13
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;example-3&#34;&gt;Example 3&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import pandas as pd
data =  [[&#39;Alex&#39;,10],[&#39;Bob&#39;,12],[&#39;Clarke&#39;,13]] 
df = pd.DataFrame(data,columns=[&#39;Name&#39;,&#39;Age&#39;],dtype=float)  
print (df)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;      Name     Age
0     Alex     10.0
1     Bob      12.0
2     Clarke   13.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;*Note**  − Observe, the  &lt;strong&gt;dtype&lt;/strong&gt;  parameter changes the type of Age column to floating point.&lt;/p&gt;

&lt;h2 id=&#34;create-a-dataframe-from-dict-of-ndarrays-lists&#34;&gt;Create a DataFrame from Dict of ndarrays / Lists&lt;/h2&gt;

&lt;p&gt;All the  &lt;strong&gt;ndarrays&lt;/strong&gt;  must be of same length. If index is passed, then the length of the index should equal to the length of the arrays.&lt;/p&gt;

&lt;p&gt;If no index is passed, then by default, index will be range(n), where  &lt;strong&gt;n&lt;/strong&gt;  is the array length.&lt;/p&gt;

&lt;h3 id=&#34;example-1-1&#34;&gt;Example 1&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import pandas as pd
data =  {&#39;Name&#39;:[&#39;Tom&#39;,  &#39;Jack&#39;,  &#39;Steve&#39;,  
&#39;Ricky&#39;],&#39;Age&#39;:[28,34,29,42]} 
df = pd.DataFrame(data)  
print (df)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;      Age      Name
0     28        Tom
1     34       Jack
2     29      Steve
3     42      Ricky
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;  − Observe the values 0,1,2,3. They are the default index assigned to each using the function range(n).&lt;/p&gt;

&lt;h3 id=&#34;example-2-1&#34;&gt;Example 2&lt;/h3&gt;

&lt;p&gt;Let us now create an indexed DataFrame using arrays.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import pandas as pd
data =  {&#39;Name&#39;:[&#39;Tom&#39;,  &#39;Jack&#39;,  &#39;Steve&#39;,  &#39;Ricky&#39;],&#39;Age&#39;:[28,34,29,42]} 
df = pd.DataFrame(data, 
index=[&#39;rank1&#39;,&#39;rank2&#39;,&#39;rank3&#39;,&#39;rank4&#39;])  
print df
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;         Age    Name
rank1    28      Tom
rank2    34     Jack
rank3    29    Steve
rank4    42    Ricky
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;  − Observe, the  &lt;strong&gt;index&lt;/strong&gt;  parameter assigns an index to each row.&lt;/p&gt;

&lt;h2 id=&#34;create-a-dataframe-from-list-of-dicts&#34;&gt;Create a DataFrame from List of Dicts&lt;/h2&gt;

&lt;p&gt;List of Dictionaries can be passed as input data to create a DataFrame. The dictionary keys are by default taken as column names.&lt;/p&gt;

&lt;h3 id=&#34;example-1-2&#34;&gt;Example 1&lt;/h3&gt;

&lt;p&gt;The following example shows how to create a DataFrame by passing a list of dictionaries.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import pandas as pd
data =  [{&#39;a&#39;:  1,  &#39;b&#39;:  2},{&#39;a&#39;:  5,  &#39;b&#39;:  10,  &#39;c&#39;:  20}] 
df = pd.DataFrame(data)  
print df
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;    a    b      c
0   1   2     NaN
1   5   10   20.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;  − Observe, NaN (Not a Number) is appended in missing areas.&lt;/p&gt;

&lt;h3 id=&#34;example-2-2&#34;&gt;Example 2&lt;/h3&gt;

&lt;p&gt;The following example shows how to create a DataFrame by passing a list of dictionaries and the row indices.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import pandas as pd
data =  [{&#39;a&#39;:  1,  &#39;b&#39;:  2},{&#39;a&#39;:  5,  &#39;b&#39;:  10,  &#39;c&#39;:  20}] 
df = pd.DataFrame(data, index=[&#39;first&#39;,  &#39;second&#39;])  
print df
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;        a   b       c
first   1   2     NaN
second  5   10   20.0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;example-3-1&#34;&gt;Example 3&lt;/h3&gt;

&lt;p&gt;The following example shows how to create a DataFrame with a list of dictionaries, row indices, and column indices.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import pandas as pd
data =  [{&#39;a&#39;:  1,  &#39;b&#39;:  2},{&#39;a&#39;:  5,  &#39;b&#39;:  10,  &#39;c&#39;:  20}]  
#With two column indices, values same as dictionary keys 
df1 = pd.DataFrame(data, 
index=[&#39;first&#39;,  &#39;second&#39;], columns=[&#39;a&#39;,  &#39;b&#39;])  #With two column indices with one index with other name 
df2 = pd.DataFrame(data, 
index=[&#39;first&#39;,  &#39;second&#39;], columns=[&#39;a&#39;,  &#39;b1&#39;]) 
print df1 
print df2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;#df1 output
         a  b
first    1  2
second   5  10

#df2 output
         a  b1
first    1  NaN
second   5  NaN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;  − Observe, df2 DataFrame is created with a column index other than the dictionary key; thus, appended the NaN’s in place. Whereas, df1 is created with column indices same as dictionary keys, so NaN’s appended.&lt;/p&gt;

&lt;h2 id=&#34;create-a-dataframe-from-dict-of-series&#34;&gt;Create a DataFrame from Dict of Series&lt;/h2&gt;

&lt;p&gt;Dictionary of Series can be passed to form a DataFrame. The resultant index is the union of all the series indexes passed.&lt;/p&gt;

&lt;h3 id=&#34;example-1-3&#34;&gt;Example&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import pandas as pd

d =  {&#39;one&#39;  : pd.Series([1,  2,  3], 
index=[&#39;a&#39;,  &#39;b&#39;,  &#39;c&#39;]),  &#39;two&#39;  : pd.Series([1,  2,  3,  4], 
index=[&#39;a&#39;,  &#39;b&#39;,  &#39;c&#39;,  &#39;d&#39;])} 
df = pd.DataFrame(d)  
print df
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;      one    two
a     1.0    1
b     2.0    2
c     3.0    3
d     NaN    4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;  − Observe, for the series one, there is no label  &lt;strong&gt;‘d’&lt;/strong&gt;  passed, but in the result, for the  &lt;strong&gt;d&lt;/strong&gt;  label, NaN is appended with NaN.&lt;/p&gt;

&lt;p&gt;Let us now understand  &lt;strong&gt;column selection, addition&lt;/strong&gt;, and  &lt;strong&gt;deletion&lt;/strong&gt;  through examples.&lt;/p&gt;

&lt;h2 id=&#34;column-selection&#34;&gt;Column Selection&lt;/h2&gt;

&lt;p&gt;We will understand this by selecting a column from the DataFrame.&lt;/p&gt;

&lt;h3 id=&#34;example-1-4&#34;&gt;Example&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;
import pandas as pd

d =  {&#39;one&#39;  : pd.Series([1,  2,  3], 
index=[&#39;a&#39;,  &#39;b&#39;,  &#39;c&#39;]),  &#39;two&#39;  : pd.Series([1,  2,  3,  4], 
index=[&#39;a&#39;,  &#39;b&#39;,  &#39;c&#39;,  &#39;d&#39;])} 
df = pd.DataFrame(d)  
print df [&#39;one&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;a     1.0
b     2.0
c     3.0
d     NaN
Name: one, dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;column-addition&#34;&gt;Column Addition&lt;/h2&gt;

&lt;p&gt;We will understand this by adding a new column to an existing data frame.&lt;/p&gt;

&lt;h3 id=&#34;example-1-5&#34;&gt;Example&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import pandas as pd

d =  {&#39;one&#39;  : pd.Series([1,  2,  3], 
index=[&#39;a&#39;,  &#39;b&#39;,  &#39;c&#39;]),  
&#39;two&#39;  : pd.Series([1,  2,  3,  4], 
index=[&#39;a&#39;,  &#39;b&#39;,  &#39;c&#39;,  &#39;d&#39;])} 
df = pd.DataFrame(d)  # Adding a new column to an existing DataFrame object with column label by passing new series  
print  (&amp;quot;Adding a new column by passing as Series:&amp;quot;) df[&#39;three&#39;]=pd.Series([10,20,30],index=[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;])  
print df 
print (&amp;quot;Adding a new column using the existing columns in DataFrame:&amp;quot;) 
df[&#39;four&#39;]=df[&#39;one&#39;]+df[&#39;three&#39;] 
print df
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;Adding a new column by passing as Series:
     one   two   three
a    1.0    1    10.0
b    2.0    2    20.0
c    3.0    3    30.0
d    NaN    4    NaN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Adding a new column using the existing columns in DataFrame:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;      one   two   three    four
a     1.0    1    10.0     11.0
b     2.0    2    20.0     22.0
c     3.0    3    30.0     33.0
d     NaN    4     NaN     NaN
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;column-deletion&#34;&gt;Column Deletion&lt;/h2&gt;

&lt;p&gt;Columns can be deleted or popped; let us take an example to understand how.&lt;/p&gt;

&lt;h3 id=&#34;example-1-6&#34;&gt;Example&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;# Using the previous DataFrame, we will delete a column  
# using del function  
import pandas as pd

d =  {&#39;one&#39;  : pd.Series([1,  2,  3], 
index=[&#39;a&#39;,  &#39;b&#39;,  &#39;c&#39;]),  &#39;two&#39;  : pd.Series([1,  2,  3,  4], 
index=[&#39;a&#39;,  &#39;b&#39;,  &#39;c&#39;,  &#39;d&#39;]),  &#39;three&#39;  : pd.Series([10,20,30], 
index=[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;])} 
df = pd.DataFrame(d)  
print  (&amp;quot;Our dataframe is:&amp;quot;)  
print df # using del function  print  (&amp;quot;Deleting the first column using DEL function:&amp;quot;)  
del df[&#39;one&#39;]  
print df # using pop function  
print  (&amp;quot;Deleting another column using POP function:&amp;quot;) df.pop(&#39;two&#39;)  
print df
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;p&gt;Our dataframe is:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;      one   three  two
a     1.0    10.0   1
b     2.0    20.0   2
c     3.0    30.0   3
d     NaN     NaN   4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Deleting the first column using DEL function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;      three    two
a     10.0     1
b     20.0     2
c     30.0     3
d     NaN      4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Deleting another column using POP function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;   three
a  10.0
b  20.0
c  30.0
d  NaN
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;row-selection-addition-and-deletion&#34;&gt;Row Selection, Addition, and Deletion&lt;/h2&gt;

&lt;p&gt;We will now understand row selection, addition and deletion through examples. Let us begin with the concept of selection.&lt;/p&gt;

&lt;h3 id=&#34;selection-by-label&#34;&gt;Selection by Label&lt;/h3&gt;

&lt;p&gt;Rows can be selected by passing row label to a  &lt;strong&gt;loc&lt;/strong&gt;  function.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import pandas as pd

d =  {&#39;one&#39;  : pd.Series([1,  2,  3], 
index=[&#39;a&#39;,  &#39;b&#39;,  &#39;c&#39;]),  &#39;two&#39;  : pd.Series([1,  2,  3,  4], 
index=[&#39;a&#39;,  &#39;b&#39;,  &#39;c&#39;,  &#39;d&#39;])} 
df = pd.DataFrame(d)  
print df.loc[&#39;b&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;one 2.0
two 2.0
Name: b, dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The result is a series with labels as column names of the DataFrame. And, the Name of the series is the label with which it is retrieved.&lt;/p&gt;

&lt;h3 id=&#34;selection-by-integer-location&#34;&gt;Selection by integer location&lt;/h3&gt;

&lt;p&gt;Rows can be selected by passing integer location to an  &lt;strong&gt;iloc&lt;/strong&gt;  function.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import pandas as pd

d =  {&#39;one&#39;  : pd.Series([1,  2,  3], 
index=[&#39;a&#39;,  &#39;b&#39;,  &#39;c&#39;]),  &#39;two&#39;  : pd.Series([1,  2,  3,  4], 
index=[&#39;a&#39;,  &#39;b&#39;,  &#39;c&#39;,  &#39;d&#39;])} 
df = pd.DataFrame(d)  
print df.iloc[2]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;one   3.0
two   3.0
Name: c, dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;slice-rows&#34;&gt;Slice Rows&lt;/h3&gt;

&lt;p&gt;Multiple rows can be selected using ‘ : ’ operator.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import pandas as pd

d =  {&#39;one&#39;  : pd.Series([1,  2,  3], 
index=[&#39;a&#39;,  &#39;b&#39;,  &#39;c&#39;]),  &#39;two&#39;  : pd.Series([1,  2,  3,  4], 
index=[&#39;a&#39;,  &#39;b&#39;,  &#39;c&#39;,  &#39;d&#39;])} 
df = pd.DataFrame(d)  
print df[2:4]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;   one  two
c  3.0    3
d  NaN    4
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;addition-of-rows&#34;&gt;Addition of Rows&lt;/h3&gt;

&lt;p&gt;Add new rows to a DataFrame using the  &lt;strong&gt;append&lt;/strong&gt;  function. This function will append the rows at the end.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import pandas as pd

df = pd.DataFrame([[1,  2],  [3,  4]], columns =  [&#39;a&#39;,&#39;b&#39;]) 
df2 = pd.DataFrame([[5,  6],  [7,  8]], columns =  [&#39;a&#39;,&#39;b&#39;]) 
df = df.append(df2)  
print df
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;   a  b
0  1  2
1  3  4
0  5  6
1  7  8
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;deletion-of-rows&#34;&gt;Deletion of Rows&lt;/h3&gt;

&lt;p&gt;Use index label to delete or drop rows from a DataFrame. If label is duplicated, then multiple rows will be dropped.&lt;/p&gt;

&lt;p&gt;If you observe, in the above example, the labels are duplicate. Let us drop a label and will see how many rows will get dropped.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import pandas as pd

df = pd.DataFrame([[1,  2],  [3,  4]], columns =  [&#39;a&#39;,&#39;b&#39;]) 
df2 = pd.DataFrame([[5,  6],  [7,  8]], columns =  [&#39;a&#39;,&#39;b&#39;]) 
df = df.append(df2)  # Drop rows with label 0 
df = df.drop(0)  
print df
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its  &lt;strong&gt;output&lt;/strong&gt;  is as follows −&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;  a b
1 3 4
1 7 8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the above example, two rows were dropped because those two contain the same label 0.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Reference : &lt;a href=&#34;https://www.tutorialspoint.com/python_pandas/python_pandas_dataframe.htm&#34; target=&#34;_blank&#34;&gt;tutorialspoint.com&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Preface</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/intro/00.00-preface/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/intro/00.00-preface/</guid>
      <description>

&lt;h2 id=&#34;what-is-data-science&#34;&gt;What Is Data Science?&lt;/h2&gt;

&lt;p&gt;This is a book about doing data science with Python, which immediately begs the question: what is &lt;em&gt;data science&lt;/em&gt;?
It&amp;rsquo;s a surprisingly hard definition to nail down, especially given how ubiquitous the term has become.
Vocal critics have variously dismissed the term as a superfluous label (after all, what science doesn&amp;rsquo;t involve data?) or a simple buzzword that only exists to salt resumes and catch the eye of overzealous tech recruiters.&lt;/p&gt;

&lt;p&gt;In my mind, these critiques miss something important.
Data science, despite its hype-laden veneer, is perhaps the best label we have for the cross-disciplinary set of skills that are becoming increasingly important in many applications across industry and academia.
This cross-disciplinary piece is key: in my mind, the best extisting definition of data science is illustrated by Drew Conway&amp;rsquo;s Data Science Venn Diagram, first published on his blog in September 2010:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../img/Data_Science_VD.png&#34; alt=&#34;Data Science Venn Diagram&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;small&gt;(Source: &lt;a href=&#34;http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram&#34; target=&#34;_blank&#34;&gt;Drew Conway&lt;/a&gt;. Used by permission.)&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;While some of the intersection labels are a bit tongue-in-cheek, this diagram captures the essence of what I think people mean when they say &amp;laquo;data science&amp;raquo;: it is fundamentally an &lt;em&gt;interdisciplinary&lt;/em&gt; subject.
Data science comprises three distinct and overlapping areas: the skills of a &lt;em&gt;statistician&lt;/em&gt; who knows how to model and summarize datasets (which are growing ever larger); the skills of a &lt;em&gt;computer scientist&lt;/em&gt; who can design and use algorithms to efficiently store, process, and visualize this data; and the *domain expertise*—what we might think of as &amp;laquo;classical&amp;raquo; training in a subject—necessary both to formulate the right questions and to put their answers in context.&lt;/p&gt;

&lt;p&gt;With this in mind, I would encourage you to think of data science not as a new domain of knowledge to learn, but a new set of skills that you can apply within your current area of expertise.
Whether you are reporting election results, forecasting stock returns, optimizing online ad clicks, identifying microorganisms in microscope photos, seeking new classes of astronomical objects, or working with data in any other field, the goal of this book is to give you the ability to ask and answer new questions about your chosen subject area.&lt;/p&gt;

&lt;h2 id=&#34;who-is-this-book-for&#34;&gt;Who Is This Book For?&lt;/h2&gt;

&lt;p&gt;In my teaching both at the University of Washington and at various tech-focused conferences and meetups, one of the most common questions I have heard is this: &amp;laquo;how should I learn Python?&amp;raquo;
The people asking are generally technically minded students, developers, or researchers, often with an already strong background in writing code and using computational and numerical tools.
Most of these folks don&amp;rsquo;t want to learn Python &lt;em&gt;per se&lt;/em&gt;, but want to learn the language with the aim of using it as a tool for data-intensive and computational science.
While a large patchwork of videos, blog posts, and tutorials for this audience is available online, I&amp;rsquo;ve long been frustrated by the lack of a single good answer to this question; that is what inspired this book.&lt;/p&gt;

&lt;p&gt;The book is not meant to be an introduction to Python or to programming in general; I assume the reader has familiarity with the Python language, including defining functions, assigning variables, calling methods of objects, controlling the flow of a program, and other basic tasks.
Instead it is meant to help Python users learn to use Python&amp;rsquo;s data science stack–libraries such as IPython, NumPy, Pandas, Matplotlib, Scikit-Learn, and related tools–to effectively store, manipulate, and gain insight from data.&lt;/p&gt;

&lt;h2 id=&#34;why-python&#34;&gt;Why Python?&lt;/h2&gt;

&lt;p&gt;Python has emerged over the last couple decades as a first-class tool for scientific computing tasks, including the analysis and visualization of large datasets.
This may have come as a surprise to early proponents of the Python language: the language itself was not specifically designed with data analysis or scientific computing in mind.
The usefulness of Python for data science stems primarily from the large and active ecosystem of third-party packages: &lt;em&gt;NumPy&lt;/em&gt; for manipulation of homogeneous array-based data, &lt;em&gt;Pandas&lt;/em&gt; for manipulation of heterogeneous and labeled data, &lt;em&gt;SciPy&lt;/em&gt; for common scientific computing tasks, &lt;em&gt;Matplotlib&lt;/em&gt; for publication-quality visualizations, &lt;em&gt;IPython&lt;/em&gt; for interactive execution and sharing of code, &lt;em&gt;Scikit-Learn&lt;/em&gt; for machine learning, and many more tools that will be mentioned in the following pages.&lt;/p&gt;

&lt;p&gt;If you are looking for a guide to the Python language itself, I would suggest the sister project to this book, &amp;laquo;&lt;a href=&#34;https://github.com/jakevdp/WhirlwindTourOfPython&#34; target=&#34;_blank&#34;&gt;A Whirlwind Tour of the Python Language&lt;/a&gt;&amp;raquo;.
This short report provides a tour of the essential features of the Python language, aimed at data scientists who already are familiar with one or more other programming languages.&lt;/p&gt;

&lt;h3 id=&#34;python-2-vs-python-3&#34;&gt;Python 2 vs Python 3&lt;/h3&gt;

&lt;p&gt;This book uses the syntax of Python 3, which contains language enhancements that are not compatible with the 2.x series of Python.
Though Python 3.0 was first released in 2008, adoption has been relatively slow, particularly in the scientific and web development communities.
This is primarily because it took some time for many of the essential third-party packages and toolkits to be made compatible with the new language internals.
Since early 2014, however, stable releases of the most important tools in the data science ecosystem have been fully compatible with both Python 2 and 3, and so this book will use the newer Python 3 syntax.
However, the vast majority of code snippets in this book will also work without modification in Python 2: in cases where a Py2-incompatible syntax is used, I will make every effort to note it explicitly.&lt;/p&gt;

&lt;h2 id=&#34;outline-of-the-book&#34;&gt;Outline of the Book&lt;/h2&gt;

&lt;p&gt;Each chapter of this book focuses on a particular package or tool that contributes a fundamental piece of the Python Data Sciece story.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;IPython and Jupyter: these packages provide the computational environment in which many Python-using data scientists work.&lt;/li&gt;
&lt;li&gt;NumPy: this library provides the &lt;code&gt;ndarray&lt;/code&gt; for efficient storage and manipulation of dense data arrays in Python.&lt;/li&gt;
&lt;li&gt;Pandas: this library provides the &lt;code&gt;DataFrame&lt;/code&gt; for efficient storage and manipulation of labeled/columnar data in Python.&lt;/li&gt;
&lt;li&gt;Matplotlib: this library provides capabilities for a flexible range of data visualizations in Python.&lt;/li&gt;
&lt;li&gt;Scikit-Learn: this library provides efficient &amp;amp; clean Python implementations of the most important and established machine learning algorithms.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The PyData world is certainly much larger than these five packages, and is growing every day.
With this in mind, I make every attempt through these pages to provide references to other interesting efforts, projects, and packages that are pushing the boundaries of what can be done in Python.
Nevertheless, these five are currently fundamental to much of the work being done in the Python data science space, and I expect they will remain important even as the ecosystem continues growing around them.&lt;/p&gt;

&lt;h2 id=&#34;using-code-examples&#34;&gt;Using Code Examples&lt;/h2&gt;

&lt;p&gt;Supplemental material (code examples, figures, etc.) is available for download at &lt;a href=&#34;http://github.com/jakevdp/PythonDataScienceHandbook/&#34; target=&#34;_blank&#34;&gt;http://github.com/jakevdp/PythonDataScienceHandbook/&lt;/a&gt;. This book is here to help you get your job done. In general, if example code is offered with this book, you may use it in your programs and documentation. You do not need to contact us for permission unless you’re reproducing a significant portion of the code. For example, writing a program that uses several chunks of code from this book does not require permission. Selling or distributing a CD-ROM of examples from O’Reilly books does require permission. Answering a question by citing this book and quoting example code does not require permission. Incorporating a significant amount of example code from this book into your product’s documentation does require permission.&lt;/p&gt;

&lt;p&gt;We appreciate, but do not require, attribution. An attribution usually includes the title, author, publisher, and ISBN. For example:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;The Python Data Science Handbook&lt;/em&gt; by Jake VanderPlas (O’Reilly). Copyright 2016 Jake VanderPlas, 978-1-491-91205-8.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If you feel your use of code examples falls outside fair use or the per‐ mission given above, feel free to contact us at permissions@oreilly.com.&lt;/p&gt;

&lt;h2 id=&#34;installation-considerations&#34;&gt;Installation Considerations&lt;/h2&gt;

&lt;p&gt;Installing Python and the suite of libraries that enable scientific computing is straightforward . This section will outline some of the considerations when setting up your computer.&lt;/p&gt;

&lt;p&gt;Though there are various ways to install Python, the one I would suggest for use in data science is the Anaconda distribution, which works similarly whether you use Windows, Linux, or Mac OS X.
The Anaconda distribution comes in two flavors:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://conda.pydata.org/miniconda.html&#34; target=&#34;_blank&#34;&gt;Miniconda&lt;/a&gt; gives you the Python interpreter itself, along with a command-line tool called &lt;code&gt;conda&lt;/code&gt; which operates as a cross-platform package manager geared toward Python packages, similar in spirit to the apt or yum tools that Linux users might be familiar with.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.continuum.io/downloads&#34; target=&#34;_blank&#34;&gt;Anaconda&lt;/a&gt; includes both Python and conda, and additionally bundles a suite of other pre-installed packages geared toward scientific computing. Because of the size of this bundle, expect the installation to consume several gigabytes of disk space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Any of the packages included with Anaconda can also be installed manually on top of Miniconda; for this reason I suggest starting with Miniconda.&lt;/p&gt;

&lt;p&gt;To get started, download and install the Miniconda package–make sure to choose a version with Python 3–and then install the core packages used in this book:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[~]$ conda install numpy pandas scikit-learn matplotlib seaborn jupyter
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Throughout the text, we will also make use of other more specialized tools in Python&amp;rsquo;s scientific ecosystem; installation is usually as easy as typing &lt;strong&gt;&lt;code&gt;conda install packagename&lt;/code&gt;&lt;/strong&gt;.
For more information on conda, including information about creating and using conda environments (which I would &lt;em&gt;highly&lt;/em&gt; recommend), refer to &lt;a href=&#34;http://conda.pydata.org/docs/&#34; target=&#34;_blank&#34;&gt;conda&amp;rsquo;s online documentation&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>1. IPython - Beyond Normal Python</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/1.ipython/main/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/1.ipython/main/</guid>
      <description>

&lt;p&gt;There are many options for development environments for Python, and I&amp;rsquo;m often asked which one I use in my own work.
My answer sometimes surprises people: my preferred environment is &lt;a href=&#34;http://ipython.org/&#34; target=&#34;_blank&#34;&gt;IPython&lt;/a&gt; plus a text editor (in my case, Emacs or Atom depending on my mood).
IPython (short for &lt;em&gt;Interactive Python&lt;/em&gt;) was started in 2001 by Fernando Perez as an enhanced Python interpreter, and has since grown into a project aiming to provide, in Perez&amp;rsquo;s words, &amp;laquo;Tools for the entire life cycle of research computing.&amp;raquo;
If Python is the engine of our data science task, you might think of IPython as the interactive control panel.&lt;/p&gt;

&lt;p&gt;As well as being a useful interactive interface to Python, IPython also provides a number of useful syntactic additions to the language; we&amp;rsquo;ll cover the most useful of these additions here.
In addition, IPython is closely tied with the &lt;a href=&#34;http://jupyter.org&#34; target=&#34;_blank&#34;&gt;Jupyter project&lt;/a&gt;, which provides a browser-based notebook that is useful for development, collaboration, sharing, and even publication of data science results.
The IPython notebook is actually a special case of the broader Jupyter notebook structure, which encompasses notebooks for Julia, R, and other programming languages.
As an example of the usefulness of the notebook format, look no further than the page you are reading: the entire manuscript for this book was composed as a set of IPython notebooks.&lt;/p&gt;

&lt;p&gt;IPython is about using Python effectively for interactive scientific and data-intensive computing.
This chapter will start by stepping through some of the IPython features that are useful to the practice of data science, focusing especially on the syntax it offers beyond the standard features of Python.
Next, we will go into a bit more depth on some of the more useful &amp;laquo;magic commands&amp;raquo; that can speed-up common tasks in creating and using data science code.
Finally, we will touch on some of the features of the notebook that make it useful in understanding data and sharing results.&lt;/p&gt;

&lt;h2 id=&#34;shell-or-notebook&#34;&gt;Shell or Notebook?&lt;/h2&gt;

&lt;p&gt;There are two primary means of using IPython that we&amp;rsquo;ll discuss in this chapter: the IPython shell and the IPython notebook.
The bulk of the material in this chapter is relevant to both, and the examples will switch between them depending on what is most convenient.
In the few sections that are relevant to just one or the other, we will explicitly state that fact.
Before we start, some words on how to launch the IPython shell and IPython notebook.&lt;/p&gt;

&lt;h3 id=&#34;launching-the-ipython-shell&#34;&gt;Launching the IPython Shell&lt;/h3&gt;

&lt;p&gt;This chapter, like most of this book, is not designed to be absorbed passively.
I recommend that as you read through it, you follow along and experiment with the tools and syntax we cover: the muscle-memory you build through doing this will be far more useful than the simple act of reading about it.
Start by launching the IPython interpreter by typing &lt;strong&gt;&lt;code&gt;ipython&lt;/code&gt;&lt;/strong&gt; on the command-line; alternatively, if you&amp;rsquo;ve installed a distribution like Anaconda or EPD, there may be a launcher specific to your system (we&amp;rsquo;ll discuss this more fully in &lt;a href=&#34;01.01-Help-And-Documentation.ipynb&#34; target=&#34;_blank&#34;&gt;Help and Documentation in IPython&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Once you do this, you should see a prompt like the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;IPython 4.0.1 -- An enhanced Interactive Python.
?         -&amp;gt; Introduction and overview of IPython&#39;s features.
%quickref -&amp;gt; Quick reference.
help      -&amp;gt; Python&#39;s own help system.
object?   -&amp;gt; Details about &#39;object&#39;, use &#39;object??&#39; for extra details.
In [1]:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With that, you&amp;rsquo;re ready to follow along.&lt;/p&gt;

&lt;h3 id=&#34;launching-the-jupyter-notebook&#34;&gt;Launching the Jupyter Notebook&lt;/h3&gt;

&lt;p&gt;The Jupyter notebook is a browser-based graphical interface to the IPython shell, and builds on it a rich set of dynamic display capabilities.
As well as executing Python/IPython statements, the notebook allows the user to include formatted text, static and dynamic visualizations, mathematical equations, JavaScript widgets, and much more.
Furthermore, these documents can be saved in a way that lets other people open them and execute the code on their own systems.&lt;/p&gt;

&lt;p&gt;Though the IPython notebook is viewed and edited through your web browser window, it must connect to a running Python process in order to execute code.
This process (known as a &amp;laquo;kernel&amp;raquo;) can be started by running the following command in your system shell:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ jupyter notebook
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command will launch a local web server that will be visible to your browser.
It immediately spits out a log showing what it is doing; that log will look something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ jupyter notebook
[NotebookApp] Serving notebooks from local directory: /Users/jakevdp/PythonDataScienceHandbook
[NotebookApp] 0 active kernels 
[NotebookApp] The IPython Notebook is running at: http://localhost:8888/
[NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Upon issuing the command, your default browser should automatically open and navigate to the listed local URL;
the exact address will depend on your system.
If the browser does not open automatically, you can open a window and manually open this address (&lt;em&gt;&lt;a href=&#34;http://localhost:8888/&#34; target=&#34;_blank&#34;&gt;http://localhost:8888/&lt;/a&gt;&lt;/em&gt; in this example).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Help and Documentation in IPython</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/1.ipython/01.01-help-and-documentation/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/1.ipython/01.01-help-and-documentation/</guid>
      <description>

&lt;p&gt;If you read no other section in this chapter, read this one: I find the tools discussed here to be the most transformative contributions of IPython to my daily workflow.&lt;/p&gt;

&lt;p&gt;When a technologically-minded person is asked to help a friend, family member, or colleague with a computer problem, most of the time it&amp;rsquo;s less a matter of knowing the answer as much as knowing how to quickly find an unknown answer.
In data science it&amp;rsquo;s the same: searchable web resources such as online documentation, mailing-list threads, and StackOverflow answers contain a wealth of information, even (especially?) if it is a topic you&amp;rsquo;ve found yourself searching before.
Being an effective practitioner of data science is less about memorizing the tool or command you should use for every possible situation, and more about learning to effectively find the information you don&amp;rsquo;t know, whether through a web search engine or another means.&lt;/p&gt;

&lt;p&gt;One of the most useful functions of IPython/Jupyter is to shorten the gap between the user and the type of documentation and search that will help them do their work effectively.
While web searches still play a role in answering complicated questions, an amazing amount of information can be found through IPython alone.
Some examples of the questions IPython can help answer in a few keystrokes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;How do I call this function? What arguments and options does it have?&lt;/li&gt;
&lt;li&gt;What does the source code of this Python object look like?&lt;/li&gt;
&lt;li&gt;What is in this package I imported? What attributes or methods does this object have?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here we&amp;rsquo;ll discuss IPython&amp;rsquo;s tools to quickly access this information, namely the &lt;code&gt;?&lt;/code&gt; character to explore documentation, the &lt;code&gt;??&lt;/code&gt; characters to explore source code, and the Tab key for auto-completion.&lt;/p&gt;

&lt;h2 id=&#34;accessing-documentation-with&#34;&gt;Accessing Documentation with &lt;code&gt;?&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;The Python language and its data science ecosystem is built with the user in mind, and one big part of that is access to documentation.
Every Python object contains the reference to a string, known as a &lt;em&gt;doc string&lt;/em&gt;, which in most cases will contain a concise summary of the object and how to use it.
Python has a built-in &lt;code&gt;help()&lt;/code&gt; function that can access this information and prints the results.
For example, to see the documentation of the built-in &lt;code&gt;len&lt;/code&gt; function, you can do the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;In [1]: help(len)
Help on built-in function len in module builtins:

len(...)
    len(object) -&amp;gt; integer
    
    Return the number of items of a sequence or mapping.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Depending on your interpreter, this information may be displayed as inline text, or in some separate pop-up window.&lt;/p&gt;

&lt;p&gt;Because finding help on an object is so common and useful, IPython introduces the &lt;code&gt;?&lt;/code&gt; character as a shorthand for accessing this documentation and other relevant information:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;In [2]: len?
Type:        builtin_function_or_method
String form: &amp;lt;built-in function len&amp;gt;
Namespace:   Python builtin
Docstring:
len(object) -&amp;gt; integer

Return the number of items of a sequence or mapping.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This notation works for just about anything, including object methods:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;In [3]: L = [1, 2, 3]
In [4]: L.insert?
Type:        builtin_function_or_method
String form: &amp;lt;built-in method insert of list object at 0x1024b8ea8&amp;gt;
Docstring:   L.insert(index, object) -- insert object before index
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or even objects themselves, with the documentation from their type:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;In [5]: L?
Type:        list
String form: [1, 2, 3]
Length:      3
Docstring:
list() -&amp;gt; new empty list
list(iterable) -&amp;gt; new list initialized from iterable&#39;s items
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Importantly, this will even work for functions or other objects you create yourself!
Here we&amp;rsquo;ll define a small function with a docstring:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;In [6]: def square(a):
  ....:     &amp;quot;&amp;quot;&amp;quot;Return the square of a.&amp;quot;&amp;quot;&amp;quot;
  ....:     return a ** 2
  ....:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that to create a docstring for our function, we simply placed a string literal in the first line.
Because doc strings are usually multiple lines, by convention we used Python&amp;rsquo;s triple-quote notation for multi-line strings.&lt;/p&gt;

&lt;p&gt;Now we&amp;rsquo;ll use the &lt;code&gt;?&lt;/code&gt; mark to find this doc string:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;In [7]: square?
Type:        function
String form: &amp;lt;function square at 0x103713cb0&amp;gt;
Definition:  square(a)
Docstring:   Return the square of a.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This quick access to documentation via docstrings is one reason you should get in the habit of always adding such inline documentation to the code you write!&lt;/p&gt;

&lt;h2 id=&#34;accessing-source-code-with&#34;&gt;Accessing Source Code with &lt;code&gt;??&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;Because the Python language is so easily readable, another level of insight can usually be gained by reading the source code of the object you&amp;rsquo;re curious about.
IPython provides a shortcut to the source code with the double question mark (&lt;code&gt;??&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;In [8]: square??
Type:        function
String form: &amp;lt;function square at 0x103713cb0&amp;gt;
Definition:  square(a)
Source:
def square(a):
    &amp;quot;Return the square of a&amp;quot;
    return a ** 2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For simple functions like this, the double question-mark can give quick insight into the under-the-hood details.&lt;/p&gt;

&lt;p&gt;If you play with this much, you&amp;rsquo;ll notice that sometimes the &lt;code&gt;??&lt;/code&gt; suffix doesn&amp;rsquo;t display any source code: this is generally because the object in question is not implemented in Python, but in C or some other compiled extension language.
If this is the case, the &lt;code&gt;??&lt;/code&gt; suffix gives the same output as the &lt;code&gt;?&lt;/code&gt; suffix.
You&amp;rsquo;ll find this particularly with many of Python&amp;rsquo;s built-in objects and types, for example &lt;code&gt;len&lt;/code&gt; from above:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;In [9]: len??
Type:        builtin_function_or_method
String form: &amp;lt;built-in function len&amp;gt;
Namespace:   Python builtin
Docstring:
len(object) -&amp;gt; integer

Return the number of items of a sequence or mapping.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using &lt;code&gt;?&lt;/code&gt; and/or &lt;code&gt;??&lt;/code&gt; gives a powerful and quick interface for finding information about what any Python function or module does.&lt;/p&gt;

&lt;h2 id=&#34;exploring-modules-with-tab-completion&#34;&gt;Exploring Modules with Tab-Completion&lt;/h2&gt;

&lt;p&gt;IPython&amp;rsquo;s other useful interface is the use of the tab key for auto-completion and exploration of the contents of objects, modules, and name-spaces.
In the examples that follow, we&amp;rsquo;ll use &lt;code&gt;&amp;lt;TAB&amp;gt;&lt;/code&gt; to indicate when the Tab key should be pressed.&lt;/p&gt;

&lt;h3 id=&#34;tab-completion-of-object-contents&#34;&gt;Tab-completion of object contents&lt;/h3&gt;

&lt;p&gt;Every Python object has various attributes and methods associated with it.
Like with the &lt;code&gt;help&lt;/code&gt; function discussed before, Python has a built-in &lt;code&gt;dir&lt;/code&gt; function that returns a list of these, but the tab-completion interface is much easier to use in practice.
To see a list of all available attributes of an object, you can type the name of the object followed by a period (&amp;raquo;&lt;code&gt;.&lt;/code&gt;&amp;raquo;) character and the Tab key:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;In [10]: L.&amp;lt;TAB&amp;gt;
L.append   L.copy     L.extend   L.insert   L.remove   L.sort     
L.clear    L.count    L.index    L.pop      L.reverse  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To narrow-down the list, you can type the first character or several characters of the name, and the Tab key will find the matching attributes and methods:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;In [10]: L.c&amp;lt;TAB&amp;gt;
L.clear  L.copy   L.count  

In [10]: L.co&amp;lt;TAB&amp;gt;
L.copy   L.count 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If there is only a single option, pressing the Tab key will complete the line for you.
For example, the following will instantly be replaced with &lt;code&gt;L.count&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;In [10]: L.cou&amp;lt;TAB&amp;gt;

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Though Python has no strictly-enforced distinction between public/external attributes and private/internal attributes, by convention a preceding underscore is used to denote such methods.
For clarity, these private methods and special methods are omitted from the list by default, but it&amp;rsquo;s possible to list them by explicitly typing the underscore:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;In [10]: L._&amp;lt;TAB&amp;gt;
L.__add__           L.__gt__            L.__reduce__
L.__class__         L.__hash__          L.__reduce_ex__
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For brevity, we&amp;rsquo;ve only shown the first couple lines of the output.
Most of these are Python&amp;rsquo;s special double-underscore methods (often nicknamed &amp;laquo;dunder&amp;raquo; methods).&lt;/p&gt;

&lt;h3 id=&#34;tab-completion-when-importing&#34;&gt;Tab completion when importing&lt;/h3&gt;

&lt;p&gt;Tab completion is also useful when importing objects from packages.
Here we&amp;rsquo;ll use it to find all possible imports in the &lt;code&gt;itertools&lt;/code&gt; package that start with &lt;code&gt;co&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;In [10]: from itertools import co&amp;lt;TAB&amp;gt;
combinations                   compress
combinations_with_replacement  count
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Similarly, you can use tab-completion to see which imports are available on your system (this will change depending on which third-party scripts and modules are visible to your Python session):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;In [10]: import &amp;lt;TAB&amp;gt;
Display all 399 possibilities? (y or n)
Crypto              dis                 py_compile
Cython              distutils           pyclbr
...                 ...                 ...
difflib             pwd                 zmq

In [10]: import h&amp;lt;TAB&amp;gt;
hashlib             hmac                http         
heapq               html                husl         
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(Note that for brevity, I did not print here all 399 importable packages and modules on my system.)&lt;/p&gt;

&lt;h3 id=&#34;beyond-tab-completion-wildcard-matching&#34;&gt;Beyond tab completion: wildcard matching&lt;/h3&gt;

&lt;p&gt;Tab completion is useful if you know the first few characters of the object or attribute you&amp;rsquo;re looking for, but is little help if you&amp;rsquo;d like to match characters at the middle or end of the word.
For this use-case, IPython provides a means of wildcard matching for names using the &lt;code&gt;*&lt;/code&gt; character.&lt;/p&gt;

&lt;p&gt;For example, we can use this to list every object in the namespace that ends with &lt;code&gt;Warning&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;In [10]: *Warning?
BytesWarning                  RuntimeWarning
DeprecationWarning            SyntaxWarning
FutureWarning                 UnicodeWarning
ImportWarning                 UserWarning
PendingDeprecationWarning     Warning
ResourceWarning
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice that the &lt;code&gt;*&lt;/code&gt; character matches any string, including the empty string.&lt;/p&gt;

&lt;p&gt;Similarly, suppose we are looking for a string method that contains the word &lt;code&gt;find&lt;/code&gt; somewhere in its name.
We can search for it this way:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;In [10]: str.*find*?
str.find
str.rfind
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I find this type of flexible wildcard search can be very useful for finding a particular command when getting to know a new package or reacquainting myself with a familiar one.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Keyboard Shortcuts in the IPython Shell</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/1.ipython/01.02-shell-keyboard-shortcuts/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/1.ipython/01.02-shell-keyboard-shortcuts/</guid>
      <description>

&lt;p&gt;If you spend any amount of time on the computer, you&amp;rsquo;ve probably found a use for keyboard shortcuts in your workflow.
Most familiar perhaps are the Cmd-C and Cmd-V (or Ctrl-C and Ctrl-V) for copying and pasting in a wide variety of programs and systems.
Power-users tend to go even further: popular text editors like Emacs, Vim, and others provide users an incredible range of operations through intricate combinations of keystrokes.&lt;/p&gt;

&lt;p&gt;The IPython shell doesn&amp;rsquo;t go this far, but does provide a number of keyboard shortcuts for fast navigation while typing commands.
These shortcuts are not in fact provided by IPython itself, but through its dependency on the GNU Readline library: as such, some of the following shortcuts may differ depending on your system configuration.
Also, while some of these shortcuts do work in the browser-based notebook, this section is primarily about shortcuts in the IPython shell.&lt;/p&gt;

&lt;p&gt;Once you get accustomed to these, they can be very useful for quickly performing certain commands without moving your hands from the &amp;laquo;home&amp;raquo; keyboard position.
If you&amp;rsquo;re an Emacs user or if you have experience with Linux-style shells, the following will be very familiar.
We&amp;rsquo;ll group these shortcuts into a few categories: &lt;em&gt;navigation shortcuts&lt;/em&gt;, &lt;em&gt;text entry shortcuts&lt;/em&gt;, &lt;em&gt;command history shortcuts&lt;/em&gt;, and &lt;em&gt;miscellaneous shortcuts&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&#34;navigation-shortcuts&#34;&gt;Navigation shortcuts&lt;/h2&gt;

&lt;p&gt;While the use of the left and right arrow keys to move backward and forward in the line is quite obvious, there are other options that don&amp;rsquo;t require moving your hands from the &amp;laquo;home&amp;raquo; keyboard position:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Keystroke&lt;/th&gt;
&lt;th&gt;Action&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Ctrl-a&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Move cursor to the beginning of the line&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Ctrl-e&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Move cursor to the end of the line&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Ctrl-b&lt;/code&gt; or the left arrow key&lt;/td&gt;
&lt;td&gt;Move cursor back one character&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Ctrl-f&lt;/code&gt; or the right arrow key&lt;/td&gt;
&lt;td&gt;Move cursor forward one character&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;text-entry-shortcuts&#34;&gt;Text Entry Shortcuts&lt;/h2&gt;

&lt;p&gt;While everyone is familiar with using the Backspace key to delete the previous character, reaching for the key often requires some minor finger gymnastics, and it only deletes a single character at a time.
In IPython there are several shortcuts for removing some portion of the text you&amp;rsquo;re typing.
The most immediately useful of these are the commands to delete entire lines of text.
You&amp;rsquo;ll know these have become second-nature if you find yourself using a combination of Ctrl-b and Ctrl-d instead of reaching for Backspace to delete the previous character!&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Keystroke&lt;/th&gt;
&lt;th&gt;Action&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Backspace key&lt;/td&gt;
&lt;td&gt;Delete previous character in line&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Ctrl-d&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Delete next character in line&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Ctrl-k&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Cut text from cursor to end of line&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Ctrl-u&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Cut text from beginning of line to cursor&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Ctrl-y&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Yank (i.e. paste) text that was previously cut&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Ctrl-t&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Transpose (i.e., switch) previous two characters&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;command-history-shortcuts&#34;&gt;Command History Shortcuts&lt;/h2&gt;

&lt;p&gt;Perhaps the most impactful shortcuts discussed here are the ones IPython provides for navigating the command history.
This command history goes beyond your current IPython session: your entire command history is stored in a SQLite database in your IPython profile directory.
The most straightforward way to access these is with the up and down arrow keys to step through the history, but other options exist as well:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Keystroke&lt;/th&gt;
&lt;th&gt;Action&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Ctrl-p&lt;/code&gt; (or the up arrow key)&lt;/td&gt;
&lt;td&gt;Access previous command in history&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Ctrl-n&lt;/code&gt; (or the down arrow key)&lt;/td&gt;
&lt;td&gt;Access next command in history&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Ctrl-r&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Reverse-search through command history&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The reverse-search can be particularly useful.
Recall that in the previous section we defined a function called &lt;code&gt;square&lt;/code&gt;.
Let&amp;rsquo;s reverse-search our Python history from a new IPython shell and find this definition again.
When you press Ctrl-r in the IPython terminal, you&amp;rsquo;ll see the following prompt:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;In [1]:
(reverse-i-search)`&#39;: 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you start typing characters at this prompt, IPython will auto-fill the most recent command, if any, that matches those characters:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;In [1]: 
(reverse-i-search)`sqa&#39;: square??
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At any point, you can add more characters to refine the search, or press Ctrl-r again to search further for another command that matches the query. If you followed along in the previous section, pressing Ctrl-r twice more gives:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;In [1]: 
(reverse-i-search)`sqa&#39;: def square(a):
    &amp;quot;&amp;quot;&amp;quot;Return the square of a&amp;quot;&amp;quot;&amp;quot;
    return a ** 2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once you have found the command you&amp;rsquo;re looking for, press Return and the search will end.
We can then use the retrieved command, and carry-on with our session:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;In [1]: def square(a):
    &amp;quot;&amp;quot;&amp;quot;Return the square of a&amp;quot;&amp;quot;&amp;quot;
    return a ** 2

In [2]: square(2)
Out[2]: 4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that Ctrl-p/Ctrl-n or the up/down arrow keys can also be used to search through history, but only by matching characters at the beginning of the line.
That is, if you type &lt;strong&gt;&lt;code&gt;def&lt;/code&gt;&lt;/strong&gt; and then press Ctrl-p, it would find the most recent command (if any) in your history that begins with the characters &lt;code&gt;def&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;miscellaneous-shortcuts&#34;&gt;Miscellaneous Shortcuts&lt;/h2&gt;

&lt;p&gt;Finally, there are a few miscellaneous shortcuts that don&amp;rsquo;t fit into any of the preceding categories, but are nevertheless useful to know:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Keystroke&lt;/th&gt;
&lt;th&gt;Action&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Ctrl-l&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Clear terminal screen&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Ctrl-c&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Interrupt current Python command&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Ctrl-d&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Exit IPython session&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The Ctrl-c in particular can be useful when you inadvertently start a very long-running job.&lt;/p&gt;

&lt;p&gt;While some of the shortcuts discussed here may seem a bit tedious at first, they quickly become automatic with practice.
Once you develop that muscle memory, I suspect you will even find yourself wishing they were available in other contexts.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>3. Introducing Pandas Objects</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/intro/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/intro/</guid>
      <description>

&lt;p&gt;At the very basic level, Pandas objects can be thought of as enhanced versions of NumPy structured arrays in which the rows and columns are identified with labels rather than simple integer indices.
As we will see during the course of this chapter, Pandas provides a host of useful tools, methods, and functionality on top of the basic data structures, but nearly everything that follows will require an understanding of what these structures are.
Thus, before we go any further, let&amp;rsquo;s introduce these three fundamental Pandas data structures: the &lt;code&gt;Series&lt;/code&gt;, &lt;code&gt;DataFrame&lt;/code&gt;, and &lt;code&gt;Index&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We will start our code sessions with the standard NumPy and Pandas imports:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
import pandas as pd
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;the-pandas-series-object&#34;&gt;The Pandas Series Object&lt;/h2&gt;

&lt;p&gt;A Pandas &lt;code&gt;Series&lt;/code&gt; is a one-dimensional array of indexed data.
It can be created from a list or array as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data = pd.Series([0.25, 0.5, 0.75, 1.0])
data
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    0.25
1    0.50
2    0.75
3    1.00
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As we see in the output, the &lt;code&gt;Series&lt;/code&gt; wraps both a sequence of values and a sequence of indices, which we can access with the &lt;code&gt;values&lt;/code&gt; and &lt;code&gt;index&lt;/code&gt; attributes.
The &lt;code&gt;values&lt;/code&gt; are simply a familiar NumPy array:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.values
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([ 0.25,  0.5 ,  0.75,  1.  ])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;index&lt;/code&gt; is an array-like object of type &lt;code&gt;pd.Index&lt;/code&gt;, which we&amp;rsquo;ll discuss in more detail momentarily.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.index
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;RangeIndex(start=0, stop=4, step=1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Like with a NumPy array, data can be accessed by the associated index via the familiar Python square-bracket notation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data[1]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0.5
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data[1:3]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1    0.50
2    0.75
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As we will see, though, the Pandas &lt;code&gt;Series&lt;/code&gt; is much more general and flexible than the one-dimensional NumPy array that it emulates.&lt;/p&gt;

&lt;h3 id=&#34;series-as-generalized-numpy-array&#34;&gt;&lt;code&gt;Series&lt;/code&gt; as generalized NumPy array&lt;/h3&gt;

&lt;p&gt;From what we&amp;rsquo;ve seen so far, it may look like the &lt;code&gt;Series&lt;/code&gt; object is basically interchangeable with a one-dimensional NumPy array.
The essential difference is the presence of the index: while the Numpy Array has an &lt;em&gt;implicitly defined&lt;/em&gt; integer index used to access the values, the Pandas &lt;code&gt;Series&lt;/code&gt; has an &lt;em&gt;explicitly defined&lt;/em&gt; index associated with the values.&lt;/p&gt;

&lt;p&gt;This explicit index definition gives the &lt;code&gt;Series&lt;/code&gt; object additional capabilities. For example, the index need not be an integer, but can consist of values of any desired type.
For example, if we wish, we can use strings as an index:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data = pd.Series([0.25, 0.5, 0.75, 1.0],
                 index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
data
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;a    0.25
b    0.50
c    0.75
d    1.00
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And the item access works as expected:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data[&#39;b&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0.5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can even use non-contiguous or non-sequential indices:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data = pd.Series([0.25, 0.5, 0.75, 1.0],
                 index=[2, 5, 3, 7])
data
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;2    0.25
5    0.50
3    0.75
7    1.00
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data[5]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0.5
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;series-as-specialized-dictionary&#34;&gt;Series as specialized dictionary&lt;/h3&gt;

&lt;p&gt;In this way, you can think of a Pandas &lt;code&gt;Series&lt;/code&gt; a bit like a specialization of a Python dictionary.
A dictionary is a structure that maps arbitrary keys to a set of arbitrary values, and a &lt;code&gt;Series&lt;/code&gt; is a structure which maps typed keys to a set of typed values.
This typing is important: just as the type-specific compiled code behind a NumPy array makes it more efficient than a Python list for certain operations, the type information of a Pandas &lt;code&gt;Series&lt;/code&gt; makes it much more efficient than Python dictionaries for certain operations.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;Series&lt;/code&gt;-as-dictionary analogy can be made even more clear by constructing a &lt;code&gt;Series&lt;/code&gt; object directly from a Python dictionary:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;population_dict = {&#39;California&#39;: 38332521,
                   &#39;Texas&#39;: 26448193,
                   &#39;New York&#39;: 19651127,
                   &#39;Florida&#39;: 19552860,
                   &#39;Illinois&#39;: 12882135}
population = pd.Series(population_dict)
population
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;California    38332521
Florida       19552860
Illinois      12882135
New York      19651127
Texas         26448193
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By default, a &lt;code&gt;Series&lt;/code&gt; will be created where the index is drawn from the sorted keys.
From here, typical dictionary-style item access can be performed:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;population[&#39;California&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;38332521
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Unlike a dictionary, though, the &lt;code&gt;Series&lt;/code&gt; also supports array-style operations such as slicing:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;population[&#39;California&#39;:&#39;Illinois&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;California    38332521
Florida       19552860
Illinois      12882135
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;ll discuss some of the quirks of Pandas indexing and slicing in &lt;a href=&#34;03.02-Data-Indexing-and-Selection.ipynb&#34; target=&#34;_blank&#34;&gt;Data Indexing and Selection&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;constructing-series-objects&#34;&gt;Constructing Series objects&lt;/h3&gt;

&lt;p&gt;We&amp;rsquo;ve already seen a few ways of constructing a Pandas &lt;code&gt;Series&lt;/code&gt; from scratch; all of them are some version of the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; pd.Series(data, index=index)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where &lt;code&gt;index&lt;/code&gt; is an optional argument, and &lt;code&gt;data&lt;/code&gt; can be one of many entities.&lt;/p&gt;

&lt;p&gt;For example, &lt;code&gt;data&lt;/code&gt; can be a list or NumPy array, in which case &lt;code&gt;index&lt;/code&gt; defaults to an integer sequence:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.Series([2, 4, 6])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    2
1    4
2    6
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;data&lt;/code&gt; can be a scalar, which is repeated to fill the specified index:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.Series(5, index=[100, 200, 300])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;100    5
200    5
300    5
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;data&lt;/code&gt; can be a dictionary, in which &lt;code&gt;index&lt;/code&gt; defaults to the sorted dictionary keys:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.Series({2:&#39;a&#39;, 1:&#39;b&#39;, 3:&#39;c&#39;})
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1    b
2    a
3    c
dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In each case, the index can be explicitly set if a different result is preferred:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.Series({2:&#39;a&#39;, 1:&#39;b&#39;, 3:&#39;c&#39;}, index=[3, 2])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;3    c
2    a
dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice that in this case, the &lt;code&gt;Series&lt;/code&gt; is populated only with the explicitly identified keys.&lt;/p&gt;

&lt;h2 id=&#34;the-pandas-dataframe-object&#34;&gt;The Pandas DataFrame Object&lt;/h2&gt;

&lt;p&gt;The next fundamental structure in Pandas is the &lt;code&gt;DataFrame&lt;/code&gt;.
Like the &lt;code&gt;Series&lt;/code&gt; object discussed in the previous section, the &lt;code&gt;DataFrame&lt;/code&gt; can be thought of either as a generalization of a NumPy array, or as a specialization of a Python dictionary.
We&amp;rsquo;ll now take a look at each of these perspectives.&lt;/p&gt;

&lt;h3 id=&#34;dataframe-as-a-generalized-numpy-array&#34;&gt;DataFrame as a generalized NumPy array&lt;/h3&gt;

&lt;p&gt;If a &lt;code&gt;Series&lt;/code&gt; is an analog of a one-dimensional array with flexible indices, a &lt;code&gt;DataFrame&lt;/code&gt; is an analog of a two-dimensional array with both flexible row indices and flexible column names.
Just as you might think of a two-dimensional array as an ordered sequence of aligned one-dimensional columns, you can think of a &lt;code&gt;DataFrame&lt;/code&gt; as a sequence of aligned &lt;code&gt;Series&lt;/code&gt; objects.
Here, by &amp;laquo;aligned&amp;raquo; we mean that they share the same index.&lt;/p&gt;

&lt;p&gt;To demonstrate this, let&amp;rsquo;s first construct a new &lt;code&gt;Series&lt;/code&gt; listing the area of each of the five states discussed in the previous section:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;area_dict = {&#39;California&#39;: 423967, &#39;Texas&#39;: 695662, &#39;New York&#39;: 141297,
             &#39;Florida&#39;: 170312, &#39;Illinois&#39;: 149995}
area = pd.Series(area_dict)
area
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;California    423967
Florida       170312
Illinois      149995
New York      141297
Texas         695662
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that we have this along with the &lt;code&gt;population&lt;/code&gt; Series from before, we can use a dictionary to construct a single two-dimensional object containing this information:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;states = pd.DataFrame({&#39;population&#39;: population,
                       &#39;area&#39;: area})
states
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;area&lt;/th&gt;
      &lt;th&gt;population&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;California&lt;/th&gt;
      &lt;td&gt;423967&lt;/td&gt;
      &lt;td&gt;38332521&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Florida&lt;/th&gt;
      &lt;td&gt;170312&lt;/td&gt;
      &lt;td&gt;19552860&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Illinois&lt;/th&gt;
      &lt;td&gt;149995&lt;/td&gt;
      &lt;td&gt;12882135&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;New York&lt;/th&gt;
      &lt;td&gt;141297&lt;/td&gt;
      &lt;td&gt;19651127&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Texas&lt;/th&gt;
      &lt;td&gt;695662&lt;/td&gt;
      &lt;td&gt;26448193&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Like the &lt;code&gt;Series&lt;/code&gt; object, the &lt;code&gt;DataFrame&lt;/code&gt; has an &lt;code&gt;index&lt;/code&gt; attribute that gives access to the index labels:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;states.index
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Index([&#39;California&#39;, &#39;Florida&#39;, &#39;Illinois&#39;, &#39;New York&#39;, &#39;Texas&#39;], dtype=&#39;object&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Additionally, the &lt;code&gt;DataFrame&lt;/code&gt; has a &lt;code&gt;columns&lt;/code&gt; attribute, which is an &lt;code&gt;Index&lt;/code&gt; object holding the column labels:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;states.columns
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Index([&#39;area&#39;, &#39;population&#39;], dtype=&#39;object&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Thus the &lt;code&gt;DataFrame&lt;/code&gt; can be thought of as a generalization of a two-dimensional NumPy array, where both the rows and columns have a generalized index for accessing the data.&lt;/p&gt;

&lt;h3 id=&#34;dataframe-as-specialized-dictionary&#34;&gt;DataFrame as specialized dictionary&lt;/h3&gt;

&lt;p&gt;Similarly, we can also think of a &lt;code&gt;DataFrame&lt;/code&gt; as a specialization of a dictionary.
Where a dictionary maps a key to a value, a &lt;code&gt;DataFrame&lt;/code&gt; maps a column name to a &lt;code&gt;Series&lt;/code&gt; of column data.
For example, asking for the &lt;code&gt;&#39;area&#39;&lt;/code&gt; attribute returns the &lt;code&gt;Series&lt;/code&gt; object containing the areas we saw earlier:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;states[&#39;area&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;California    423967
Florida       170312
Illinois      149995
New York      141297
Texas         695662
Name: area, dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice the potential point of confusion here: in a two-dimesnional NumPy array, &lt;code&gt;data[0]&lt;/code&gt; will return the first &lt;em&gt;row&lt;/em&gt;. For a &lt;code&gt;DataFrame&lt;/code&gt;, &lt;code&gt;data[&#39;col0&#39;]&lt;/code&gt; will return the first &lt;em&gt;column&lt;/em&gt;.
Because of this, it is probably better to think about &lt;code&gt;DataFrame&lt;/code&gt;s as generalized dictionaries rather than generalized arrays, though both ways of looking at the situation can be useful.
We&amp;rsquo;ll explore more flexible means of indexing &lt;code&gt;DataFrame&lt;/code&gt;s in &lt;a href=&#34;03.02-Data-Indexing-and-Selection.ipynb&#34; target=&#34;_blank&#34;&gt;Data Indexing and Selection&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;constructing-dataframe-objects&#34;&gt;Constructing DataFrame objects&lt;/h3&gt;

&lt;p&gt;A Pandas &lt;code&gt;DataFrame&lt;/code&gt; can be constructed in a variety of ways.
Here we&amp;rsquo;ll give several examples.&lt;/p&gt;

&lt;h4 id=&#34;from-a-single-series-object&#34;&gt;From a single Series object&lt;/h4&gt;

&lt;p&gt;A &lt;code&gt;DataFrame&lt;/code&gt; is a collection of &lt;code&gt;Series&lt;/code&gt; objects, and a single-column &lt;code&gt;DataFrame&lt;/code&gt; can be constructed from a single &lt;code&gt;Series&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.DataFrame(population, columns=[&#39;population&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;population&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;California&lt;/th&gt;
      &lt;td&gt;38332521&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Florida&lt;/th&gt;
      &lt;td&gt;19552860&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Illinois&lt;/th&gt;
      &lt;td&gt;12882135&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;New York&lt;/th&gt;
      &lt;td&gt;19651127&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Texas&lt;/th&gt;
      &lt;td&gt;26448193&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h4 id=&#34;from-a-list-of-dicts&#34;&gt;From a list of dicts&lt;/h4&gt;

&lt;p&gt;Any list of dictionaries can be made into a &lt;code&gt;DataFrame&lt;/code&gt;.
We&amp;rsquo;ll use a simple list comprehension to create some data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data = [{&#39;a&#39;: i, &#39;b&#39;: 2 * i}
        for i in range(3)]
pd.DataFrame(data)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;a&lt;/th&gt;
      &lt;th&gt;b&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Even if some keys in the dictionary are missing, Pandas will fill them in with &lt;code&gt;NaN&lt;/code&gt; (i.e., &amp;laquo;not a number&amp;raquo;) values:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.DataFrame([{&#39;a&#39;: 1, &#39;b&#39;: 2}, {&#39;b&#39;: 3, &#39;c&#39;: 4}])
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;a&lt;/th&gt;
      &lt;th&gt;b&lt;/th&gt;
      &lt;th&gt;c&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h4 id=&#34;from-a-dictionary-of-series-objects&#34;&gt;From a dictionary of Series objects&lt;/h4&gt;

&lt;p&gt;As we saw before, a &lt;code&gt;DataFrame&lt;/code&gt; can be constructed from a dictionary of &lt;code&gt;Series&lt;/code&gt; objects as well:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.DataFrame({&#39;population&#39;: population,
              &#39;area&#39;: area})
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;area&lt;/th&gt;
      &lt;th&gt;population&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;California&lt;/th&gt;
      &lt;td&gt;423967&lt;/td&gt;
      &lt;td&gt;38332521&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Florida&lt;/th&gt;
      &lt;td&gt;170312&lt;/td&gt;
      &lt;td&gt;19552860&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Illinois&lt;/th&gt;
      &lt;td&gt;149995&lt;/td&gt;
      &lt;td&gt;12882135&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;New York&lt;/th&gt;
      &lt;td&gt;141297&lt;/td&gt;
      &lt;td&gt;19651127&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Texas&lt;/th&gt;
      &lt;td&gt;695662&lt;/td&gt;
      &lt;td&gt;26448193&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h4 id=&#34;from-a-two-dimensional-numpy-array&#34;&gt;From a two-dimensional NumPy array&lt;/h4&gt;

&lt;p&gt;Given a two-dimensional array of data, we can create a &lt;code&gt;DataFrame&lt;/code&gt; with any specified column and index names.
If omitted, an integer index will be used for each:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.DataFrame(np.random.rand(3, 2),
             columns=[&#39;foo&#39;, &#39;bar&#39;],
             index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;foo&lt;/th&gt;
      &lt;th&gt;bar&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;a&lt;/th&gt;
      &lt;td&gt;0.865257&lt;/td&gt;
      &lt;td&gt;0.213169&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;b&lt;/th&gt;
      &lt;td&gt;0.442759&lt;/td&gt;
      &lt;td&gt;0.108267&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;c&lt;/th&gt;
      &lt;td&gt;0.047110&lt;/td&gt;
      &lt;td&gt;0.905718&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h4 id=&#34;from-a-numpy-structured-array&#34;&gt;From a NumPy structured array&lt;/h4&gt;

&lt;p&gt;We covered structured arrays in &lt;a href=&#34;02.09-Structured-Data-NumPy.ipynb&#34; target=&#34;_blank&#34;&gt;Structured Data: NumPy&amp;rsquo;s Structured Arrays&lt;/a&gt;.
A Pandas &lt;code&gt;DataFrame&lt;/code&gt; operates much like a structured array, and can be created directly from one:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;A = np.zeros(3, dtype=[(&#39;A&#39;, &#39;i8&#39;), (&#39;B&#39;, &#39;f8&#39;)])
A
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([(0, 0.0), (0, 0.0), (0, 0.0)], 
      dtype=[(&#39;A&#39;, &#39;&amp;lt;i8&#39;), (&#39;B&#39;, &#39;&amp;lt;f8&#39;)])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.DataFrame(A)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h2 id=&#34;the-pandas-index-object&#34;&gt;The Pandas Index Object&lt;/h2&gt;

&lt;p&gt;We have seen here that both the &lt;code&gt;Series&lt;/code&gt; and &lt;code&gt;DataFrame&lt;/code&gt; objects contain an explicit &lt;em&gt;index&lt;/em&gt; that lets you reference and modify data.
This &lt;code&gt;Index&lt;/code&gt; object is an interesting structure in itself, and it can be thought of either as an &lt;em&gt;immutable array&lt;/em&gt; or as an &lt;em&gt;ordered set&lt;/em&gt; (technically a multi-set, as &lt;code&gt;Index&lt;/code&gt; objects may contain repeated values).
Those views have some interesting consequences in the operations available on &lt;code&gt;Index&lt;/code&gt; objects.
As a simple example, let&amp;rsquo;s construct an &lt;code&gt;Index&lt;/code&gt; from a list of integers:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ind = pd.Index([2, 3, 5, 7, 11])
ind
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Int64Index([2, 3, 5, 7, 11], dtype=&#39;int64&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;index-as-immutable-array&#34;&gt;Index as immutable array&lt;/h3&gt;

&lt;p&gt;The &lt;code&gt;Index&lt;/code&gt; in many ways operates like an array.
For example, we can use standard Python indexing notation to retrieve values or slices:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ind[1]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;3
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ind[::2]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Int64Index([2, 5, 11], dtype=&#39;int64&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;Index&lt;/code&gt; objects also have many of the attributes familiar from NumPy arrays:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(ind.size, ind.shape, ind.ndim, ind.dtype)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;5 (5,) 1 int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;One difference between &lt;code&gt;Index&lt;/code&gt; objects and NumPy arrays is that indices are immutable–that is, they cannot be modified via the normal means:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ind[1] = 0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

&amp;lt;ipython-input-34-40e631c82e8a&amp;gt; in &amp;lt;module&amp;gt;()
----&amp;gt; 1 ind[1] = 0


/Users/jakevdp/anaconda/lib/python3.5/site-packages/pandas/indexes/base.py in __setitem__(self, key, value)
   1243 
   1244     def __setitem__(self, key, value):
-&amp;gt; 1245         raise TypeError(&amp;quot;Index does not support mutable operations&amp;quot;)
   1246 
   1247     def __getitem__(self, key):


TypeError: Index does not support mutable operations
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This immutability makes it safer to share indices between multiple &lt;code&gt;DataFrame&lt;/code&gt;s and arrays, without the potential for side effects from inadvertent index modification.&lt;/p&gt;

&lt;h3 id=&#34;index-as-ordered-set&#34;&gt;Index as ordered set&lt;/h3&gt;

&lt;p&gt;Pandas objects are designed to facilitate operations such as joins across datasets, which depend on many aspects of set arithmetic.
The &lt;code&gt;Index&lt;/code&gt; object follows many of the conventions used by Python&amp;rsquo;s built-in &lt;code&gt;set&lt;/code&gt; data structure, so that unions, intersections, differences, and other combinations can be computed in a familiar way:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;indA = pd.Index([1, 3, 5, 7, 9])
indB = pd.Index([2, 3, 5, 7, 11])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;indA &amp;amp; indB  # intersection
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Int64Index([3, 5, 7], dtype=&#39;int64&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;indA | indB  # union
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Int64Index([1, 2, 3, 5, 7, 9, 11], dtype=&#39;int64&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;indA ^ indB  # symmetric difference
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Int64Index([1, 2, 9, 11], dtype=&#39;int64&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These operations may also be accessed via object methods, for example &lt;code&gt;indA.intersection(indB)&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data Indexing and Selection</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.02-data-indexing-and-selection/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.02-data-indexing-and-selection/</guid>
      <description>

&lt;p&gt;In &lt;a href=&#34;02.00-Introduction-to-NumPy.ipynb&#34; target=&#34;_blank&#34;&gt;Chapter 2&lt;/a&gt;, we looked in detail at methods and tools to access, set, and modify values in NumPy arrays.
These included indexing (e.g., &lt;code&gt;arr[2, 1]&lt;/code&gt;), slicing (e.g., &lt;code&gt;arr[:, 1:5]&lt;/code&gt;), masking (e.g., &lt;code&gt;arr[arr &amp;gt; 0]&lt;/code&gt;), fancy indexing (e.g., &lt;code&gt;arr[0, [1, 5]]&lt;/code&gt;), and combinations thereof (e.g., &lt;code&gt;arr[:, [1, 5]]&lt;/code&gt;).
Here we&amp;rsquo;ll look at similar means of accessing and modifying values in Pandas &lt;code&gt;Series&lt;/code&gt; and &lt;code&gt;DataFrame&lt;/code&gt; objects.
If you have used the NumPy patterns, the corresponding patterns in Pandas will feel very familiar, though there are a few quirks to be aware of.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll start with the simple case of the one-dimensional &lt;code&gt;Series&lt;/code&gt; object, and then move on to the more complicated two-dimesnional &lt;code&gt;DataFrame&lt;/code&gt; object.&lt;/p&gt;

&lt;h2 id=&#34;data-selection-in-series&#34;&gt;Data Selection in Series&lt;/h2&gt;

&lt;p&gt;As we saw in the previous section, a &lt;code&gt;Series&lt;/code&gt; object acts in many ways like a one-dimensional NumPy array, and in many ways like a standard Python dictionary.
If we keep these two overlapping analogies in mind, it will help us to understand the patterns of data indexing and selection in these arrays.&lt;/p&gt;

&lt;h3 id=&#34;series-as-dictionary&#34;&gt;Series as dictionary&lt;/h3&gt;

&lt;p&gt;Like a dictionary, the &lt;code&gt;Series&lt;/code&gt; object provides a mapping from a collection of keys to a collection of values:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
data = pd.Series([0.25, 0.5, 0.75, 1.0],
                 index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
data
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;a    0.25
b    0.50
c    0.75
d    1.00
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data[&#39;b&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0.5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can also use dictionary-like Python expressions and methods to examine the keys/indices and values:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#39;a&#39; in data
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.keys()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Index([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;], dtype=&#39;object&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;list(data.items())
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[(&#39;a&#39;, 0.25), (&#39;b&#39;, 0.5), (&#39;c&#39;, 0.75), (&#39;d&#39;, 1.0)]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;Series&lt;/code&gt; objects can even be modified with a dictionary-like syntax.
Just as you can extend a dictionary by assigning to a new key, you can extend a &lt;code&gt;Series&lt;/code&gt; by assigning to a new index value:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data[&#39;e&#39;] = 1.25
data
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;a    0.25
b    0.50
c    0.75
d    1.00
e    1.25
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This easy mutability of the objects is a convenient feature: under the hood, Pandas is making decisions about memory layout and data copying that might need to take place; the user generally does not need to worry about these issues.&lt;/p&gt;

&lt;h3 id=&#34;series-as-one-dimensional-array&#34;&gt;Series as one-dimensional array&lt;/h3&gt;

&lt;p&gt;A &lt;code&gt;Series&lt;/code&gt; builds on this dictionary-like interface and provides array-style item selection via the same basic mechanisms as NumPy arrays – that is, &lt;em&gt;slices&lt;/em&gt;, &lt;em&gt;masking&lt;/em&gt;, and &lt;em&gt;fancy indexing&lt;/em&gt;.
Examples of these are as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# slicing by explicit index
data[&#39;a&#39;:&#39;c&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;a    0.25
b    0.50
c    0.75
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# slicing by implicit integer index
data[0:2]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;a    0.25
b    0.50
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# masking
data[(data &amp;gt; 0.3) &amp;amp; (data &amp;lt; 0.8)]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;b    0.50
c    0.75
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# fancy indexing
data[[&#39;a&#39;, &#39;e&#39;]]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;a    0.25
e    1.25
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Among these, slicing may be the source of the most confusion.
Notice that when slicing with an explicit index (i.e., &lt;code&gt;data[&#39;a&#39;:&#39;c&#39;]&lt;/code&gt;), the final index is &lt;em&gt;included&lt;/em&gt; in the slice, while when slicing with an implicit index (i.e., &lt;code&gt;data[0:2]&lt;/code&gt;), the final index is &lt;em&gt;excluded&lt;/em&gt; from the slice.&lt;/p&gt;

&lt;h3 id=&#34;indexers-loc-iloc-and-ix&#34;&gt;Indexers: loc, iloc, and ix&lt;/h3&gt;

&lt;p&gt;These slicing and indexing conventions can be a source of confusion.
For example, if your &lt;code&gt;Series&lt;/code&gt; has an explicit integer index, an indexing operation such as &lt;code&gt;data[1]&lt;/code&gt; will use the explicit indices, while a slicing operation like &lt;code&gt;data[1:3]&lt;/code&gt; will use the implicit Python-style index.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data = pd.Series([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], index=[1, 3, 5])
data
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1    a
3    b
5    c
dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# explicit index when indexing
data[1]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&#39;a&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# implicit index when slicing
data[1:3]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;3    b
5    c
dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Because of this potential confusion in the case of integer indexes, Pandas provides some special &lt;em&gt;indexer&lt;/em&gt; attributes that explicitly expose certain indexing schemes.
These are not functional methods, but attributes that expose a particular slicing interface to the data in the &lt;code&gt;Series&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;First, the &lt;code&gt;loc&lt;/code&gt; attribute allows indexing and slicing that always references the explicit index:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.loc[1]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&#39;a&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.loc[1:3]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1    a
3    b
dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;iloc&lt;/code&gt; attribute allows indexing and slicing that always references the implicit Python-style index:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.iloc[1]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&#39;b&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.iloc[1:3]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;3    b
5    c
dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A third indexing attribute, &lt;code&gt;ix&lt;/code&gt;, is a hybrid of the two, and for &lt;code&gt;Series&lt;/code&gt; objects is equivalent to standard &lt;code&gt;[]&lt;/code&gt;-based indexing.
The purpose of the &lt;code&gt;ix&lt;/code&gt; indexer will become more apparent in the context of &lt;code&gt;DataFrame&lt;/code&gt; objects, which we will discuss in a moment.&lt;/p&gt;

&lt;p&gt;One guiding principle of Python code is that &amp;laquo;explicit is better than implicit.&amp;raquo;
The explicit nature of &lt;code&gt;loc&lt;/code&gt; and &lt;code&gt;iloc&lt;/code&gt; make them very useful in maintaining clean and readable code; especially in the case of integer indexes, I recommend using these both to make code easier to read and understand, and to prevent subtle bugs due to the mixed indexing/slicing convention.&lt;/p&gt;

&lt;h2 id=&#34;data-selection-in-dataframe&#34;&gt;Data Selection in DataFrame&lt;/h2&gt;

&lt;p&gt;Recall that a &lt;code&gt;DataFrame&lt;/code&gt; acts in many ways like a two-dimensional or structured array, and in other ways like a dictionary of &lt;code&gt;Series&lt;/code&gt; structures sharing the same index.
These analogies can be helpful to keep in mind as we explore data selection within this structure.&lt;/p&gt;

&lt;h3 id=&#34;dataframe-as-a-dictionary&#34;&gt;DataFrame as a dictionary&lt;/h3&gt;

&lt;p&gt;The first analogy we will consider is the &lt;code&gt;DataFrame&lt;/code&gt; as a dictionary of related &lt;code&gt;Series&lt;/code&gt; objects.
Let&amp;rsquo;s return to our example of areas and populations of states:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;area = pd.Series({&#39;California&#39;: 423967, &#39;Texas&#39;: 695662,
                  &#39;New York&#39;: 141297, &#39;Florida&#39;: 170312,
                  &#39;Illinois&#39;: 149995})
pop = pd.Series({&#39;California&#39;: 38332521, &#39;Texas&#39;: 26448193,
                 &#39;New York&#39;: 19651127, &#39;Florida&#39;: 19552860,
                 &#39;Illinois&#39;: 12882135})
data = pd.DataFrame({&#39;area&#39;:area, &#39;pop&#39;:pop})
data
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;area&lt;/th&gt;
      &lt;th&gt;pop&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;California&lt;/th&gt;
      &lt;td&gt;423967&lt;/td&gt;
      &lt;td&gt;38332521&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Florida&lt;/th&gt;
      &lt;td&gt;170312&lt;/td&gt;
      &lt;td&gt;19552860&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Illinois&lt;/th&gt;
      &lt;td&gt;149995&lt;/td&gt;
      &lt;td&gt;12882135&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;New York&lt;/th&gt;
      &lt;td&gt;141297&lt;/td&gt;
      &lt;td&gt;19651127&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Texas&lt;/th&gt;
      &lt;td&gt;695662&lt;/td&gt;
      &lt;td&gt;26448193&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The individual &lt;code&gt;Series&lt;/code&gt; that make up the columns of the &lt;code&gt;DataFrame&lt;/code&gt; can be accessed via dictionary-style indexing of the column name:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data[&#39;area&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;California    423967
Florida       170312
Illinois      149995
New York      141297
Texas         695662
Name: area, dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Equivalently, we can use attribute-style access with column names that are strings:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.area
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;California    423967
Florida       170312
Illinois      149995
New York      141297
Texas         695662
Name: area, dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This attribute-style column access actually accesses the exact same object as the dictionary-style access:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.area is data[&#39;area&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Though this is a useful shorthand, keep in mind that it does not work for all cases!
For example, if the column names are not strings, or if the column names conflict with methods of the &lt;code&gt;DataFrame&lt;/code&gt;, this attribute-style access is not possible.
For example, the &lt;code&gt;DataFrame&lt;/code&gt; has a &lt;code&gt;pop()&lt;/code&gt; method, so &lt;code&gt;data.pop&lt;/code&gt; will point to this rather than the &lt;code&gt;&amp;quot;pop&amp;quot;&lt;/code&gt; column:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.pop is data[&#39;pop&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;False
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In particular, you should avoid the temptation to try column assignment via attribute (i.e., use &lt;code&gt;data[&#39;pop&#39;] = z&lt;/code&gt; rather than &lt;code&gt;data.pop = z&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;Like with the &lt;code&gt;Series&lt;/code&gt; objects discussed earlier, this dictionary-style syntax can also be used to modify the object, in this case adding a new column:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data[&#39;density&#39;] = data[&#39;pop&#39;] / data[&#39;area&#39;]
data
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;area&lt;/th&gt;
      &lt;th&gt;pop&lt;/th&gt;
      &lt;th&gt;density&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;California&lt;/th&gt;
      &lt;td&gt;423967&lt;/td&gt;
      &lt;td&gt;38332521&lt;/td&gt;
      &lt;td&gt;90.413926&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Florida&lt;/th&gt;
      &lt;td&gt;170312&lt;/td&gt;
      &lt;td&gt;19552860&lt;/td&gt;
      &lt;td&gt;114.806121&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Illinois&lt;/th&gt;
      &lt;td&gt;149995&lt;/td&gt;
      &lt;td&gt;12882135&lt;/td&gt;
      &lt;td&gt;85.883763&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;New York&lt;/th&gt;
      &lt;td&gt;141297&lt;/td&gt;
      &lt;td&gt;19651127&lt;/td&gt;
      &lt;td&gt;139.076746&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Texas&lt;/th&gt;
      &lt;td&gt;695662&lt;/td&gt;
      &lt;td&gt;26448193&lt;/td&gt;
      &lt;td&gt;38.018740&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;This shows a preview of the straightforward syntax of element-by-element arithmetic between &lt;code&gt;Series&lt;/code&gt; objects; we&amp;rsquo;ll dig into this further in &lt;a href=&#34;03.03-Operations-in-Pandas.ipynb&#34; target=&#34;_blank&#34;&gt;Operating on Data in Pandas&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;dataframe-as-two-dimensional-array&#34;&gt;DataFrame as two-dimensional array&lt;/h3&gt;

&lt;p&gt;As mentioned previously, we can also view the &lt;code&gt;DataFrame&lt;/code&gt; as an enhanced two-dimensional array.
We can examine the raw underlying data array using the &lt;code&gt;values&lt;/code&gt; attribute:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.values
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([[  4.23967000e+05,   3.83325210e+07,   9.04139261e+01],
       [  1.70312000e+05,   1.95528600e+07,   1.14806121e+02],
       [  1.49995000e+05,   1.28821350e+07,   8.58837628e+01],
       [  1.41297000e+05,   1.96511270e+07,   1.39076746e+02],
       [  6.95662000e+05,   2.64481930e+07,   3.80187404e+01]])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With this picture in mind, many familiar array-like observations can be done on the &lt;code&gt;DataFrame&lt;/code&gt; itself.
For example, we can transpose the full &lt;code&gt;DataFrame&lt;/code&gt; to swap rows and columns:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.T
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;California&lt;/th&gt;
      &lt;th&gt;Florida&lt;/th&gt;
      &lt;th&gt;Illinois&lt;/th&gt;
      &lt;th&gt;New York&lt;/th&gt;
      &lt;th&gt;Texas&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;area&lt;/th&gt;
      &lt;td&gt;4.239670e+05&lt;/td&gt;
      &lt;td&gt;1.703120e+05&lt;/td&gt;
      &lt;td&gt;1.499950e+05&lt;/td&gt;
      &lt;td&gt;1.412970e+05&lt;/td&gt;
      &lt;td&gt;6.956620e+05&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;pop&lt;/th&gt;
      &lt;td&gt;3.833252e+07&lt;/td&gt;
      &lt;td&gt;1.955286e+07&lt;/td&gt;
      &lt;td&gt;1.288214e+07&lt;/td&gt;
      &lt;td&gt;1.965113e+07&lt;/td&gt;
      &lt;td&gt;2.644819e+07&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;density&lt;/th&gt;
      &lt;td&gt;9.041393e+01&lt;/td&gt;
      &lt;td&gt;1.148061e+02&lt;/td&gt;
      &lt;td&gt;8.588376e+01&lt;/td&gt;
      &lt;td&gt;1.390767e+02&lt;/td&gt;
      &lt;td&gt;3.801874e+01&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;When it comes to indexing of &lt;code&gt;DataFrame&lt;/code&gt; objects, however, it is clear that the dictionary-style indexing of columns precludes our ability to simply treat it as a NumPy array.
In particular, passing a single index to an array accesses a row:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.values[0]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([  4.23967000e+05,   3.83325210e+07,   9.04139261e+01])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and passing a single &amp;laquo;index&amp;raquo; to a &lt;code&gt;DataFrame&lt;/code&gt; accesses a column:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data[&#39;area&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;California    423967
Florida       170312
Illinois      149995
New York      141297
Texas         695662
Name: area, dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Thus for array-style indexing, we need another convention.
Here Pandas again uses the &lt;code&gt;loc&lt;/code&gt;, &lt;code&gt;iloc&lt;/code&gt;, and &lt;code&gt;ix&lt;/code&gt; indexers mentioned earlier.
Using the &lt;code&gt;iloc&lt;/code&gt; indexer, we can index the underlying array as if it is a simple NumPy array (using the implicit Python-style index), but the &lt;code&gt;DataFrame&lt;/code&gt; index and column labels are maintained in the result:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.iloc[:3, :2]
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;area&lt;/th&gt;
      &lt;th&gt;pop&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;California&lt;/th&gt;
      &lt;td&gt;423967&lt;/td&gt;
      &lt;td&gt;38332521&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Florida&lt;/th&gt;
      &lt;td&gt;170312&lt;/td&gt;
      &lt;td&gt;19552860&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Illinois&lt;/th&gt;
      &lt;td&gt;149995&lt;/td&gt;
      &lt;td&gt;12882135&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Similarly, using the &lt;code&gt;loc&lt;/code&gt; indexer we can index the underlying data in an array-like style but using the explicit index and column names:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.loc[:&#39;Illinois&#39;, :&#39;pop&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;area&lt;/th&gt;
      &lt;th&gt;pop&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;California&lt;/th&gt;
      &lt;td&gt;423967&lt;/td&gt;
      &lt;td&gt;38332521&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Florida&lt;/th&gt;
      &lt;td&gt;170312&lt;/td&gt;
      &lt;td&gt;19552860&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Illinois&lt;/th&gt;
      &lt;td&gt;149995&lt;/td&gt;
      &lt;td&gt;12882135&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;ix&lt;/code&gt; indexer allows a hybrid of these two approaches:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.ix[:3, :&#39;pop&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;area&lt;/th&gt;
      &lt;th&gt;pop&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;California&lt;/th&gt;
      &lt;td&gt;423967&lt;/td&gt;
      &lt;td&gt;38332521&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Florida&lt;/th&gt;
      &lt;td&gt;170312&lt;/td&gt;
      &lt;td&gt;19552860&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Illinois&lt;/th&gt;
      &lt;td&gt;149995&lt;/td&gt;
      &lt;td&gt;12882135&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Keep in mind that for integer indices, the &lt;code&gt;ix&lt;/code&gt; indexer is subject to the same potential sources of confusion as discussed for integer-indexed &lt;code&gt;Series&lt;/code&gt; objects.&lt;/p&gt;

&lt;p&gt;Any of the familiar NumPy-style data access patterns can be used within these indexers.
For example, in the &lt;code&gt;loc&lt;/code&gt; indexer we can combine masking and fancy indexing as in the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.loc[data.density &amp;gt; 100, [&#39;pop&#39;, &#39;density&#39;]]
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;pop&lt;/th&gt;
      &lt;th&gt;density&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Florida&lt;/th&gt;
      &lt;td&gt;19552860&lt;/td&gt;
      &lt;td&gt;114.806121&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;New York&lt;/th&gt;
      &lt;td&gt;19651127&lt;/td&gt;
      &lt;td&gt;139.076746&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Any of these indexing conventions may also be used to set or modify values; this is done in the standard way that you might be accustomed to from working with NumPy:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.iloc[0, 2] = 90
data
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;area&lt;/th&gt;
      &lt;th&gt;pop&lt;/th&gt;
      &lt;th&gt;density&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;California&lt;/th&gt;
      &lt;td&gt;423967&lt;/td&gt;
      &lt;td&gt;38332521&lt;/td&gt;
      &lt;td&gt;90.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Florida&lt;/th&gt;
      &lt;td&gt;170312&lt;/td&gt;
      &lt;td&gt;19552860&lt;/td&gt;
      &lt;td&gt;114.806121&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Illinois&lt;/th&gt;
      &lt;td&gt;149995&lt;/td&gt;
      &lt;td&gt;12882135&lt;/td&gt;
      &lt;td&gt;85.883763&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;New York&lt;/th&gt;
      &lt;td&gt;141297&lt;/td&gt;
      &lt;td&gt;19651127&lt;/td&gt;
      &lt;td&gt;139.076746&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Texas&lt;/th&gt;
      &lt;td&gt;695662&lt;/td&gt;
      &lt;td&gt;26448193&lt;/td&gt;
      &lt;td&gt;38.018740&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;To build up your fluency in Pandas data manipulation, I suggest spending some time with a simple &lt;code&gt;DataFrame&lt;/code&gt; and exploring the types of indexing, slicing, masking, and fancy indexing that are allowed by these various indexing approaches.&lt;/p&gt;

&lt;h3 id=&#34;additional-indexing-conventions&#34;&gt;Additional indexing conventions&lt;/h3&gt;

&lt;p&gt;There are a couple extra indexing conventions that might seem at odds with the preceding discussion, but nevertheless can be very useful in practice.
First, while &lt;em&gt;indexing&lt;/em&gt; refers to columns, &lt;em&gt;slicing&lt;/em&gt; refers to rows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data[&#39;Florida&#39;:&#39;Illinois&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;area&lt;/th&gt;
      &lt;th&gt;pop&lt;/th&gt;
      &lt;th&gt;density&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Florida&lt;/th&gt;
      &lt;td&gt;170312&lt;/td&gt;
      &lt;td&gt;19552860&lt;/td&gt;
      &lt;td&gt;114.806121&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Illinois&lt;/th&gt;
      &lt;td&gt;149995&lt;/td&gt;
      &lt;td&gt;12882135&lt;/td&gt;
      &lt;td&gt;85.883763&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Such slices can also refer to rows by number rather than by index:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data[1:3]
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;area&lt;/th&gt;
      &lt;th&gt;pop&lt;/th&gt;
      &lt;th&gt;density&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Florida&lt;/th&gt;
      &lt;td&gt;170312&lt;/td&gt;
      &lt;td&gt;19552860&lt;/td&gt;
      &lt;td&gt;114.806121&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Illinois&lt;/th&gt;
      &lt;td&gt;149995&lt;/td&gt;
      &lt;td&gt;12882135&lt;/td&gt;
      &lt;td&gt;85.883763&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Similarly, direct masking operations are also interpreted row-wise rather than column-wise:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data[data.density &amp;gt; 100]
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;area&lt;/th&gt;
      &lt;th&gt;pop&lt;/th&gt;
      &lt;th&gt;density&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Florida&lt;/th&gt;
      &lt;td&gt;170312&lt;/td&gt;
      &lt;td&gt;19552860&lt;/td&gt;
      &lt;td&gt;114.806121&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;New York&lt;/th&gt;
      &lt;td&gt;141297&lt;/td&gt;
      &lt;td&gt;19651127&lt;/td&gt;
      &lt;td&gt;139.076746&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;These two conventions are syntactically similar to those on a NumPy array, and while these may not precisely fit the mold of the Pandas conventions, they are nevertheless quite useful in practice.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Operating on Data in Pandas</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.03-operations-in-pandas/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.03-operations-in-pandas/</guid>
      <description>

&lt;p&gt;One of the essential pieces of NumPy is the ability to perform quick element-wise operations, both with basic arithmetic (addition, subtraction, multiplication, etc.) and with more sophisticated operations (trigonometric functions, exponential and logarithmic functions, etc.).
Pandas inherits much of this functionality from NumPy, and the ufuncs that we introduced in &lt;a href=&#34;02.03-Computation-on-arrays-ufuncs.ipynb&#34; target=&#34;_blank&#34;&gt;Computation on NumPy Arrays: Universal Functions&lt;/a&gt; are key to this.&lt;/p&gt;

&lt;p&gt;Pandas includes a couple useful twists, however: for unary operations like negation and trigonometric functions, these ufuncs will &lt;em&gt;preserve index and column labels&lt;/em&gt; in the output, and for binary operations such as addition and multiplication, Pandas will automatically &lt;em&gt;align indices&lt;/em&gt; when passing the objects to the ufunc.
This means that keeping the context of data and combining data from different sources–both potentially error-prone tasks with raw NumPy arrays–become essentially foolproof ones with Pandas.
We will additionally see that there are well-defined operations between one-dimensional &lt;code&gt;Series&lt;/code&gt; structures and two-dimensional &lt;code&gt;DataFrame&lt;/code&gt; structures.&lt;/p&gt;

&lt;h2 id=&#34;ufuncs-index-preservation&#34;&gt;Ufuncs: Index Preservation&lt;/h2&gt;

&lt;p&gt;Because Pandas is designed to work with NumPy, any NumPy ufunc will work on Pandas &lt;code&gt;Series&lt;/code&gt; and &lt;code&gt;DataFrame&lt;/code&gt; objects.
Let&amp;rsquo;s start by defining a simple &lt;code&gt;Series&lt;/code&gt; and &lt;code&gt;DataFrame&lt;/code&gt; on which to demonstrate this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
import numpy as np
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;rng = np.random.RandomState(42)
ser = pd.Series(rng.randint(0, 10, 4))
ser
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    6
1    3
2    7
3    4
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df = pd.DataFrame(rng.randint(0, 10, (3, 4)),
                  columns=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;])
df
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;th&gt;D&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;If we apply a NumPy ufunc on either of these objects, the result will be another Pandas object &lt;em&gt;with the indices preserved:&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;np.exp(ser)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0     403.428793
1      20.085537
2    1096.633158
3      54.598150
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or, for a slightly more complex calculation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;np.sin(df * np.pi / 4)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;th&gt;D&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;-1.000000&lt;/td&gt;
      &lt;td&gt;7.071068e-01&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;-1.000000e+00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;-0.707107&lt;/td&gt;
      &lt;td&gt;1.224647e-16&lt;/td&gt;
      &lt;td&gt;0.707107&lt;/td&gt;
      &lt;td&gt;-7.071068e-01&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;-0.707107&lt;/td&gt;
      &lt;td&gt;1.000000e+00&lt;/td&gt;
      &lt;td&gt;-0.707107&lt;/td&gt;
      &lt;td&gt;1.224647e-16&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Any of the ufuncs discussed in &lt;a href=&#34;02.03-Computation-on-arrays-ufuncs.ipynb&#34; target=&#34;_blank&#34;&gt;Computation on NumPy Arrays: Universal Functions&lt;/a&gt; can be used in a similar manner.&lt;/p&gt;

&lt;h2 id=&#34;ufuncs-index-alignment&#34;&gt;UFuncs: Index Alignment&lt;/h2&gt;

&lt;p&gt;For binary operations on two &lt;code&gt;Series&lt;/code&gt; or &lt;code&gt;DataFrame&lt;/code&gt; objects, Pandas will align indices in the process of performing the operation.
This is very convenient when working with incomplete data, as we&amp;rsquo;ll see in some of the examples that follow.&lt;/p&gt;

&lt;h3 id=&#34;index-alignment-in-series&#34;&gt;Index alignment in Series&lt;/h3&gt;

&lt;p&gt;As an example, suppose we are combining two different data sources, and find only the top three US states by &lt;em&gt;area&lt;/em&gt; and the top three US states by &lt;em&gt;population&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;area = pd.Series({&#39;Alaska&#39;: 1723337, &#39;Texas&#39;: 695662,
                  &#39;California&#39;: 423967}, name=&#39;area&#39;)
population = pd.Series({&#39;California&#39;: 38332521, &#39;Texas&#39;: 26448193,
                        &#39;New York&#39;: 19651127}, name=&#39;population&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s see what happens when we divide these to compute the population density:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;population / area
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Alaska              NaN
California    90.413926
New York            NaN
Texas         38.018740
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The resulting array contains the &lt;em&gt;union&lt;/em&gt; of indices of the two input arrays, which could be determined using standard Python set arithmetic on these indices:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;area.index | population.index
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Index([&#39;Alaska&#39;, &#39;California&#39;, &#39;New York&#39;, &#39;Texas&#39;], dtype=&#39;object&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Any item for which one or the other does not have an entry is marked with &lt;code&gt;NaN&lt;/code&gt;, or &amp;laquo;Not a Number,&amp;raquo; which is how Pandas marks missing data (see further discussion of missing data in &lt;a href=&#34;03.04-Missing-Values.ipynb&#34; target=&#34;_blank&#34;&gt;Handling Missing Data&lt;/a&gt;).
This index matching is implemented this way for any of Python&amp;rsquo;s built-in arithmetic expressions; any missing values are filled in with NaN by default:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;A = pd.Series([2, 4, 6], index=[0, 1, 2])
B = pd.Series([1, 3, 5], index=[1, 2, 3])
A + B
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    NaN
1    5.0
2    9.0
3    NaN
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If using NaN values is not the desired behavior, the fill value can be modified using appropriate object methods in place of the operators.
For example, calling &lt;code&gt;A.add(B)&lt;/code&gt; is equivalent to calling &lt;code&gt;A + B&lt;/code&gt;, but allows optional explicit specification of the fill value for any elements in &lt;code&gt;A&lt;/code&gt; or &lt;code&gt;B&lt;/code&gt; that might be missing:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;A.add(B, fill_value=0)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    2.0
1    5.0
2    9.0
3    5.0
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;index-alignment-in-dataframe&#34;&gt;Index alignment in DataFrame&lt;/h3&gt;

&lt;p&gt;A similar type of alignment takes place for &lt;em&gt;both&lt;/em&gt; columns and indices when performing operations on &lt;code&gt;DataFrame&lt;/code&gt;s:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;A = pd.DataFrame(rng.randint(0, 20, (2, 2)),
                 columns=list(&#39;AB&#39;))
A
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;B = pd.DataFrame(rng.randint(0, 10, (3, 3)),
                 columns=list(&#39;BAC&#39;))
B
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;A + B
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;13.0&lt;/td&gt;
      &lt;td&gt;6.0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Notice that indices are aligned correctly irrespective of their order in the two objects, and indices in the result are sorted.
As was the case with &lt;code&gt;Series&lt;/code&gt;, we can use the associated object&amp;rsquo;s arithmetic method and pass any desired &lt;code&gt;fill_value&lt;/code&gt; to be used in place of missing entries.
Here we&amp;rsquo;ll fill with the mean of all values in &lt;code&gt;A&lt;/code&gt; (computed by first stacking the rows of &lt;code&gt;A&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fill = A.stack().mean()
A.add(B, fill_value=fill)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;13.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;13.0&lt;/td&gt;
      &lt;td&gt;6.0&lt;/td&gt;
      &lt;td&gt;4.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;6.5&lt;/td&gt;
      &lt;td&gt;13.5&lt;/td&gt;
      &lt;td&gt;10.5&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The following table lists Python operators and their equivalent Pandas object methods:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Python Operator&lt;/th&gt;
&lt;th&gt;Pandas Method(s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;+&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;add()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;-&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;sub()&lt;/code&gt;, &lt;code&gt;subtract()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;*&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;mul()&lt;/code&gt;, &lt;code&gt;multiply()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;truediv()&lt;/code&gt;, &lt;code&gt;div()&lt;/code&gt;, &lt;code&gt;divide()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;//&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;floordiv()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;%&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;mod()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;**&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;pow()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;ufuncs-operations-between-dataframe-and-series&#34;&gt;Ufuncs: Operations Between DataFrame and Series&lt;/h2&gt;

&lt;p&gt;When performing operations between a &lt;code&gt;DataFrame&lt;/code&gt; and a &lt;code&gt;Series&lt;/code&gt;, the index and column alignment is similarly maintained.
Operations between a &lt;code&gt;DataFrame&lt;/code&gt; and a &lt;code&gt;Series&lt;/code&gt; are similar to operations between a two-dimensional and one-dimensional NumPy array.
Consider one common operation, where we find the difference of a two-dimensional array and one of its rows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;A = rng.randint(10, size=(3, 4))
A
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([[3, 8, 2, 4],
       [2, 6, 4, 8],
       [6, 1, 3, 8]])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;A - A[0]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([[ 0,  0,  0,  0],
       [-1, -2,  2,  4],
       [ 3, -7,  1,  4]])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;According to NumPy&amp;rsquo;s broadcasting rules (see &lt;a href=&#34;02.05-Computation-on-arrays-broadcasting.ipynb&#34; target=&#34;_blank&#34;&gt;Computation on Arrays: Broadcasting&lt;/a&gt;), subtraction between a two-dimensional array and one of its rows is applied row-wise.&lt;/p&gt;

&lt;p&gt;In Pandas, the convention similarly operates row-wise by default:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df = pd.DataFrame(A, columns=list(&#39;QRST&#39;))
df - df.iloc[0]
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Q&lt;/th&gt;
      &lt;th&gt;R&lt;/th&gt;
      &lt;th&gt;S&lt;/th&gt;
      &lt;th&gt;T&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;-1&lt;/td&gt;
      &lt;td&gt;-2&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;-7&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;If you would instead like to operate column-wise, you can use the object methods mentioned earlier, while specifying the &lt;code&gt;axis&lt;/code&gt; keyword:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.subtract(df[&#39;R&#39;], axis=0)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Q&lt;/th&gt;
      &lt;th&gt;R&lt;/th&gt;
      &lt;th&gt;S&lt;/th&gt;
      &lt;th&gt;T&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;-5&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;-6&lt;/td&gt;
      &lt;td&gt;-4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;-4&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;-2&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Note that these &lt;code&gt;DataFrame&lt;/code&gt;/&lt;code&gt;Series&lt;/code&gt; operations, like the operations discussed above, will automatically align  indices between the two elements:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;halfrow = df.iloc[0, ::2]
halfrow
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Q    3
S    2
Name: 0, dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df - halfrow
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Q&lt;/th&gt;
      &lt;th&gt;R&lt;/th&gt;
      &lt;th&gt;S&lt;/th&gt;
      &lt;th&gt;T&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;-1.0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;This preservation and alignment of indices and columns means that operations on data in Pandas will always maintain the data context, which prevents the types of silly errors that might come up when working with heterogeneous and/or misaligned data in raw NumPy arrays.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Handling Missing Data</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.04-missing-values/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.04-missing-values/</guid>
      <description>

&lt;p&gt;The difference between data found in many tutorials and data in the real world is that real-world data is rarely clean and homogeneous.
In particular, many interesting datasets will have some amount of data missing.
To make matters even more complicated, different data sources may indicate missing data in different ways.&lt;/p&gt;

&lt;p&gt;In this section, we will discuss some general considerations for missing data, discuss how Pandas chooses to represent it, and demonstrate some built-in Pandas tools for handling missing data in Python.
Here and throughout the book, we&amp;rsquo;ll refer to missing data in general as &lt;em&gt;null&lt;/em&gt;, &lt;em&gt;NaN&lt;/em&gt;, or &lt;em&gt;NA&lt;/em&gt; values.&lt;/p&gt;

&lt;h2 id=&#34;trade-offs-in-missing-data-conventions&#34;&gt;Trade-Offs in Missing Data Conventions&lt;/h2&gt;

&lt;p&gt;There are a number of schemes that have been developed to indicate the presence of missing data in a table or DataFrame.
Generally, they revolve around one of two strategies: using a &lt;em&gt;mask&lt;/em&gt; that globally indicates missing values, or choosing a &lt;em&gt;sentinel value&lt;/em&gt; that indicates a missing entry.&lt;/p&gt;

&lt;p&gt;In the masking approach, the mask might be an entirely separate Boolean array, or it may involve appropriation of one bit in the data representation to locally indicate the null status of a value.&lt;/p&gt;

&lt;p&gt;In the sentinel approach, the sentinel value could be some data-specific convention, such as indicating a missing integer value with -9999 or some rare bit pattern, or it could be a more global convention, such as indicating a missing floating-point value with NaN (Not a Number), a special value which is part of the IEEE floating-point specification.&lt;/p&gt;

&lt;p&gt;None of these approaches is without trade-offs: use of a separate mask array requires allocation of an additional Boolean array, which adds overhead in both storage and computation. A sentinel value reduces the range of valid values that can be represented, and may require extra (often non-optimized) logic in CPU and GPU arithmetic. Common special values like NaN are not available for all data types.&lt;/p&gt;

&lt;p&gt;As in most cases where no universally optimal choice exists, different languages and systems use different conventions.
For example, the R language uses reserved bit patterns within each data type as sentinel values indicating missing data, while the SciDB system uses an extra byte attached to every cell which indicates a NA state.&lt;/p&gt;

&lt;h2 id=&#34;missing-data-in-pandas&#34;&gt;Missing Data in Pandas&lt;/h2&gt;

&lt;p&gt;The way in which Pandas handles missing values is constrained by its reliance on the NumPy package, which does not have a built-in notion of NA values for non-floating-point data types.&lt;/p&gt;

&lt;p&gt;Pandas could have followed R&amp;rsquo;s lead in specifying bit patterns for each individual data type to indicate nullness, but this approach turns out to be rather unwieldy.
While R contains four basic data types, NumPy supports &lt;em&gt;far&lt;/em&gt; more than this: for example, while R has a single integer type, NumPy supports &lt;em&gt;fourteen&lt;/em&gt; basic integer types once you account for available precisions, signedness, and endianness of the encoding.
Reserving a specific bit pattern in all available NumPy types would lead to an unwieldy amount of overhead in special-casing various operations for various types, likely even requiring a new fork of the NumPy package. Further, for the smaller data types (such as 8-bit integers), sacrificing a bit to use as a mask will significantly reduce the range of values it can represent.&lt;/p&gt;

&lt;p&gt;NumPy does have support for masked arrays – that is, arrays that have a separate Boolean mask array attached for marking data as &amp;laquo;good&amp;raquo; or &amp;laquo;bad.&amp;raquo;
Pandas could have derived from this, but the overhead in both storage, computation, and code maintenance makes that an unattractive choice.&lt;/p&gt;

&lt;p&gt;With these constraints in mind, Pandas chose to use sentinels for missing data, and further chose to use two already-existing Python null values: the special floating-point &lt;code&gt;NaN&lt;/code&gt; value, and the Python &lt;code&gt;None&lt;/code&gt; object.
This choice has some side effects, as we will see, but in practice ends up being a good compromise in most cases of interest.&lt;/p&gt;

&lt;h3 id=&#34;none-pythonic-missing-data&#34;&gt;&lt;code&gt;None&lt;/code&gt;: Pythonic missing data&lt;/h3&gt;

&lt;p&gt;The first sentinel value used by Pandas is &lt;code&gt;None&lt;/code&gt;, a Python singleton object that is often used for missing data in Python code.
Because it is a Python object, &lt;code&gt;None&lt;/code&gt; cannot be used in any arbitrary NumPy/Pandas array, but only in arrays with data type &lt;code&gt;&#39;object&#39;&lt;/code&gt; (i.e., arrays of Python objects):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
import pandas as pd
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;vals1 = np.array([1, None, 3, 4])
vals1
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([1, None, 3, 4], dtype=object)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This &lt;code&gt;dtype=object&lt;/code&gt; means that the best common type representation NumPy could infer for the contents of the array is that they are Python objects.
While this kind of object array is useful for some purposes, any operations on the data will be done at the Python level, with much more overhead than the typically fast operations seen for arrays with native types:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for dtype in [&#39;object&#39;, &#39;int&#39;]:
    print(&amp;quot;dtype =&amp;quot;, dtype)
    %timeit np.arange(1E6, dtype=dtype).sum()
    print()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;dtype = object
10 loops, best of 3: 78.2 ms per loop

dtype = int
100 loops, best of 3: 3.06 ms per loop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The use of Python objects in an array also means that if you perform aggregations like &lt;code&gt;sum()&lt;/code&gt; or &lt;code&gt;min()&lt;/code&gt; across an array with a &lt;code&gt;None&lt;/code&gt; value, you will generally get an error:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;vals1.sum()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

&amp;lt;ipython-input-4-749fd8ae6030&amp;gt; in &amp;lt;module&amp;gt;()
----&amp;gt; 1 vals1.sum()


/Users/jakevdp/anaconda/lib/python3.5/site-packages/numpy/core/_methods.py in _sum(a, axis, dtype, out, keepdims)
     30 
     31 def _sum(a, axis=None, dtype=None, out=None, keepdims=False):
---&amp;gt; 32     return umr_sum(a, axis, dtype, out, keepdims)
     33 
     34 def _prod(a, axis=None, dtype=None, out=None, keepdims=False):


TypeError: unsupported operand type(s) for +: &#39;int&#39; and &#39;NoneType&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This reflects the fact that addition between an integer and &lt;code&gt;None&lt;/code&gt; is undefined.&lt;/p&gt;

&lt;h3 id=&#34;nan-missing-numerical-data&#34;&gt;&lt;code&gt;NaN&lt;/code&gt;: Missing numerical data&lt;/h3&gt;

&lt;p&gt;The other missing data representation, &lt;code&gt;NaN&lt;/code&gt; (acronym for &lt;em&gt;Not a Number&lt;/em&gt;), is different; it is a special floating-point value recognized by all systems that use the standard IEEE floating-point representation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;vals2 = np.array([1, np.nan, 3, 4]) 
vals2.dtype
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;dtype(&#39;float64&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice that NumPy chose a native floating-point type for this array: this means that unlike the object array from before, this array supports fast operations pushed into compiled code.
You should be aware that &lt;code&gt;NaN&lt;/code&gt; is a bit like a data virus–it infects any other object it touches.
Regardless of the operation, the result of arithmetic with &lt;code&gt;NaN&lt;/code&gt; will be another &lt;code&gt;NaN&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;1 + np.nan
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;nan
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;0 *  np.nan
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;nan
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that this means that aggregates over the values are well defined (i.e., they don&amp;rsquo;t result in an error) but not always useful:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;vals2.sum(), vals2.min(), vals2.max()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(nan, nan, nan)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;NumPy does provide some special aggregations that will ignore these missing values:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;np.nansum(vals2), np.nanmin(vals2), np.nanmax(vals2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(8.0, 1.0, 4.0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Keep in mind that &lt;code&gt;NaN&lt;/code&gt; is specifically a floating-point value; there is no equivalent NaN value for integers, strings, or other types.&lt;/p&gt;

&lt;h3 id=&#34;nan-and-none-in-pandas&#34;&gt;NaN and None in Pandas&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;NaN&lt;/code&gt; and &lt;code&gt;None&lt;/code&gt; both have their place, and Pandas is built to handle the two of them nearly interchangeably, converting between them where appropriate:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.Series([1, np.nan, 2, None])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    1.0
1    NaN
2    2.0
3    NaN
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For types that don&amp;rsquo;t have an available sentinel value, Pandas automatically type-casts when NA values are present.
For example, if we set a value in an integer array to &lt;code&gt;np.nan&lt;/code&gt;, it will automatically be upcast to a floating-point type to accommodate the NA:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x = pd.Series(range(2), dtype=int)
x
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    0
1    1
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x[0] = None
x
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    NaN
1    1.0
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice that in addition to casting the integer array to floating point, Pandas automatically converts the &lt;code&gt;None&lt;/code&gt; to a &lt;code&gt;NaN&lt;/code&gt; value.
(Be aware that there is a proposal to add a native integer NA to Pandas in the future; as of this writing, it has not been included).&lt;/p&gt;

&lt;p&gt;While this type of magic may feel a bit hackish compared to the more unified approach to NA values in domain-specific languages like R, the Pandas sentinel/casting approach works quite well in practice and in my experience only rarely causes issues.&lt;/p&gt;

&lt;p&gt;The following table lists the upcasting conventions in Pandas when NA values are introduced:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Typeclass&lt;/th&gt;
&lt;th&gt;Conversion When Storing NAs&lt;/th&gt;
&lt;th&gt;NA Sentinel Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;floating&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;No change&lt;/td&gt;
&lt;td&gt;&lt;code&gt;np.nan&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;object&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;No change&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt; or &lt;code&gt;np.nan&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;integer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Cast to &lt;code&gt;float64&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;np.nan&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;boolean&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Cast to &lt;code&gt;object&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt; or &lt;code&gt;np.nan&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Keep in mind that in Pandas, string data is always stored with an &lt;code&gt;object&lt;/code&gt; dtype.&lt;/p&gt;

&lt;h2 id=&#34;operating-on-null-values&#34;&gt;Operating on Null Values&lt;/h2&gt;

&lt;p&gt;As we have seen, Pandas treats &lt;code&gt;None&lt;/code&gt; and &lt;code&gt;NaN&lt;/code&gt; as essentially interchangeable for indicating missing or null values.
To facilitate this convention, there are several useful methods for detecting, removing, and replacing null values in Pandas data structures.
They are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;isnull()&lt;/code&gt;: Generate a boolean mask indicating missing values&lt;/li&gt;
&lt;li&gt;&lt;code&gt;notnull()&lt;/code&gt;: Opposite of &lt;code&gt;isnull()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dropna()&lt;/code&gt;: Return a filtered version of the data&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fillna()&lt;/code&gt;: Return a copy of the data with missing values filled or imputed&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We will conclude this section with a brief exploration and demonstration of these routines.&lt;/p&gt;

&lt;h3 id=&#34;detecting-null-values&#34;&gt;Detecting null values&lt;/h3&gt;

&lt;p&gt;Pandas data structures have two useful methods for detecting null data: &lt;code&gt;isnull()&lt;/code&gt; and &lt;code&gt;notnull()&lt;/code&gt;.
Either one will return a Boolean mask over the data. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data = pd.Series([1, np.nan, &#39;hello&#39;, None])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.isnull()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    False
1     True
2    False
3     True
dtype: bool
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As mentioned in &lt;a href=&#34;03.02-Data-Indexing-and-Selection.ipynb&#34; target=&#34;_blank&#34;&gt;Data Indexing and Selection&lt;/a&gt;, Boolean masks can be used directly as a &lt;code&gt;Series&lt;/code&gt; or &lt;code&gt;DataFrame&lt;/code&gt; index:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data[data.notnull()]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0        1
2    hello
dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;isnull()&lt;/code&gt; and &lt;code&gt;notnull()&lt;/code&gt; methods produce similar Boolean results for &lt;code&gt;DataFrame&lt;/code&gt;s.&lt;/p&gt;

&lt;h3 id=&#34;dropping-null-values&#34;&gt;Dropping null values&lt;/h3&gt;

&lt;p&gt;In addition to the masking used before, there are the convenience methods, &lt;code&gt;dropna()&lt;/code&gt;
(which removes NA values) and &lt;code&gt;fillna()&lt;/code&gt; (which fills in NA values). For a &lt;code&gt;Series&lt;/code&gt;,
the result is straightforward:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.dropna()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0        1
2    hello
dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For a &lt;code&gt;DataFrame&lt;/code&gt;, there are more options.
Consider the following &lt;code&gt;DataFrame&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df = pd.DataFrame([[1,      np.nan, 2],
                   [2,      3,      5],
                   [np.nan, 4,      6]])
df
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;th&gt;2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We cannot drop single values from a &lt;code&gt;DataFrame&lt;/code&gt;; we can only drop full rows or full columns.
Depending on the application, you might want one or the other, so &lt;code&gt;dropna()&lt;/code&gt; gives a number of options for a &lt;code&gt;DataFrame&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;By default, &lt;code&gt;dropna()&lt;/code&gt; will drop all rows in which &lt;em&gt;any&lt;/em&gt; null value is present:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.dropna()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;th&gt;2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Alternatively, you can drop NA values along a different axis; &lt;code&gt;axis=1&lt;/code&gt; drops all columns containing a null value:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.dropna(axis=&#39;columns&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;But this drops some good data as well; you might rather be interested in dropping rows or columns with &lt;em&gt;all&lt;/em&gt; NA values, or a majority of NA values.
This can be specified through the &lt;code&gt;how&lt;/code&gt; or &lt;code&gt;thresh&lt;/code&gt; parameters, which allow fine control of the number of nulls to allow through.&lt;/p&gt;

&lt;p&gt;The default is &lt;code&gt;how=&#39;any&#39;&lt;/code&gt;, such that any row or column (depending on the &lt;code&gt;axis&lt;/code&gt; keyword) containing a null value will be dropped.
You can also specify &lt;code&gt;how=&#39;all&#39;&lt;/code&gt;, which will only drop rows/columns that are &lt;em&gt;all&lt;/em&gt; null values:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df[3] = np.nan
df
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;th&gt;3&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.dropna(axis=&#39;columns&#39;, how=&#39;all&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;th&gt;2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;For finer-grained control, the &lt;code&gt;thresh&lt;/code&gt; parameter lets you specify a minimum number of non-null values for the row/column to be kept:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.dropna(axis=&#39;rows&#39;, thresh=3)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;th&gt;3&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Here the first and last row have been dropped, because they contain only two non-null values.&lt;/p&gt;

&lt;h3 id=&#34;filling-null-values&#34;&gt;Filling null values&lt;/h3&gt;

&lt;p&gt;Sometimes rather than dropping NA values, you&amp;rsquo;d rather replace them with a valid value.
This value might be a single number like zero, or it might be some sort of imputation or interpolation from the good values.
You could do this in-place using the &lt;code&gt;isnull()&lt;/code&gt; method as a mask, but because it is such a common operation Pandas provides the &lt;code&gt;fillna()&lt;/code&gt; method, which returns a copy of the array with the null values replaced.&lt;/p&gt;

&lt;p&gt;Consider the following &lt;code&gt;Series&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data = pd.Series([1, np.nan, 2, None, 3], index=list(&#39;abcde&#39;))
data
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;a    1.0
b    NaN
c    2.0
d    NaN
e    3.0
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can fill NA entries with a single value, such as zero:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.fillna(0)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;a    1.0
b    0.0
c    2.0
d    0.0
e    3.0
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can specify a forward-fill to propagate the previous value forward:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# forward-fill
data.fillna(method=&#39;ffill&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;a    1.0
b    1.0
c    2.0
d    2.0
e    3.0
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or we can specify a back-fill to propagate the next values backward:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# back-fill
data.fillna(method=&#39;bfill&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;a    1.0
b    2.0
c    2.0
d    3.0
e    3.0
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For &lt;code&gt;DataFrame&lt;/code&gt;s, the options are similar, but we can also specify an &lt;code&gt;axis&lt;/code&gt; along which the fills take place:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;th&gt;3&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.fillna(method=&#39;ffill&#39;, axis=1)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;th&gt;3&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;2.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;6.0&lt;/td&gt;
      &lt;td&gt;6.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Notice that if a previous value is not available during a forward fill, the NA value remains.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hierarchical Indexing</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.05-hierarchical-indexing/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.05-hierarchical-indexing/</guid>
      <description>

&lt;p&gt;Up to this point we&amp;rsquo;ve been focused primarily on one-dimensional and two-dimensional data, stored in Pandas &lt;code&gt;Series&lt;/code&gt; and &lt;code&gt;DataFrame&lt;/code&gt; objects, respectively.
Often it is useful to go beyond this and store higher-dimensional data–that is, data indexed by more than one or two keys.
While Pandas does provide &lt;code&gt;Panel&lt;/code&gt; and &lt;code&gt;Panel4D&lt;/code&gt; objects that natively handle three-dimensional and four-dimensional data (see &lt;a href=&#34;#Aside:-Panel-Data&#34;&gt;Aside: Panel Data&lt;/a&gt;), a far more common pattern in practice is to make use of &lt;em&gt;hierarchical indexing&lt;/em&gt; (also known as &lt;em&gt;multi-indexing&lt;/em&gt;) to incorporate multiple index &lt;em&gt;levels&lt;/em&gt; within a single index.
In this way, higher-dimensional data can be compactly represented within the familiar one-dimensional &lt;code&gt;Series&lt;/code&gt; and two-dimensional &lt;code&gt;DataFrame&lt;/code&gt; objects.&lt;/p&gt;

&lt;p&gt;In this section, we&amp;rsquo;ll explore the direct creation of &lt;code&gt;MultiIndex&lt;/code&gt; objects, considerations when indexing, slicing, and computing statistics across multiply indexed data, and useful routines for converting between simple and hierarchically indexed representations of your data.&lt;/p&gt;

&lt;p&gt;We begin with the standard imports:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
import numpy as np
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;a-multiply-indexed-series&#34;&gt;A Multiply Indexed Series&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s start by considering how we might represent two-dimensional data within a one-dimensional &lt;code&gt;Series&lt;/code&gt;.
For concreteness, we will consider a series of data where each point has a character and numerical key.&lt;/p&gt;

&lt;h3 id=&#34;the-bad-way&#34;&gt;The bad way&lt;/h3&gt;

&lt;p&gt;Suppose you would like to track data about states from two different years.
Using the Pandas tools we&amp;rsquo;ve already covered, you might be tempted to simply use Python tuples as keys:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;index = [(&#39;California&#39;, 2000), (&#39;California&#39;, 2010),
         (&#39;New York&#39;, 2000), (&#39;New York&#39;, 2010),
         (&#39;Texas&#39;, 2000), (&#39;Texas&#39;, 2010)]
populations = [33871648, 37253956,
               18976457, 19378102,
               20851820, 25145561]
pop = pd.Series(populations, index=index)
pop
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(California, 2000)    33871648
(California, 2010)    37253956
(New York, 2000)      18976457
(New York, 2010)      19378102
(Texas, 2000)         20851820
(Texas, 2010)         25145561
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With this indexing scheme, you can straightforwardly index or slice the series based on this multiple index:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop[(&#39;California&#39;, 2010):(&#39;Texas&#39;, 2000)]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(California, 2010)    37253956
(New York, 2000)      18976457
(New York, 2010)      19378102
(Texas, 2000)         20851820
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But the convenience ends there. For example, if you need to select all values from 2010, you&amp;rsquo;ll need to do some messy (and potentially slow) munging to make it happen:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop[[i for i in pop.index if i[1] == 2010]]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(California, 2010)    37253956
(New York, 2010)      19378102
(Texas, 2010)         25145561
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This produces the desired result, but is not as clean (or as efficient for large datasets) as the slicing syntax we&amp;rsquo;ve grown to love in Pandas.&lt;/p&gt;

&lt;h3 id=&#34;the-better-way-pandas-multiindex&#34;&gt;The Better Way: Pandas MultiIndex&lt;/h3&gt;

&lt;p&gt;Fortunately, Pandas provides a better way.
Our tuple-based indexing is essentially a rudimentary multi-index, and the Pandas &lt;code&gt;MultiIndex&lt;/code&gt; type gives us the type of operations we wish to have.
We can create a multi-index from the tuples as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;index = pd.MultiIndex.from_tuples(index)
index
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;MultiIndex(levels=[[&#39;California&#39;, &#39;New York&#39;, &#39;Texas&#39;], [2000, 2010]],
           codes=[[0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 0, 1]])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice that the &lt;code&gt;MultiIndex&lt;/code&gt; contains multiple &lt;em&gt;levels&lt;/em&gt; of indexing–in this case, the state names and the years, as well as multiple &lt;em&gt;labels&lt;/em&gt; for each data point which encode these levels.&lt;/p&gt;

&lt;p&gt;If we re-index our series with this &lt;code&gt;MultiIndex&lt;/code&gt;, we see the hierarchical representation of the data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop = pop.reindex(index)
pop
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;California  2000    33871648
            2010    37253956
New York    2000    18976457
            2010    19378102
Texas       2000    20851820
            2010    25145561
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here the first two columns of the &lt;code&gt;Series&lt;/code&gt; representation show the multiple index values, while the third column shows the data.
Notice that some entries are missing in the first column: in this multi-index representation, any blank entry indicates the same value as the line above it.&lt;/p&gt;

&lt;p&gt;Now to access all data for which the second index is 2010, we can simply use the Pandas slicing notation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop[:, 2010]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;California    37253956
New York      19378102
Texas         25145561
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The result is a singly indexed array with just the keys we&amp;rsquo;re interested in.
This syntax is much more convenient (and the operation is much more efficient!) than the home-spun tuple-based multi-indexing solution that we started with.
We&amp;rsquo;ll now further discuss this sort of indexing operation on hieararchically indexed data.&lt;/p&gt;

&lt;h3 id=&#34;multiindex-as-extra-dimension&#34;&gt;MultiIndex as extra dimension&lt;/h3&gt;

&lt;p&gt;You might notice something else here: we could easily have stored the same data using a simple &lt;code&gt;DataFrame&lt;/code&gt; with index and column labels.
In fact, Pandas is built with this equivalence in mind. The &lt;code&gt;unstack()&lt;/code&gt; method will quickly convert a multiply indexed &lt;code&gt;Series&lt;/code&gt; into a conventionally indexed &lt;code&gt;DataFrame&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop_df = pop.unstack()
pop_df
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;2000&lt;/th&gt;
      &lt;th&gt;2010&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;California&lt;/th&gt;
      &lt;td&gt;33871648&lt;/td&gt;
      &lt;td&gt;37253956&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;New York&lt;/th&gt;
      &lt;td&gt;18976457&lt;/td&gt;
      &lt;td&gt;19378102&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Texas&lt;/th&gt;
      &lt;td&gt;20851820&lt;/td&gt;
      &lt;td&gt;25145561&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Naturally, the &lt;code&gt;stack()&lt;/code&gt; method provides the opposite operation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop_df.stack()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;California  2000    33871648
            2010    37253956
New York    2000    18976457
            2010    19378102
Texas       2000    20851820
            2010    25145561
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Seeing this, you might wonder why would we would bother with hierarchical indexing at all.
The reason is simple: just as we were able to use multi-indexing to represent two-dimensional data within a one-dimensional &lt;code&gt;Series&lt;/code&gt;, we can also use it to represent data of three or more dimensions in a &lt;code&gt;Series&lt;/code&gt; or &lt;code&gt;DataFrame&lt;/code&gt;.
Each extra level in a multi-index represents an extra dimension of data; taking advantage of this property gives us much more flexibility in the types of data we can represent. Concretely, we might want to add another column of demographic data for each state at each year (say, population under 18) ; with a &lt;code&gt;MultiIndex&lt;/code&gt; this is as easy as adding another column to the &lt;code&gt;DataFrame&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop_df = pd.DataFrame({&#39;total&#39;: pop,
                       &#39;under18&#39;: [9267089, 9284094,
                                   4687374, 4318033,
                                   5906301, 6879014]})
pop_df
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;total&lt;/th&gt;
      &lt;th&gt;under18&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;California&lt;/th&gt;
      &lt;th&gt;2000&lt;/th&gt;
      &lt;td&gt;33871648&lt;/td&gt;
      &lt;td&gt;9267089&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2010&lt;/th&gt;
      &lt;td&gt;37253956&lt;/td&gt;
      &lt;td&gt;9284094&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;New York&lt;/th&gt;
      &lt;th&gt;2000&lt;/th&gt;
      &lt;td&gt;18976457&lt;/td&gt;
      &lt;td&gt;4687374&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2010&lt;/th&gt;
      &lt;td&gt;19378102&lt;/td&gt;
      &lt;td&gt;4318033&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;Texas&lt;/th&gt;
      &lt;th&gt;2000&lt;/th&gt;
      &lt;td&gt;20851820&lt;/td&gt;
      &lt;td&gt;5906301&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2010&lt;/th&gt;
      &lt;td&gt;25145561&lt;/td&gt;
      &lt;td&gt;6879014&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;In addition, all the ufuncs and other functionality discussed in &lt;a href=&#34;03.03-Operations-in-Pandas.ipynb&#34; target=&#34;_blank&#34;&gt;Operating on Data in Pandas&lt;/a&gt; work with hierarchical indices as well.
Here we compute the fraction of people under 18 by year, given the above data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;f_u18 = pop_df[&#39;under18&#39;] / pop_df[&#39;total&#39;]
f_u18.unstack()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;2000&lt;/th&gt;
      &lt;th&gt;2010&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;California&lt;/th&gt;
      &lt;td&gt;0.273594&lt;/td&gt;
      &lt;td&gt;0.249211&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;New York&lt;/th&gt;
      &lt;td&gt;0.247010&lt;/td&gt;
      &lt;td&gt;0.222831&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Texas&lt;/th&gt;
      &lt;td&gt;0.283251&lt;/td&gt;
      &lt;td&gt;0.273568&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;This allows us to easily and quickly manipulate and explore even high-dimensional data.&lt;/p&gt;

&lt;h2 id=&#34;methods-of-multiindex-creation&#34;&gt;Methods of MultiIndex Creation&lt;/h2&gt;

&lt;p&gt;The most straightforward way to construct a multiply indexed &lt;code&gt;Series&lt;/code&gt; or &lt;code&gt;DataFrame&lt;/code&gt; is to simply pass a list of two or more index arrays to the constructor. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df = pd.DataFrame(np.random.rand(4, 2),
                  index=[[&#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;b&#39;], [1, 2, 1, 2]],
                  columns=[&#39;data1&#39;, &#39;data2&#39;])
df
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;a&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;0.796230&lt;/td&gt;
      &lt;td&gt;0.068256&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;0.426336&lt;/td&gt;
      &lt;td&gt;0.132107&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;b&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;0.143173&lt;/td&gt;
      &lt;td&gt;0.353800&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;0.768689&lt;/td&gt;
      &lt;td&gt;0.646376&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The work of creating the &lt;code&gt;MultiIndex&lt;/code&gt; is done in the background.&lt;/p&gt;

&lt;p&gt;Similarly, if you pass a dictionary with appropriate tuples as keys, Pandas will automatically recognize this and use a &lt;code&gt;MultiIndex&lt;/code&gt; by default:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data = {(&#39;California&#39;, 2000): 33871648,
        (&#39;California&#39;, 2010): 37253956,
        (&#39;Texas&#39;, 2000): 20851820,
        (&#39;Texas&#39;, 2010): 25145561,
        (&#39;New York&#39;, 2000): 18976457,
        (&#39;New York&#39;, 2010): 19378102}
pd.Series(data)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;California  2000    33871648
            2010    37253956
Texas       2000    20851820
            2010    25145561
New York    2000    18976457
            2010    19378102
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nevertheless, it is sometimes useful to explicitly create a &lt;code&gt;MultiIndex&lt;/code&gt;; we&amp;rsquo;ll see a couple of these methods here.&lt;/p&gt;

&lt;h3 id=&#34;explicit-multiindex-constructors&#34;&gt;Explicit MultiIndex constructors&lt;/h3&gt;

&lt;p&gt;For more flexibility in how the index is constructed, you can instead use the class method constructors available in the &lt;code&gt;pd.MultiIndex&lt;/code&gt;.
For example, as we did before, you can construct the &lt;code&gt;MultiIndex&lt;/code&gt; from a simple list of arrays giving the index values within each level:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.MultiIndex.from_arrays([[&#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;b&#39;], [1, 2, 1, 2]])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;MultiIndex(levels=[[&#39;a&#39;, &#39;b&#39;], [1, 2]],
           codes=[[0, 0, 1, 1], [0, 1, 0, 1]])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can construct it from a list of tuples giving the multiple index values of each point:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.MultiIndex.from_tuples([(&#39;a&#39;, 1), (&#39;a&#39;, 2), (&#39;b&#39;, 1), (&#39;b&#39;, 2)])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;MultiIndex(levels=[[&#39;a&#39;, &#39;b&#39;], [1, 2]],
           codes=[[0, 0, 1, 1], [0, 1, 0, 1]])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can even construct it from a Cartesian product of single indices:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.MultiIndex.from_product([[&#39;a&#39;, &#39;b&#39;], [1, 2]])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;MultiIndex(levels=[[&#39;a&#39;, &#39;b&#39;], [1, 2]],
           codes=[[0, 0, 1, 1], [0, 1, 0, 1]])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Similarly, you can construct the &lt;code&gt;MultiIndex&lt;/code&gt; directly using its internal encoding by passing &lt;code&gt;levels&lt;/code&gt; (a list of lists containing available index values for each level) and &lt;code&gt;labels&lt;/code&gt; (a list of lists that reference these labels):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.MultiIndex(levels=[[&#39;a&#39;, &#39;b&#39;], [1, 2]],
              labels=[[0, 0, 1, 1], [0, 1, 0, 1]])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;D:\Anaconda\lib\site-packages\ipykernel_launcher.py:2: FutureWarning: the &#39;labels&#39; keyword is deprecated, use &#39;codes&#39; instead






MultiIndex(levels=[[&#39;a&#39;, &#39;b&#39;], [1, 2]],
           codes=[[0, 0, 1, 1], [0, 1, 0, 1]])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Any of these objects can be passed as the &lt;code&gt;index&lt;/code&gt; argument when creating a &lt;code&gt;Series&lt;/code&gt; or &lt;code&gt;Dataframe&lt;/code&gt;, or be passed to the &lt;code&gt;reindex&lt;/code&gt; method of an existing &lt;code&gt;Series&lt;/code&gt; or &lt;code&gt;DataFrame&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;multiindex-level-names&#34;&gt;MultiIndex level names&lt;/h3&gt;

&lt;p&gt;Sometimes it is convenient to name the levels of the &lt;code&gt;MultiIndex&lt;/code&gt;.
This can be accomplished by passing the &lt;code&gt;names&lt;/code&gt; argument to any of the above &lt;code&gt;MultiIndex&lt;/code&gt; constructors, or by setting the &lt;code&gt;names&lt;/code&gt; attribute of the index after the fact:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop.index.names = [&#39;state&#39;, &#39;year&#39;]
pop
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;state       year
California  2000    33871648
            2010    37253956
New York    2000    18976457
            2010    19378102
Texas       2000    20851820
            2010    25145561
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With more involved datasets, this can be a useful way to keep track of the meaning of various index values.&lt;/p&gt;

&lt;h3 id=&#34;multiindex-for-columns&#34;&gt;MultiIndex for columns&lt;/h3&gt;

&lt;p&gt;In a &lt;code&gt;DataFrame&lt;/code&gt;, the rows and columns are completely symmetric, and just as the rows can have multiple levels of indices, the columns can have multiple levels as well.
Consider the following, which is a mock-up of some (somewhat realistic) medical data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# hierarchical indices and columns
index = pd.MultiIndex.from_product([[2013, 2014], [1, 2]],
                                   names=[&#39;year&#39;, &#39;visit&#39;])
columns = pd.MultiIndex.from_product([[&#39;Bob&#39;, &#39;Guido&#39;, &#39;Sue&#39;], [&#39;HR&#39;, &#39;Temp&#39;]],
                                     names=[&#39;subject&#39;, &#39;type&#39;])

# mock some data
data = np.round(np.random.randn(4, 6), 1)
data[:, ::2] *= 10
data += 37

# create the DataFrame
health_data = pd.DataFrame(data, index=index, columns=columns)
health_data
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;subject&lt;/th&gt;
      &lt;th colspan=&#34;2&#34; halign=&#34;left&#34;&gt;Bob&lt;/th&gt;
      &lt;th colspan=&#34;2&#34; halign=&#34;left&#34;&gt;Guido&lt;/th&gt;
      &lt;th colspan=&#34;2&#34; halign=&#34;left&#34;&gt;Sue&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;type&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;Temp&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;Temp&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;Temp&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;visit&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;2013&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;37.0&lt;/td&gt;
      &lt;td&gt;36.7&lt;/td&gt;
      &lt;td&gt;37.0&lt;/td&gt;
      &lt;td&gt;36.5&lt;/td&gt;
      &lt;td&gt;37.0&lt;/td&gt;
      &lt;td&gt;37.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;32.0&lt;/td&gt;
      &lt;td&gt;36.8&lt;/td&gt;
      &lt;td&gt;50.0&lt;/td&gt;
      &lt;td&gt;36.3&lt;/td&gt;
      &lt;td&gt;43.0&lt;/td&gt;
      &lt;td&gt;37.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;2014&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;27.0&lt;/td&gt;
      &lt;td&gt;36.5&lt;/td&gt;
      &lt;td&gt;38.0&lt;/td&gt;
      &lt;td&gt;37.4&lt;/td&gt;
      &lt;td&gt;30.0&lt;/td&gt;
      &lt;td&gt;35.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;28.0&lt;/td&gt;
      &lt;td&gt;38.4&lt;/td&gt;
      &lt;td&gt;32.0&lt;/td&gt;
      &lt;td&gt;36.9&lt;/td&gt;
      &lt;td&gt;33.0&lt;/td&gt;
      &lt;td&gt;38.8&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Here we see where the multi-indexing for both rows and columns can come in &lt;em&gt;very&lt;/em&gt; handy.
This is fundamentally four-dimensional data, where the dimensions are the subject, the measurement type, the year, and the visit number.
With this in place we can, for example, index the top-level column by the person&amp;rsquo;s name and get a full &lt;code&gt;DataFrame&lt;/code&gt; containing just that person&amp;rsquo;s information:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;health_data[&#39;Guido&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;type&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;Temp&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;visit&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;2013&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;37.0&lt;/td&gt;
      &lt;td&gt;36.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;50.0&lt;/td&gt;
      &lt;td&gt;36.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;2014&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;38.0&lt;/td&gt;
      &lt;td&gt;37.4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;32.0&lt;/td&gt;
      &lt;td&gt;36.9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;For complicated records containing multiple labeled measurements across multiple times for many subjects (people, countries, cities, etc.) use of hierarchical rows and columns can be extremely convenient!&lt;/p&gt;

&lt;h2 id=&#34;indexing-and-slicing-a-multiindex&#34;&gt;Indexing and Slicing a MultiIndex&lt;/h2&gt;

&lt;p&gt;Indexing and slicing on a &lt;code&gt;MultiIndex&lt;/code&gt; is designed to be intuitive, and it helps if you think about the indices as added dimensions.
We&amp;rsquo;ll first look at indexing multiply indexed &lt;code&gt;Series&lt;/code&gt;, and then multiply-indexed &lt;code&gt;DataFrame&lt;/code&gt;s.&lt;/p&gt;

&lt;h3 id=&#34;multiply-indexed-series&#34;&gt;Multiply indexed Series&lt;/h3&gt;

&lt;p&gt;Consider the multiply indexed &lt;code&gt;Series&lt;/code&gt; of state populations we saw earlier:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;state       year
California  2000    33871648
            2010    37253956
New York    2000    18976457
            2010    19378102
Texas       2000    20851820
            2010    25145561
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can access single elements by indexing with multiple terms:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop[&#39;California&#39;, 2000]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;33871648
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;MultiIndex&lt;/code&gt; also supports &lt;em&gt;partial indexing&lt;/em&gt;, or indexing just one of the levels in the index.
The result is another &lt;code&gt;Series&lt;/code&gt;, with the lower-level indices maintained:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop[&#39;California&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;year
2000    33871648
2010    37253956
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Partial slicing is available as well, as long as the &lt;code&gt;MultiIndex&lt;/code&gt; is sorted (see discussion in &lt;a href=&#34;#Sorted-and-unsorted-indices&#34;&gt;Sorted and Unsorted Indices&lt;/a&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop.loc[&#39;California&#39;:&#39;New York&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;state       year
California  2000    33871648
            2010    37253956
New York    2000    18976457
            2010    19378102
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With sorted indices, partial indexing can be performed on lower levels by passing an empty slice in the first index:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop[:, 2000]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;state
California    33871648
New York      18976457
Texas         20851820
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Other types of indexing and selection (discussed in &lt;a href=&#34;03.02-Data-Indexing-and-Selection.ipynb&#34; target=&#34;_blank&#34;&gt;Data Indexing and Selection&lt;/a&gt;) work as well; for example, selection based on Boolean masks:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop[pop &amp;gt; 22000000]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;state       year
California  2000    33871648
            2010    37253956
Texas       2010    25145561
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Selection based on fancy indexing also works:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop[[&#39;California&#39;, &#39;Texas&#39;]]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;state       year
California  2000    33871648
            2010    37253956
Texas       2000    20851820
            2010    25145561
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;multiply-indexed-dataframes&#34;&gt;Multiply indexed DataFrames&lt;/h3&gt;

&lt;p&gt;A multiply indexed &lt;code&gt;DataFrame&lt;/code&gt; behaves in a similar manner.
Consider our toy medical &lt;code&gt;DataFrame&lt;/code&gt; from before:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;health_data
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;subject&lt;/th&gt;
      &lt;th colspan=&#34;2&#34; halign=&#34;left&#34;&gt;Bob&lt;/th&gt;
      &lt;th colspan=&#34;2&#34; halign=&#34;left&#34;&gt;Guido&lt;/th&gt;
      &lt;th colspan=&#34;2&#34; halign=&#34;left&#34;&gt;Sue&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;type&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;Temp&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;Temp&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;Temp&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;visit&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;2013&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;37.0&lt;/td&gt;
      &lt;td&gt;36.7&lt;/td&gt;
      &lt;td&gt;37.0&lt;/td&gt;
      &lt;td&gt;36.5&lt;/td&gt;
      &lt;td&gt;37.0&lt;/td&gt;
      &lt;td&gt;37.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;32.0&lt;/td&gt;
      &lt;td&gt;36.8&lt;/td&gt;
      &lt;td&gt;50.0&lt;/td&gt;
      &lt;td&gt;36.3&lt;/td&gt;
      &lt;td&gt;43.0&lt;/td&gt;
      &lt;td&gt;37.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;2014&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;27.0&lt;/td&gt;
      &lt;td&gt;36.5&lt;/td&gt;
      &lt;td&gt;38.0&lt;/td&gt;
      &lt;td&gt;37.4&lt;/td&gt;
      &lt;td&gt;30.0&lt;/td&gt;
      &lt;td&gt;35.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;28.0&lt;/td&gt;
      &lt;td&gt;38.4&lt;/td&gt;
      &lt;td&gt;32.0&lt;/td&gt;
      &lt;td&gt;36.9&lt;/td&gt;
      &lt;td&gt;33.0&lt;/td&gt;
      &lt;td&gt;38.8&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Remember that columns are primary in a &lt;code&gt;DataFrame&lt;/code&gt;, and the syntax used for multiply indexed &lt;code&gt;Series&lt;/code&gt; applies to the columns.
For example, we can recover Guido&amp;rsquo;s heart rate data with a simple operation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;health_data[&#39;Guido&#39;, &#39;HR&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;year  visit
2013  1        37.0
      2        50.0
2014  1        38.0
      2        32.0
Name: (Guido, HR), dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Also, as with the single-index case, we can use the &lt;code&gt;loc&lt;/code&gt;, &lt;code&gt;iloc&lt;/code&gt;, and &lt;code&gt;ix&lt;/code&gt; indexers introduced in &lt;a href=&#34;03.02-Data-Indexing-and-Selection.ipynb&#34; target=&#34;_blank&#34;&gt;Data Indexing and Selection&lt;/a&gt;. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;health_data.iloc[:2, :2]
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;subject&lt;/th&gt;
      &lt;th colspan=&#34;2&#34; halign=&#34;left&#34;&gt;Bob&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;type&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;Temp&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;visit&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;2013&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;37.0&lt;/td&gt;
      &lt;td&gt;36.7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;32.0&lt;/td&gt;
      &lt;td&gt;36.8&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;These indexers provide an array-like view of the underlying two-dimensional data, but each individual index in &lt;code&gt;loc&lt;/code&gt; or &lt;code&gt;iloc&lt;/code&gt; can be passed a tuple of multiple indices. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;health_data.loc[:, (&#39;Bob&#39;, &#39;HR&#39;)]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;year  visit
2013  1        37.0
      2        32.0
2014  1        27.0
      2        28.0
Name: (Bob, HR), dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Working with slices within these index tuples is not especially convenient; trying to create a slice within a tuple will lead to a syntax error:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;health_data.loc[(:, 1), (:, &#39;HR&#39;)]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  File &amp;quot;&amp;lt;ipython-input-33-fb34fa30ac09&amp;gt;&amp;quot;, line 1
    health_data.loc[(:, 1), (:, &#39;HR&#39;)]
                     ^
SyntaxError: invalid syntax
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You could get around this by building the desired slice explicitly using Python&amp;rsquo;s built-in &lt;code&gt;slice()&lt;/code&gt; function, but a better way in this context is to use an &lt;code&gt;IndexSlice&lt;/code&gt; object, which Pandas provides for precisely this situation.
For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;idx = pd.IndexSlice
health_data.loc[idx[:, 1], idx[:, &#39;HR&#39;]]
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;subject&lt;/th&gt;
      &lt;th&gt;Bob&lt;/th&gt;
      &lt;th&gt;Guido&lt;/th&gt;
      &lt;th&gt;Sue&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;type&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;visit&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2013&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;37.0&lt;/td&gt;
      &lt;td&gt;37.0&lt;/td&gt;
      &lt;td&gt;37.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2014&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;27.0&lt;/td&gt;
      &lt;td&gt;38.0&lt;/td&gt;
      &lt;td&gt;30.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;There are so many ways to interact with data in multiply indexed &lt;code&gt;Series&lt;/code&gt; and &lt;code&gt;DataFrame&lt;/code&gt;s, and as with many tools in this book the best way to become familiar with them is to try them out!&lt;/p&gt;

&lt;h2 id=&#34;rearranging-multi-indices&#34;&gt;Rearranging Multi-Indices&lt;/h2&gt;

&lt;p&gt;One of the keys to working with multiply indexed data is knowing how to effectively transform the data.
There are a number of operations that will preserve all the information in the dataset, but rearrange it for the purposes of various computations.
We saw a brief example of this in the &lt;code&gt;stack()&lt;/code&gt; and &lt;code&gt;unstack()&lt;/code&gt; methods, but there are many more ways to finely control the rearrangement of data between hierarchical indices and columns, and we&amp;rsquo;ll explore them here.&lt;/p&gt;

&lt;h3 id=&#34;sorted-and-unsorted-indices&#34;&gt;Sorted and unsorted indices&lt;/h3&gt;

&lt;p&gt;Earlier, we briefly mentioned a caveat, but we should emphasize it more here.
&lt;em&gt;Many of the &lt;code&gt;MultiIndex&lt;/code&gt; slicing operations will fail if the index is not sorted.&lt;/em&gt;
Let&amp;rsquo;s take a look at this here.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll start by creating some simple multiply indexed data where the indices are &lt;em&gt;not lexographically sorted&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;index = pd.MultiIndex.from_product([[&#39;a&#39;, &#39;c&#39;, &#39;b&#39;], [1, 2]])
data = pd.Series(np.random.rand(6), index=index)
data.index.names = [&#39;char&#39;, &#39;int&#39;]
data
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;char  int
a     1      0.748770
      2      0.813412
c     1      0.551106
      2      0.423799
b     1      0.450351
      2      0.241441
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we try to take a partial slice of this index, it will result in an error:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;try:
    data[&#39;a&#39;:&#39;b&#39;]
except KeyError as e:
    print(type(e))
    print(e)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;class &#39;pandas.errors.UnsortedIndexError&#39;&amp;gt;
&#39;Key length (1) was greater than MultiIndex lexsort depth (0)&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Although it is not entirely clear from the error message, this is the result of the MultiIndex not being sorted.
For various reasons, partial slices and other similar operations require the levels in the &lt;code&gt;MultiIndex&lt;/code&gt; to be in sorted (i.e., lexographical) order.
Pandas provides a number of convenience routines to perform this type of sorting; examples are the &lt;code&gt;sort_index()&lt;/code&gt; and &lt;code&gt;sortlevel()&lt;/code&gt; methods of the &lt;code&gt;DataFrame&lt;/code&gt;.
We&amp;rsquo;ll use the simplest, &lt;code&gt;sort_index()&lt;/code&gt;, here:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data = data.sort_index()
data
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;char  int
a     1      0.748770
      2      0.813412
b     1      0.450351
      2      0.241441
c     1      0.551106
      2      0.423799
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With the index sorted in this way, partial slicing will work as expected:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data[&#39;a&#39;:&#39;b&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;char  int
a     1      0.748770
      2      0.813412
b     1      0.450351
      2      0.241441
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;stacking-and-unstacking-indices&#34;&gt;Stacking and unstacking indices&lt;/h3&gt;

&lt;p&gt;As we saw briefly before, it is possible to convert a dataset from a stacked multi-index to a simple two-dimensional representation, optionally specifying the level to use:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop.unstack(level=0)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;state&lt;/th&gt;
      &lt;th&gt;California&lt;/th&gt;
      &lt;th&gt;New York&lt;/th&gt;
      &lt;th&gt;Texas&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2000&lt;/th&gt;
      &lt;td&gt;33871648&lt;/td&gt;
      &lt;td&gt;18976457&lt;/td&gt;
      &lt;td&gt;20851820&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2010&lt;/th&gt;
      &lt;td&gt;37253956&lt;/td&gt;
      &lt;td&gt;19378102&lt;/td&gt;
      &lt;td&gt;25145561&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop.unstack(level=1)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;2000&lt;/th&gt;
      &lt;th&gt;2010&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;state&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;California&lt;/th&gt;
      &lt;td&gt;33871648&lt;/td&gt;
      &lt;td&gt;37253956&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;New York&lt;/th&gt;
      &lt;td&gt;18976457&lt;/td&gt;
      &lt;td&gt;19378102&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Texas&lt;/th&gt;
      &lt;td&gt;20851820&lt;/td&gt;
      &lt;td&gt;25145561&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The opposite of &lt;code&gt;unstack()&lt;/code&gt; is &lt;code&gt;stack()&lt;/code&gt;, which here can be used to recover the original series:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop.unstack().stack()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;state       year
California  2000    33871648
            2010    37253956
New York    2000    18976457
            2010    19378102
Texas       2000    20851820
            2010    25145561
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;index-setting-and-resetting&#34;&gt;Index setting and resetting&lt;/h3&gt;

&lt;p&gt;Another way to rearrange hierarchical data is to turn the index labels into columns; this can be accomplished with the &lt;code&gt;reset_index&lt;/code&gt; method.
Calling this on the population dictionary will result in a &lt;code&gt;DataFrame&lt;/code&gt; with a &lt;em&gt;state&lt;/em&gt; and &lt;em&gt;year&lt;/em&gt; column holding the information that was formerly in the index.
For clarity, we can optionally specify the name of the data for the column representation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop_flat = pop.reset_index(name=&#39;population&#39;)
pop_flat
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;state&lt;/th&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;population&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;California&lt;/td&gt;
      &lt;td&gt;2000&lt;/td&gt;
      &lt;td&gt;33871648&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;California&lt;/td&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;37253956&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;New York&lt;/td&gt;
      &lt;td&gt;2000&lt;/td&gt;
      &lt;td&gt;18976457&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;New York&lt;/td&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;19378102&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;Texas&lt;/td&gt;
      &lt;td&gt;2000&lt;/td&gt;
      &lt;td&gt;20851820&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;Texas&lt;/td&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;25145561&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Often when working with data in the real world, the raw input data looks like this and it&amp;rsquo;s useful to build a &lt;code&gt;MultiIndex&lt;/code&gt; from the column values.
This can be done with the &lt;code&gt;set_index&lt;/code&gt; method of the &lt;code&gt;DataFrame&lt;/code&gt;, which returns a multiply indexed &lt;code&gt;DataFrame&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop_flat.set_index([&#39;state&#39;, &#39;year&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;population&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;state&lt;/th&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;California&lt;/th&gt;
      &lt;th&gt;2000&lt;/th&gt;
      &lt;td&gt;33871648&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2010&lt;/th&gt;
      &lt;td&gt;37253956&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;New York&lt;/th&gt;
      &lt;th&gt;2000&lt;/th&gt;
      &lt;td&gt;18976457&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2010&lt;/th&gt;
      &lt;td&gt;19378102&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;Texas&lt;/th&gt;
      &lt;th&gt;2000&lt;/th&gt;
      &lt;td&gt;20851820&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2010&lt;/th&gt;
      &lt;td&gt;25145561&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;In practice, I find this type of reindexing to be one of the more useful patterns when encountering real-world datasets.&lt;/p&gt;

&lt;h2 id=&#34;data-aggregations-on-multi-indices&#34;&gt;Data Aggregations on Multi-Indices&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ve previously seen that Pandas has built-in data aggregation methods, such as &lt;code&gt;mean()&lt;/code&gt;, &lt;code&gt;sum()&lt;/code&gt;, and &lt;code&gt;max()&lt;/code&gt;.
For hierarchically indexed data, these can be passed a &lt;code&gt;level&lt;/code&gt; parameter that controls which subset of the data the aggregate is computed on.&lt;/p&gt;

&lt;p&gt;For example, let&amp;rsquo;s return to our health data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;health_data
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;subject&lt;/th&gt;
      &lt;th colspan=&#34;2&#34; halign=&#34;left&#34;&gt;Bob&lt;/th&gt;
      &lt;th colspan=&#34;2&#34; halign=&#34;left&#34;&gt;Guido&lt;/th&gt;
      &lt;th colspan=&#34;2&#34; halign=&#34;left&#34;&gt;Sue&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;type&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;Temp&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;Temp&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;Temp&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;visit&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;2013&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;37.0&lt;/td&gt;
      &lt;td&gt;36.7&lt;/td&gt;
      &lt;td&gt;37.0&lt;/td&gt;
      &lt;td&gt;36.5&lt;/td&gt;
      &lt;td&gt;37.0&lt;/td&gt;
      &lt;td&gt;37.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;32.0&lt;/td&gt;
      &lt;td&gt;36.8&lt;/td&gt;
      &lt;td&gt;50.0&lt;/td&gt;
      &lt;td&gt;36.3&lt;/td&gt;
      &lt;td&gt;43.0&lt;/td&gt;
      &lt;td&gt;37.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;2014&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;27.0&lt;/td&gt;
      &lt;td&gt;36.5&lt;/td&gt;
      &lt;td&gt;38.0&lt;/td&gt;
      &lt;td&gt;37.4&lt;/td&gt;
      &lt;td&gt;30.0&lt;/td&gt;
      &lt;td&gt;35.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;28.0&lt;/td&gt;
      &lt;td&gt;38.4&lt;/td&gt;
      &lt;td&gt;32.0&lt;/td&gt;
      &lt;td&gt;36.9&lt;/td&gt;
      &lt;td&gt;33.0&lt;/td&gt;
      &lt;td&gt;38.8&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Perhaps we&amp;rsquo;d like to average-out the measurements in the two visits each year. We can do this by naming the index level we&amp;rsquo;d like to explore, in this case the year:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data_mean = health_data.mean(level=&#39;year&#39;)
data_mean
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;subject&lt;/th&gt;
      &lt;th colspan=&#34;2&#34; halign=&#34;left&#34;&gt;Bob&lt;/th&gt;
      &lt;th colspan=&#34;2&#34; halign=&#34;left&#34;&gt;Guido&lt;/th&gt;
      &lt;th colspan=&#34;2&#34; halign=&#34;left&#34;&gt;Sue&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;type&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;Temp&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;Temp&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;Temp&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2013&lt;/th&gt;
      &lt;td&gt;34.5&lt;/td&gt;
      &lt;td&gt;36.75&lt;/td&gt;
      &lt;td&gt;43.5&lt;/td&gt;
      &lt;td&gt;36.40&lt;/td&gt;
      &lt;td&gt;40.0&lt;/td&gt;
      &lt;td&gt;37.30&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2014&lt;/th&gt;
      &lt;td&gt;27.5&lt;/td&gt;
      &lt;td&gt;37.45&lt;/td&gt;
      &lt;td&gt;35.0&lt;/td&gt;
      &lt;td&gt;37.15&lt;/td&gt;
      &lt;td&gt;31.5&lt;/td&gt;
      &lt;td&gt;37.05&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;By further making use of the &lt;code&gt;axis&lt;/code&gt; keyword, we can take the mean among levels on the columns as well:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data_mean.mean(axis=1, level=&#39;type&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;type&lt;/th&gt;
      &lt;th&gt;HR&lt;/th&gt;
      &lt;th&gt;Temp&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2013&lt;/th&gt;
      &lt;td&gt;39.333333&lt;/td&gt;
      &lt;td&gt;36.816667&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2014&lt;/th&gt;
      &lt;td&gt;31.333333&lt;/td&gt;
      &lt;td&gt;37.216667&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Thus in two lines, we&amp;rsquo;ve been able to find the average heart rate and temperature measured among all subjects in all visits each year.
This syntax is actually a short cut to the &lt;code&gt;GroupBy&lt;/code&gt; functionality, which we will discuss in &lt;a href=&#34;03.08-Aggregation-and-Grouping.ipynb&#34; target=&#34;_blank&#34;&gt;Aggregation and Grouping&lt;/a&gt;.
While this is a toy example, many real-world datasets have similar hierarchical structure.&lt;/p&gt;

&lt;h2 id=&#34;aside-panel-data&#34;&gt;Aside: Panel Data&lt;/h2&gt;

&lt;p&gt;Pandas has a few other fundamental data structures that we have not yet discussed, namely the &lt;code&gt;pd.Panel&lt;/code&gt; and &lt;code&gt;pd.Panel4D&lt;/code&gt; objects.
These can be thought of, respectively, as three-dimensional and four-dimensional generalizations of the (one-dimensional) &lt;code&gt;Series&lt;/code&gt; and (two-dimensional) &lt;code&gt;DataFrame&lt;/code&gt; structures.
Once you are familiar with indexing and manipulation of data in a &lt;code&gt;Series&lt;/code&gt; and &lt;code&gt;DataFrame&lt;/code&gt;, &lt;code&gt;Panel&lt;/code&gt; and &lt;code&gt;Panel4D&lt;/code&gt; are relatively straightforward to use.
In particular, the &lt;code&gt;ix&lt;/code&gt;, &lt;code&gt;loc&lt;/code&gt;, and &lt;code&gt;iloc&lt;/code&gt; indexers discussed in &lt;a href=&#34;03.02-Data-Indexing-and-Selection.ipynb&#34; target=&#34;_blank&#34;&gt;Data Indexing and Selection&lt;/a&gt; extend readily to these higher-dimensional structures.&lt;/p&gt;

&lt;p&gt;We won&amp;rsquo;t cover these panel structures further in this text, as I&amp;rsquo;ve found in the majority of cases that multi-indexing is a more useful and conceptually simpler representation for higher-dimensional data.
Additionally, panel data is fundamentally a dense data representation, while multi-indexing is fundamentally a sparse data representation.
As the number of dimensions increases, the dense representation can become very inefficient for the majority of real-world datasets.
For the occasional specialized application, however, these structures can be useful.
If you&amp;rsquo;d like to read more about the &lt;code&gt;Panel&lt;/code&gt; and &lt;code&gt;Panel4D&lt;/code&gt; structures, see the references listed in &lt;a href=&#34;03.13-Further-Resources.ipynb&#34; target=&#34;_blank&#34;&gt;Further Resources&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Combining Datasets - Concat and Append</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.06-concat-and-append/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.06-concat-and-append/</guid>
      <description>

&lt;p&gt;Some of the most interesting studies of data come from combining different data sources.
These operations can involve anything from very straightforward concatenation of two different datasets, to more complicated database-style joins and merges that correctly handle any overlaps between the datasets.
&lt;code&gt;Series&lt;/code&gt; and &lt;code&gt;DataFrame&lt;/code&gt;s are built with this type of operation in mind, and Pandas includes functions and methods that make this sort of data wrangling fast and straightforward.&lt;/p&gt;

&lt;p&gt;Here we&amp;rsquo;ll take a look at simple concatenation of &lt;code&gt;Series&lt;/code&gt; and &lt;code&gt;DataFrame&lt;/code&gt;s with the &lt;code&gt;pd.concat&lt;/code&gt; function; later we&amp;rsquo;ll dive into more sophisticated in-memory merges and joins implemented in Pandas.&lt;/p&gt;

&lt;p&gt;We begin with the standard imports:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
import numpy as np
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For convenience, we&amp;rsquo;ll define this function which creates a &lt;code&gt;DataFrame&lt;/code&gt; of a particular form that will be useful below:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def make_df(cols, ind):
    &amp;quot;&amp;quot;&amp;quot;Quickly make a DataFrame&amp;quot;&amp;quot;&amp;quot;
    data = {c: [str(c) + str(i) for i in ind]
            for c in cols}
    return pd.DataFrame(data, ind)

# example DataFrame
make_df(&#39;ABC&#39;, range(3))
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A0&lt;/td&gt;
      &lt;td&gt;B0&lt;/td&gt;
      &lt;td&gt;C0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
      &lt;td&gt;C1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;A2&lt;/td&gt;
      &lt;td&gt;B2&lt;/td&gt;
      &lt;td&gt;C2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;In addition, we&amp;rsquo;ll create a quick class that allows us to display multiple &lt;code&gt;DataFrame&lt;/code&gt;s side by side. The code makes use of the special &lt;code&gt;_repr_html_&lt;/code&gt; method, which IPython uses to implement its rich object display:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class display(object):
    &amp;quot;&amp;quot;&amp;quot;Display HTML representation of multiple objects&amp;quot;&amp;quot;&amp;quot;
    template = &amp;quot;&amp;quot;&amp;quot;&amp;lt;div style=&amp;quot;float: left; padding: 10px;&amp;quot;&amp;gt;
    &amp;lt;p style=&#39;font-family:&amp;quot;Courier New&amp;quot;, Courier, monospace&#39;&amp;gt;{0}&amp;lt;/p&amp;gt;{1}
    &amp;lt;/div&amp;gt;&amp;quot;&amp;quot;&amp;quot;
    def __init__(self, *args):
        self.args = args
        
    def _repr_html_(self):
        return &#39;\n&#39;.join(self.template.format(a, eval(a)._repr_html_())
                         for a in self.args)
    
    def __repr__(self):
        return &#39;\n\n&#39;.join(a + &#39;\n&#39; + repr(eval(a))
                           for a in self.args)
    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The use of this will become clearer as we continue our discussion in the following section.&lt;/p&gt;

&lt;h2 id=&#34;recall-concatenation-of-numpy-arrays&#34;&gt;Recall: Concatenation of NumPy Arrays&lt;/h2&gt;

&lt;p&gt;Concatenation of &lt;code&gt;Series&lt;/code&gt; and &lt;code&gt;DataFrame&lt;/code&gt; objects is very similar to concatenation of Numpy arrays, which can be done via the &lt;code&gt;np.concatenate&lt;/code&gt; function as discussed in &lt;a href=&#34;02.02-The-Basics-Of-NumPy-Arrays.ipynb&#34; target=&#34;_blank&#34;&gt;The Basics of NumPy Arrays&lt;/a&gt;.
Recall that with it, you can combine the contents of two or more arrays into a single array:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x = [1, 2, 3]
y = [4, 5, 6]
z = [7, 8, 9]
np.concatenate([x, y, z])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([1, 2, 3, 4, 5, 6, 7, 8, 9])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first argument is a list or tuple of arrays to concatenate.
Additionally, it takes an &lt;code&gt;axis&lt;/code&gt; keyword that allows you to specify the axis along which the result will be concatenated:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x = [[1, 2],
     [3, 4]]
np.concatenate([x, x], axis=1)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([[1, 2, 1, 2],
       [3, 4, 3, 4]])
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;simple-concatenation-with-pd-concat&#34;&gt;Simple Concatenation with &lt;code&gt;pd.concat&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;Pandas has a function, &lt;code&gt;pd.concat()&lt;/code&gt;, which has a similar syntax to &lt;code&gt;np.concatenate&lt;/code&gt; but contains a number of options that we&amp;rsquo;ll discuss momentarily:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Signature in Pandas v0.18
pd.concat(objs, axis=0, join=&#39;outer&#39;, join_axes=None, ignore_index=False,
          keys=None, levels=None, names=None, verify_integrity=False,
          copy=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;pd.concat()&lt;/code&gt; can be used for a simple concatenation of &lt;code&gt;Series&lt;/code&gt; or &lt;code&gt;DataFrame&lt;/code&gt; objects, just as &lt;code&gt;np.concatenate()&lt;/code&gt; can be used for simple concatenations of arrays:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ser1 = pd.Series([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;], index=[1, 2, 3])
ser2 = pd.Series([&#39;D&#39;, &#39;E&#39;, &#39;F&#39;], index=[4, 5, 6])
pd.concat([ser1, ser2])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1    A
2    B
3    C
4    D
5    E
6    F
dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It also works to concatenate higher-dimensional objects, such as &lt;code&gt;DataFrame&lt;/code&gt;s:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df1 = make_df(&#39;AB&#39;, [1, 2])
df2 = make_df(&#39;AB&#39;, [3, 4])
display(&#39;df1&#39;, &#39;df2&#39;, &#39;pd.concat([df1, df2])&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df1&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;A2&lt;/td&gt;
      &lt;td&gt;B2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df2&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;A3&lt;/td&gt;
      &lt;td&gt;B3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;A4&lt;/td&gt;
      &lt;td&gt;B4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.concat([df1, df2])&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;A2&lt;/td&gt;
      &lt;td&gt;B2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;A3&lt;/td&gt;
      &lt;td&gt;B3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;A4&lt;/td&gt;
      &lt;td&gt;B4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;By default, the concatenation takes place row-wise within the &lt;code&gt;DataFrame&lt;/code&gt; (i.e., &lt;code&gt;axis=0&lt;/code&gt;).
Like &lt;code&gt;np.concatenate&lt;/code&gt;, &lt;code&gt;pd.concat&lt;/code&gt; allows specification of an axis along which concatenation will take place.
Consider the following example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df3 = make_df(&#39;AB&#39;, [0, 1])
df4 = make_df(&#39;CD&#39;, [0, 1])
display(&#39;df3&#39;, &#39;df4&#39;, &amp;quot;pd.concat([df3, df4], axis=&#39;col&#39;)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df3&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A0&lt;/td&gt;
      &lt;td&gt;B0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df4&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;th&gt;D&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;C0&lt;/td&gt;
      &lt;td&gt;D0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;C1&lt;/td&gt;
      &lt;td&gt;D1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.concat([df3, df4], axis=&#39;col&#39;)&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;th&gt;D&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A0&lt;/td&gt;
      &lt;td&gt;B0&lt;/td&gt;
      &lt;td&gt;C0&lt;/td&gt;
      &lt;td&gt;D0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
      &lt;td&gt;C1&lt;/td&gt;
      &lt;td&gt;D1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;We could have equivalently specified &lt;code&gt;axis=1&lt;/code&gt;; here we&amp;rsquo;ve used the more intuitive &lt;code&gt;axis=&#39;col&#39;&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;duplicate-indices&#34;&gt;Duplicate indices&lt;/h3&gt;

&lt;p&gt;One important difference between &lt;code&gt;np.concatenate&lt;/code&gt; and &lt;code&gt;pd.concat&lt;/code&gt; is that Pandas concatenation &lt;em&gt;preserves indices&lt;/em&gt;, even if the result will have duplicate indices!
Consider this simple example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x = make_df(&#39;AB&#39;, [0, 1])
y = make_df(&#39;AB&#39;, [2, 3])
y.index = x.index  # make duplicate indices!
display(&#39;x&#39;, &#39;y&#39;, &#39;pd.concat([x, y])&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;x&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A0&lt;/td&gt;
      &lt;td&gt;B0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;y&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A2&lt;/td&gt;
      &lt;td&gt;B2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A3&lt;/td&gt;
      &lt;td&gt;B3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.concat([x, y])&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A0&lt;/td&gt;
      &lt;td&gt;B0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A2&lt;/td&gt;
      &lt;td&gt;B2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A3&lt;/td&gt;
      &lt;td&gt;B3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;Notice the repeated indices in the result.
While this is valid within &lt;code&gt;DataFrame&lt;/code&gt;s, the outcome is often undesirable.
&lt;code&gt;pd.concat()&lt;/code&gt; gives us a few ways to handle it.&lt;/p&gt;

&lt;h4 id=&#34;catching-the-repeats-as-an-error&#34;&gt;Catching the repeats as an error&lt;/h4&gt;

&lt;p&gt;If you&amp;rsquo;d like to simply verify that the indices in the result of &lt;code&gt;pd.concat()&lt;/code&gt; do not overlap, you can specify the &lt;code&gt;verify_integrity&lt;/code&gt; flag.
With this set to True, the concatenation will raise an exception if there are duplicate indices.
Here is an example, where for clarity we&amp;rsquo;ll catch and print the error message:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;try:
    pd.concat([x, y], verify_integrity=True)
except ValueError as e:
    print(&amp;quot;ValueError:&amp;quot;, e)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;ValueError: Indexes have overlapping values: [0, 1]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;ignoring-the-index&#34;&gt;Ignoring the index&lt;/h4&gt;

&lt;p&gt;Sometimes the index itself does not matter, and you would prefer it to simply be ignored.
This option can be specified using the &lt;code&gt;ignore_index&lt;/code&gt; flag.
With this set to true, the concatenation will create a new integer index for the resulting &lt;code&gt;Series&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;display(&#39;x&#39;, &#39;y&#39;, &#39;pd.concat([x, y], ignore_index=True)&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;x&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A0&lt;/td&gt;
      &lt;td&gt;B0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;y&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A2&lt;/td&gt;
      &lt;td&gt;B2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A3&lt;/td&gt;
      &lt;td&gt;B3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.concat([x, y], ignore_index=True)&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A0&lt;/td&gt;
      &lt;td&gt;B0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;A2&lt;/td&gt;
      &lt;td&gt;B2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;A3&lt;/td&gt;
      &lt;td&gt;B3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;h4 id=&#34;adding-multiindex-keys&#34;&gt;Adding MultiIndex keys&lt;/h4&gt;

&lt;p&gt;Another option is to use the &lt;code&gt;keys&lt;/code&gt; option to specify a label for the data sources; the result will be a hierarchically indexed series containing the data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;display(&#39;x&#39;, &#39;y&#39;, &amp;quot;pd.concat([x, y], keys=[&#39;x&#39;, &#39;y&#39;])&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;x&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A0&lt;/td&gt;
      &lt;td&gt;B0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;y&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A2&lt;/td&gt;
      &lt;td&gt;B2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A3&lt;/td&gt;
      &lt;td&gt;B3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.concat([x, y], keys=[&#39;x&#39;, &#39;y&#39;])&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;x&lt;/th&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A0&lt;/td&gt;
      &lt;td&gt;B0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;y&lt;/th&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A2&lt;/td&gt;
      &lt;td&gt;B2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A3&lt;/td&gt;
      &lt;td&gt;B3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;The result is a multiply indexed &lt;code&gt;DataFrame&lt;/code&gt;, and we can use the tools discussed in &lt;a href=&#34;03.05-Hierarchical-Indexing.ipynb&#34; target=&#34;_blank&#34;&gt;Hierarchical Indexing&lt;/a&gt; to transform this data into the representation we&amp;rsquo;re interested in.&lt;/p&gt;

&lt;h3 id=&#34;concatenation-with-joins&#34;&gt;Concatenation with joins&lt;/h3&gt;

&lt;p&gt;In the simple examples we just looked at, we were mainly concatenating &lt;code&gt;DataFrame&lt;/code&gt;s with shared column names.
In practice, data from different sources might have different sets of column names, and &lt;code&gt;pd.concat&lt;/code&gt; offers several options in this case.
Consider the concatenation of the following two &lt;code&gt;DataFrame&lt;/code&gt;s, which have some (but not all!) columns in common:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df5 = make_df(&#39;ABC&#39;, [1, 2])
df6 = make_df(&#39;BCD&#39;, [3, 4])
display(&#39;df5&#39;, &#39;df6&#39;, &#39;pd.concat([df5, df6])&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df5&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
      &lt;td&gt;C1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;A2&lt;/td&gt;
      &lt;td&gt;B2&lt;/td&gt;
      &lt;td&gt;C2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df6&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;th&gt;D&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;B3&lt;/td&gt;
      &lt;td&gt;C3&lt;/td&gt;
      &lt;td&gt;D3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;B4&lt;/td&gt;
      &lt;td&gt;C4&lt;/td&gt;
      &lt;td&gt;D4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.concat([df5, df6])&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;th&gt;D&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
      &lt;td&gt;C1&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;A2&lt;/td&gt;
      &lt;td&gt;B2&lt;/td&gt;
      &lt;td&gt;C2&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;B3&lt;/td&gt;
      &lt;td&gt;C3&lt;/td&gt;
      &lt;td&gt;D3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;B4&lt;/td&gt;
      &lt;td&gt;C4&lt;/td&gt;
      &lt;td&gt;D4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;By default, the entries for which no data is available are filled with NA values.
To change this, we can specify one of several options for the &lt;code&gt;join&lt;/code&gt; and &lt;code&gt;join_axes&lt;/code&gt; parameters of the concatenate function.
By default, the join is a union of the input columns (&lt;code&gt;join=&#39;outer&#39;&lt;/code&gt;), but we can change this to an intersection of the columns using &lt;code&gt;join=&#39;inner&#39;&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;display(&#39;df5&#39;, &#39;df6&#39;,
        &amp;quot;pd.concat([df5, df6], join=&#39;inner&#39;)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df5&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
      &lt;td&gt;C1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;A2&lt;/td&gt;
      &lt;td&gt;B2&lt;/td&gt;
      &lt;td&gt;C2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df6&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;th&gt;D&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;B3&lt;/td&gt;
      &lt;td&gt;C3&lt;/td&gt;
      &lt;td&gt;D3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;B4&lt;/td&gt;
      &lt;td&gt;C4&lt;/td&gt;
      &lt;td&gt;D4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.concat([df5, df6], join=&#39;inner&#39;)&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;B1&lt;/td&gt;
      &lt;td&gt;C1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;B2&lt;/td&gt;
      &lt;td&gt;C2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;B3&lt;/td&gt;
      &lt;td&gt;C3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;B4&lt;/td&gt;
      &lt;td&gt;C4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;Another option is to directly specify the index of the remaininig colums using the &lt;code&gt;join_axes&lt;/code&gt; argument, which takes a list of index objects.
Here we&amp;rsquo;ll specify that the returned columns should be the same as those of the first input:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;display(&#39;df5&#39;, &#39;df6&#39;,
        &amp;quot;pd.concat([df5, df6], join_axes=[df5.columns])&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df5&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
      &lt;td&gt;C1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;A2&lt;/td&gt;
      &lt;td&gt;B2&lt;/td&gt;
      &lt;td&gt;C2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df6&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;th&gt;D&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;B3&lt;/td&gt;
      &lt;td&gt;C3&lt;/td&gt;
      &lt;td&gt;D3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;B4&lt;/td&gt;
      &lt;td&gt;C4&lt;/td&gt;
      &lt;td&gt;D4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.concat([df5, df6], join_axes=[df5.columns])&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
      &lt;td&gt;C1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;A2&lt;/td&gt;
      &lt;td&gt;B2&lt;/td&gt;
      &lt;td&gt;C2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;B3&lt;/td&gt;
      &lt;td&gt;C3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;B4&lt;/td&gt;
      &lt;td&gt;C4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;The combination of options of the &lt;code&gt;pd.concat&lt;/code&gt; function allows a wide range of possible behaviors when joining two datasets; keep these in mind as you use these tools for your own data.&lt;/p&gt;

&lt;h3 id=&#34;the-append-method&#34;&gt;The &lt;code&gt;append()&lt;/code&gt; method&lt;/h3&gt;

&lt;p&gt;Because direct array concatenation is so common, &lt;code&gt;Series&lt;/code&gt; and &lt;code&gt;DataFrame&lt;/code&gt; objects have an &lt;code&gt;append&lt;/code&gt; method that can accomplish the same thing in fewer keystrokes.
For example, rather than calling &lt;code&gt;pd.concat([df1, df2])&lt;/code&gt;, you can simply call &lt;code&gt;df1.append(df2)&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;display(&#39;df1&#39;, &#39;df2&#39;, &#39;df1.append(df2)&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df1&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;A2&lt;/td&gt;
      &lt;td&gt;B2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df2&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;A3&lt;/td&gt;
      &lt;td&gt;B3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;A4&lt;/td&gt;
      &lt;td&gt;B4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df1.append(df2)&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;A1&lt;/td&gt;
      &lt;td&gt;B1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;A2&lt;/td&gt;
      &lt;td&gt;B2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;A3&lt;/td&gt;
      &lt;td&gt;B3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;A4&lt;/td&gt;
      &lt;td&gt;B4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;Keep in mind that unlike the &lt;code&gt;append()&lt;/code&gt; and &lt;code&gt;extend()&lt;/code&gt; methods of Python lists, the &lt;code&gt;append()&lt;/code&gt; method in Pandas does not modify the original object–instead it creates a new object with the combined data.
It also is not a very efficient method, because it involves creation of a new index &lt;em&gt;and&lt;/em&gt; data buffer.
Thus, if you plan to do multiple &lt;code&gt;append&lt;/code&gt; operations, it is generally better to build a list of &lt;code&gt;DataFrame&lt;/code&gt;s and pass them all at once to the &lt;code&gt;concat()&lt;/code&gt; function.&lt;/p&gt;

&lt;p&gt;In the next section, we&amp;rsquo;ll look at another more powerful approach to combining data from multiple sources, the database-style merges/joins implemented in &lt;code&gt;pd.merge&lt;/code&gt;.
For more information on &lt;code&gt;concat()&lt;/code&gt;, &lt;code&gt;append()&lt;/code&gt;, and related functionality, see the &lt;a href=&#34;http://pandas.pydata.org/pandas-docs/stable/merging.html&#34; target=&#34;_blank&#34;&gt;&amp;laquo;Merge, Join, and Concatenate&amp;raquo; section&lt;/a&gt; of the Pandas documentation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Combining Datasets - Merge and Join</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.07-merge-and-join/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.07-merge-and-join/</guid>
      <description>

&lt;p&gt;One essential feature offered by Pandas is its high-performance, in-memory join and merge operations.
If you have ever worked with databases, you should be familiar with this type of data interaction.
The main interface for this is the &lt;code&gt;pd.merge&lt;/code&gt; function, and we&amp;rsquo;ll see few examples of how this can work in practice.&lt;/p&gt;

&lt;p&gt;For convenience, we will start by redefining the &lt;code&gt;display()&lt;/code&gt; functionality from the previous section:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
import numpy as np

class display(object):
    &amp;quot;&amp;quot;&amp;quot;Display HTML representation of multiple objects&amp;quot;&amp;quot;&amp;quot;
    template = &amp;quot;&amp;quot;&amp;quot;&amp;lt;div style=&amp;quot;float: left; padding: 10px;&amp;quot;&amp;gt;
    &amp;lt;p style=&#39;font-family:&amp;quot;Courier New&amp;quot;, Courier, monospace&#39;&amp;gt;{0}&amp;lt;/p&amp;gt;{1}
    &amp;lt;/div&amp;gt;&amp;quot;&amp;quot;&amp;quot;
    def __init__(self, *args):
        self.args = args
        
    def _repr_html_(self):
        return &#39;\n&#39;.join(self.template.format(a, eval(a)._repr_html_())
                         for a in self.args)
    
    def __repr__(self):
        return &#39;\n\n&#39;.join(a + &#39;\n&#39; + repr(eval(a))
                           for a in self.args)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;relational-algebra&#34;&gt;Relational Algebra&lt;/h2&gt;

&lt;p&gt;The behavior implemented in &lt;code&gt;pd.merge()&lt;/code&gt; is a subset of what is known as &lt;em&gt;relational algebra&lt;/em&gt;, which is a formal set of rules for manipulating relational data, and forms the conceptual foundation of operations available in most databases.
The strength of the relational algebra approach is that it proposes several primitive operations, which become the building blocks of more complicated operations on any dataset.
With this lexicon of fundamental operations implemented efficiently in a database or other program, a wide range of fairly complicated composite operations can be performed.&lt;/p&gt;

&lt;p&gt;Pandas implements several of these fundamental building-blocks in the &lt;code&gt;pd.merge()&lt;/code&gt; function and the related &lt;code&gt;join()&lt;/code&gt; method of &lt;code&gt;Series&lt;/code&gt; and &lt;code&gt;Dataframe&lt;/code&gt;s.
As we will see, these let you efficiently link data from different sources.&lt;/p&gt;

&lt;h2 id=&#34;categories-of-joins&#34;&gt;Categories of Joins&lt;/h2&gt;

&lt;p&gt;The &lt;code&gt;pd.merge()&lt;/code&gt; function implements a number of types of joins: the &lt;em&gt;one-to-one&lt;/em&gt;, &lt;em&gt;many-to-one&lt;/em&gt;, and &lt;em&gt;many-to-many&lt;/em&gt; joins.
All three types of joins are accessed via an identical call to the &lt;code&gt;pd.merge()&lt;/code&gt; interface; the type of join performed depends on the form of the input data.
Here we will show simple examples of the three types of merges, and discuss detailed options further below.&lt;/p&gt;

&lt;h3 id=&#34;one-to-one-joins&#34;&gt;One-to-one joins&lt;/h3&gt;

&lt;p&gt;Perhaps the simplest type of merge expresion is the one-to-one join, which is in many ways very similar to the column-wise concatenation seen in &lt;a href=&#34;03.06-Concat-And-Append.ipynb&#34; target=&#34;_blank&#34;&gt;Combining Datasets: Concat &amp;amp; Append&lt;/a&gt;.
As a concrete example, consider the following two &lt;code&gt;DataFrames&lt;/code&gt; which contain information on several employees in a company:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df1 = pd.DataFrame({&#39;employee&#39;: [&#39;Bob&#39;, &#39;Jake&#39;, &#39;Lisa&#39;, &#39;Sue&#39;],
                    &#39;group&#39;: [&#39;Accounting&#39;, &#39;Engineering&#39;, &#39;Engineering&#39;, &#39;HR&#39;]})
df2 = pd.DataFrame({&#39;employee&#39;: [&#39;Lisa&#39;, &#39;Bob&#39;, &#39;Jake&#39;, &#39;Sue&#39;],
                    &#39;hire_date&#39;: [2004, 2008, 2012, 2014]})
display(&#39;df1&#39;, &#39;df2&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df1&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;HR&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df2&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;hire_date&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;2004&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;2008&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;2014&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;To combine this information into a single &lt;code&gt;DataFrame&lt;/code&gt;, we can use the &lt;code&gt;pd.merge()&lt;/code&gt; function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df3 = pd.merge(df1, df2)
df3
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
      &lt;th&gt;hire_date&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
      &lt;td&gt;2008&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;2004&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;HR&lt;/td&gt;
      &lt;td&gt;2014&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;pd.merge()&lt;/code&gt; function recognizes that each &lt;code&gt;DataFrame&lt;/code&gt; has an &amp;laquo;employee&amp;raquo; column, and automatically joins using this column as a key.
The result of the merge is a new &lt;code&gt;DataFrame&lt;/code&gt; that combines the information from the two inputs.
Notice that the order of entries in each column is not necessarily maintained: in this case, the order of the &amp;laquo;employee&amp;raquo; column differs between &lt;code&gt;df1&lt;/code&gt; and &lt;code&gt;df2&lt;/code&gt;, and the &lt;code&gt;pd.merge()&lt;/code&gt; function correctly accounts for this.
Additionally, keep in mind that the merge in general discards the index, except in the special case of merges by index (see the &lt;code&gt;left_index&lt;/code&gt; and &lt;code&gt;right_index&lt;/code&gt; keywords, discussed momentarily).&lt;/p&gt;

&lt;h3 id=&#34;many-to-one-joins&#34;&gt;Many-to-one joins&lt;/h3&gt;

&lt;p&gt;Many-to-one joins are joins in which one of the two key columns contains duplicate entries.
For the many-to-one case, the resulting &lt;code&gt;DataFrame&lt;/code&gt; will preserve those duplicate entries as appropriate.
Consider the following example of a many-to-one join:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df4 = pd.DataFrame({&#39;group&#39;: [&#39;Accounting&#39;, &#39;Engineering&#39;, &#39;HR&#39;],
                    &#39;supervisor&#39;: [&#39;Carly&#39;, &#39;Guido&#39;, &#39;Steve&#39;]})
display(&#39;df3&#39;, &#39;df4&#39;, &#39;pd.merge(df3, df4)&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df3&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
      &lt;th&gt;hire_date&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
      &lt;td&gt;2008&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;2004&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;HR&lt;/td&gt;
      &lt;td&gt;2014&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df4&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
      &lt;th&gt;supervisor&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
      &lt;td&gt;Carly&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;Guido&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;HR&lt;/td&gt;
      &lt;td&gt;Steve&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.merge(df3, df4)&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
      &lt;th&gt;hire_date&lt;/th&gt;
      &lt;th&gt;supervisor&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
      &lt;td&gt;2008&lt;/td&gt;
      &lt;td&gt;Carly&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;Guido&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;2004&lt;/td&gt;
      &lt;td&gt;Guido&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;HR&lt;/td&gt;
      &lt;td&gt;2014&lt;/td&gt;
      &lt;td&gt;Steve&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;The resulting &lt;code&gt;DataFrame&lt;/code&gt; has an aditional column with the &amp;laquo;supervisor&amp;raquo; information, where the information is repeated in one or more locations as required by the inputs.&lt;/p&gt;

&lt;h3 id=&#34;many-to-many-joins&#34;&gt;Many-to-many joins&lt;/h3&gt;

&lt;p&gt;Many-to-many joins are a bit confusing conceptually, but are nevertheless well defined.
If the key column in both the left and right array contains duplicates, then the result is a many-to-many merge.
This will be perhaps most clear with a concrete example.
Consider the following, where we have a &lt;code&gt;DataFrame&lt;/code&gt; showing one or more skills associated with a particular group.
By performing a many-to-many join, we can recover the skills associated with any individual person:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df5 = pd.DataFrame({&#39;group&#39;: [&#39;Accounting&#39;, &#39;Accounting&#39;,
                              &#39;Engineering&#39;, &#39;Engineering&#39;, &#39;HR&#39;, &#39;HR&#39;],
                    &#39;skills&#39;: [&#39;math&#39;, &#39;spreadsheets&#39;, &#39;coding&#39;, &#39;linux&#39;,
                               &#39;spreadsheets&#39;, &#39;organization&#39;]})
display(&#39;df1&#39;, &#39;df5&#39;, &amp;quot;pd.merge(df1, df5)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df1&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;HR&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df5&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
      &lt;th&gt;skills&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
      &lt;td&gt;math&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
      &lt;td&gt;spreadsheets&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;coding&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;linux&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;HR&lt;/td&gt;
      &lt;td&gt;spreadsheets&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;HR&lt;/td&gt;
      &lt;td&gt;organization&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.merge(df1, df5)&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
      &lt;th&gt;skills&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
      &lt;td&gt;math&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
      &lt;td&gt;spreadsheets&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;coding&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;linux&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;coding&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;linux&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;HR&lt;/td&gt;
      &lt;td&gt;spreadsheets&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;HR&lt;/td&gt;
      &lt;td&gt;organization&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;These three types of joins can be used with other Pandas tools to implement a wide array of functionality.
But in practice, datasets are rarely as clean as the one we&amp;rsquo;re working with here.
In the following section we&amp;rsquo;ll consider some of the options provided by &lt;code&gt;pd.merge()&lt;/code&gt; that enable you to tune how the join operations work.&lt;/p&gt;

&lt;h2 id=&#34;specification-of-the-merge-key&#34;&gt;Specification of the Merge Key&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ve already seen the default behavior of &lt;code&gt;pd.merge()&lt;/code&gt;: it looks for one or more matching column names between the two inputs, and uses this as the key.
However, often the column names will not match so nicely, and &lt;code&gt;pd.merge()&lt;/code&gt; provides a variety of options for handling this.&lt;/p&gt;

&lt;h3 id=&#34;the-on-keyword&#34;&gt;The &lt;code&gt;on&lt;/code&gt; keyword&lt;/h3&gt;

&lt;p&gt;Most simply, you can explicitly specify the name of the key column using the &lt;code&gt;on&lt;/code&gt; keyword, which takes a column name or a list of column names:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;display(&#39;df1&#39;, &#39;df2&#39;, &amp;quot;pd.merge(df1, df2, on=&#39;employee&#39;)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df1&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;HR&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df2&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;hire_date&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;2004&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;2008&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;2014&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.merge(df1, df2, on=&#39;employee&#39;)&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
      &lt;th&gt;hire_date&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
      &lt;td&gt;2008&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;2004&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;HR&lt;/td&gt;
      &lt;td&gt;2014&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;This option works only if both the left and right &lt;code&gt;DataFrame&lt;/code&gt;s have the specified column name.&lt;/p&gt;

&lt;h3 id=&#34;the-left-on-and-right-on-keywords&#34;&gt;The &lt;code&gt;left_on&lt;/code&gt; and &lt;code&gt;right_on&lt;/code&gt; keywords&lt;/h3&gt;

&lt;p&gt;At times you may wish to merge two datasets with different column names; for example, we may have a dataset in which the employee name is labeled as &amp;laquo;name&amp;raquo; rather than &amp;laquo;employee&amp;raquo;.
In this case, we can use the &lt;code&gt;left_on&lt;/code&gt; and &lt;code&gt;right_on&lt;/code&gt; keywords to specify the two column names:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df3 = pd.DataFrame({&#39;name&#39;: [&#39;Bob&#39;, &#39;Jake&#39;, &#39;Lisa&#39;, &#39;Sue&#39;],
                    &#39;salary&#39;: [70000, 80000, 120000, 90000]})
display(&#39;df1&#39;, &#39;df3&#39;, &#39;pd.merge(df1, df3, left_on=&amp;quot;employee&amp;quot;, right_on=&amp;quot;name&amp;quot;)&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df1&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;HR&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df3&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;salary&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;70000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;80000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;120000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;90000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.merge(df1, df3, left_on=&#34;employee&#34;, right_on=&#34;name&#34;)&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;salary&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;70000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;80000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;120000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;HR&lt;/td&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;90000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;The result has a redundant column that we can drop if desired–for example, by using the &lt;code&gt;drop()&lt;/code&gt; method of &lt;code&gt;DataFrame&lt;/code&gt;s:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.merge(df1, df3, left_on=&amp;quot;employee&amp;quot;, right_on=&amp;quot;name&amp;quot;).drop(&#39;name&#39;, axis=1)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
      &lt;th&gt;salary&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
      &lt;td&gt;70000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;80000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;120000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;HR&lt;/td&gt;
      &lt;td&gt;90000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&#34;the-left-index-and-right-index-keywords&#34;&gt;The &lt;code&gt;left_index&lt;/code&gt; and &lt;code&gt;right_index&lt;/code&gt; keywords&lt;/h3&gt;

&lt;p&gt;Sometimes, rather than merging on a column, you would instead like to merge on an index.
For example, your data might look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df1a = df1.set_index(&#39;employee&#39;)
df2a = df2.set_index(&#39;employee&#39;)
display(&#39;df1a&#39;, &#39;df2a&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df1a&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Bob&lt;/th&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Jake&lt;/th&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Lisa&lt;/th&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Sue&lt;/th&gt;
      &lt;td&gt;HR&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df2a&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;hire_date&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Lisa&lt;/th&gt;
      &lt;td&gt;2004&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Bob&lt;/th&gt;
      &lt;td&gt;2008&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Jake&lt;/th&gt;
      &lt;td&gt;2012&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Sue&lt;/th&gt;
      &lt;td&gt;2014&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;You can use the index as the key for merging by specifying the &lt;code&gt;left_index&lt;/code&gt; and/or &lt;code&gt;right_index&lt;/code&gt; flags in &lt;code&gt;pd.merge()&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;display(&#39;df1a&#39;, &#39;df2a&#39;,
        &amp;quot;pd.merge(df1a, df2a, left_index=True, right_index=True)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df1a&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Bob&lt;/th&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Jake&lt;/th&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Lisa&lt;/th&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Sue&lt;/th&gt;
      &lt;td&gt;HR&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df2a&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;hire_date&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Lisa&lt;/th&gt;
      &lt;td&gt;2004&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Bob&lt;/th&gt;
      &lt;td&gt;2008&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Jake&lt;/th&gt;
      &lt;td&gt;2012&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Sue&lt;/th&gt;
      &lt;td&gt;2014&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.merge(df1a, df2a, left_index=True, right_index=True)&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
      &lt;th&gt;hire_date&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Lisa&lt;/th&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;2004&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Bob&lt;/th&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
      &lt;td&gt;2008&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Jake&lt;/th&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Sue&lt;/th&gt;
      &lt;td&gt;HR&lt;/td&gt;
      &lt;td&gt;2014&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;For convenience, &lt;code&gt;DataFrame&lt;/code&gt;s implement the &lt;code&gt;join()&lt;/code&gt; method, which performs a merge that defaults to joining on indices:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;display(&#39;df1a&#39;, &#39;df2a&#39;, &#39;df1a.join(df2a)&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df1a&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Bob&lt;/th&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Jake&lt;/th&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Lisa&lt;/th&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Sue&lt;/th&gt;
      &lt;td&gt;HR&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df2a&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;hire_date&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Lisa&lt;/th&gt;
      &lt;td&gt;2004&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Bob&lt;/th&gt;
      &lt;td&gt;2008&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Jake&lt;/th&gt;
      &lt;td&gt;2012&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Sue&lt;/th&gt;
      &lt;td&gt;2014&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df1a.join(df2a)&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
      &lt;th&gt;hire_date&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Bob&lt;/th&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
      &lt;td&gt;2008&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Jake&lt;/th&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Lisa&lt;/th&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;2004&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Sue&lt;/th&gt;
      &lt;td&gt;HR&lt;/td&gt;
      &lt;td&gt;2014&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;If you&amp;rsquo;d like to mix indices and columns, you can combine &lt;code&gt;left_index&lt;/code&gt; with &lt;code&gt;right_on&lt;/code&gt; or &lt;code&gt;left_on&lt;/code&gt; with &lt;code&gt;right_index&lt;/code&gt; to get the desired behavior:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;display(&#39;df1a&#39;, &#39;df3&#39;, &amp;quot;pd.merge(df1a, df3, left_index=True, right_on=&#39;name&#39;)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df1a&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;employee&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Bob&lt;/th&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Jake&lt;/th&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Lisa&lt;/th&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Sue&lt;/th&gt;
      &lt;td&gt;HR&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df3&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;salary&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;70000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;80000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;120000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;90000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.merge(df1a, df3, left_index=True, right_on=&#39;name&#39;)&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;group&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;salary&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Accounting&lt;/td&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;70000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;80000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Engineering&lt;/td&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;120000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;HR&lt;/td&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;90000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;All of these options also work with multiple indices and/or multiple columns; the interface for this behavior is very intuitive.
For more information on this, see the &lt;a href=&#34;http://pandas.pydata.org/pandas-docs/stable/merging.html&#34; target=&#34;_blank&#34;&gt;&amp;laquo;Merge, Join, and Concatenate&amp;raquo; section&lt;/a&gt; of the Pandas documentation.&lt;/p&gt;

&lt;h2 id=&#34;specifying-set-arithmetic-for-joins&#34;&gt;Specifying Set Arithmetic for Joins&lt;/h2&gt;

&lt;p&gt;In all the preceding examples we have glossed over one important consideration in performing a join: the type of set arithmetic used in the join.
This comes up when a value appears in one key column but not the other. Consider this example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df6 = pd.DataFrame({&#39;name&#39;: [&#39;Peter&#39;, &#39;Paul&#39;, &#39;Mary&#39;],
                    &#39;food&#39;: [&#39;fish&#39;, &#39;beans&#39;, &#39;bread&#39;]},
                   columns=[&#39;name&#39;, &#39;food&#39;])
df7 = pd.DataFrame({&#39;name&#39;: [&#39;Mary&#39;, &#39;Joseph&#39;],
                    &#39;drink&#39;: [&#39;wine&#39;, &#39;beer&#39;]},
                   columns=[&#39;name&#39;, &#39;drink&#39;])
display(&#39;df6&#39;, &#39;df7&#39;, &#39;pd.merge(df6, df7)&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df6&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;food&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Peter&lt;/td&gt;
      &lt;td&gt;fish&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Paul&lt;/td&gt;
      &lt;td&gt;beans&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Mary&lt;/td&gt;
      &lt;td&gt;bread&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df7&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;drink&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Mary&lt;/td&gt;
      &lt;td&gt;wine&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Joseph&lt;/td&gt;
      &lt;td&gt;beer&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.merge(df6, df7)&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;food&lt;/th&gt;
      &lt;th&gt;drink&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Mary&lt;/td&gt;
      &lt;td&gt;bread&lt;/td&gt;
      &lt;td&gt;wine&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;Here we have merged two datasets that have only a single &amp;laquo;name&amp;raquo; entry in common: Mary.
By default, the result contains the &lt;em&gt;intersection&lt;/em&gt; of the two sets of inputs; this is what is known as an &lt;em&gt;inner join&lt;/em&gt;.
We can specify this explicitly using the &lt;code&gt;how&lt;/code&gt; keyword, which defaults to &lt;code&gt;&amp;quot;inner&amp;quot;&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.merge(df6, df7, how=&#39;inner&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;food&lt;/th&gt;
      &lt;th&gt;drink&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Mary&lt;/td&gt;
      &lt;td&gt;bread&lt;/td&gt;
      &lt;td&gt;wine&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Other options for the &lt;code&gt;how&lt;/code&gt; keyword are &lt;code&gt;&#39;outer&#39;&lt;/code&gt;, &lt;code&gt;&#39;left&#39;&lt;/code&gt;, and &lt;code&gt;&#39;right&#39;&lt;/code&gt;.
An &lt;em&gt;outer join&lt;/em&gt; returns a join over the union of the input columns, and fills in all missing values with NAs:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;display(&#39;df6&#39;, &#39;df7&#39;, &amp;quot;pd.merge(df6, df7, how=&#39;outer&#39;)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df6&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;food&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Peter&lt;/td&gt;
      &lt;td&gt;fish&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Paul&lt;/td&gt;
      &lt;td&gt;beans&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Mary&lt;/td&gt;
      &lt;td&gt;bread&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df7&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;drink&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Mary&lt;/td&gt;
      &lt;td&gt;wine&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Joseph&lt;/td&gt;
      &lt;td&gt;beer&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.merge(df6, df7, how=&#39;outer&#39;)&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;food&lt;/th&gt;
      &lt;th&gt;drink&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Peter&lt;/td&gt;
      &lt;td&gt;fish&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Paul&lt;/td&gt;
      &lt;td&gt;beans&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Mary&lt;/td&gt;
      &lt;td&gt;bread&lt;/td&gt;
      &lt;td&gt;wine&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Joseph&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;beer&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;The &lt;em&gt;left join&lt;/em&gt; and &lt;em&gt;right join&lt;/em&gt; return joins over the left entries and right entries, respectively.
For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;display(&#39;df6&#39;, &#39;df7&#39;, &amp;quot;pd.merge(df6, df7, how=&#39;left&#39;)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df6&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;food&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Peter&lt;/td&gt;
      &lt;td&gt;fish&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Paul&lt;/td&gt;
      &lt;td&gt;beans&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Mary&lt;/td&gt;
      &lt;td&gt;bread&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df7&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;drink&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Mary&lt;/td&gt;
      &lt;td&gt;wine&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Joseph&lt;/td&gt;
      &lt;td&gt;beer&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.merge(df6, df7, how=&#39;left&#39;)&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;food&lt;/th&gt;
      &lt;th&gt;drink&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Peter&lt;/td&gt;
      &lt;td&gt;fish&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Paul&lt;/td&gt;
      &lt;td&gt;beans&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Mary&lt;/td&gt;
      &lt;td&gt;bread&lt;/td&gt;
      &lt;td&gt;wine&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;The output rows now correspond to the entries in the left input. Using
&lt;code&gt;how=&#39;right&#39;&lt;/code&gt; works in a similar manner.&lt;/p&gt;

&lt;p&gt;All of these options can be applied straightforwardly to any of the preceding join types.&lt;/p&gt;

&lt;h2 id=&#34;overlapping-column-names-the-suffixes-keyword&#34;&gt;Overlapping Column Names: The &lt;code&gt;suffixes&lt;/code&gt; Keyword&lt;/h2&gt;

&lt;p&gt;Finally, you may end up in a case where your two input &lt;code&gt;DataFrame&lt;/code&gt;s have conflicting column names.
Consider this example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df8 = pd.DataFrame({&#39;name&#39;: [&#39;Bob&#39;, &#39;Jake&#39;, &#39;Lisa&#39;, &#39;Sue&#39;],
                    &#39;rank&#39;: [1, 2, 3, 4]})
df9 = pd.DataFrame({&#39;name&#39;: [&#39;Bob&#39;, &#39;Jake&#39;, &#39;Lisa&#39;, &#39;Sue&#39;],
                    &#39;rank&#39;: [3, 1, 4, 2]})
display(&#39;df8&#39;, &#39;df9&#39;, &#39;pd.merge(df8, df9, on=&amp;quot;name&amp;quot;)&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df8&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;rank&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df9&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;rank&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.merge(df8, df9, on=&#34;name&#34;)&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;rank_x&lt;/th&gt;
      &lt;th&gt;rank_y&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;Because the output would have two conflicting column names, the merge function automatically appends a suffix &lt;code&gt;_x&lt;/code&gt; or &lt;code&gt;_y&lt;/code&gt; to make the output columns unique.
If these defaults are inappropriate, it is possible to specify a custom suffix using the &lt;code&gt;suffixes&lt;/code&gt; keyword:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;display(&#39;df8&#39;, &#39;df9&#39;, &#39;pd.merge(df8, df9, on=&amp;quot;name&amp;quot;, suffixes=[&amp;quot;_L&amp;quot;, &amp;quot;_R&amp;quot;])&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df8&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;rank&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df9&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;rank&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pd.merge(df8, df9, on=&#34;name&#34;, suffixes=[&#34;_L&#34;, &#34;_R&#34;])&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;rank_L&lt;/th&gt;
      &lt;th&gt;rank_R&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Jake&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Lisa&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Sue&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;These suffixes work in any of the possible join patterns, and work also if there are multiple overlapping columns.&lt;/p&gt;

&lt;p&gt;For more information on these patterns, see &lt;a href=&#34;03.08-Aggregation-and-Grouping.ipynb&#34; target=&#34;_blank&#34;&gt;Aggregation and Grouping&lt;/a&gt; where we dive a bit deeper into relational algebra.
Also see the &lt;a href=&#34;http://pandas.pydata.org/pandas-docs/stable/merging.html&#34; target=&#34;_blank&#34;&gt;Pandas &amp;laquo;Merge, Join and Concatenate&amp;raquo; documentation&lt;/a&gt; for further discussion of these topics.&lt;/p&gt;

&lt;h2 id=&#34;example-us-states-data&#34;&gt;Example: US States Data&lt;/h2&gt;

&lt;p&gt;Merge and join operations come up most often when combining data from different sources.
Here we will consider an example of some data about US states and their populations.
The data files can be found at &lt;a href=&#34;http://github.com/jakevdp/data-USstates/:&#34; target=&#34;_blank&#34;&gt;http://github.com/jakevdp/data-USstates/:&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Following are shell commands to download the data
# !curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-population.csv
# !curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-areas.csv
# !curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-abbrevs.csv
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s take a look at the three datasets, using the Pandas &lt;code&gt;read_csv()&lt;/code&gt; function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pop = pd.read_csv(&#39;data/state-population.csv&#39;)
areas = pd.read_csv(&#39;data/state-areas.csv&#39;)
abbrevs = pd.read_csv(&#39;data/state-abbrevs.csv&#39;)

display(&#39;pop.head()&#39;, &#39;areas.head()&#39;, &#39;abbrevs.head()&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;pop.head()&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;state/region&lt;/th&gt;
      &lt;th&gt;ages&lt;/th&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;population&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;under18&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;1117489.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;4817528.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;under18&lt;/td&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;1130966.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;4785570.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;under18&lt;/td&gt;
      &lt;td&gt;2011&lt;/td&gt;
      &lt;td&gt;1125763.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;areas.head()&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;state&lt;/th&gt;
      &lt;th&gt;area (sq. mi)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;52423&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Alaska&lt;/td&gt;
      &lt;td&gt;656425&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Arizona&lt;/td&gt;
      &lt;td&gt;114006&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Arkansas&lt;/td&gt;
      &lt;td&gt;53182&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;California&lt;/td&gt;
      &lt;td&gt;163707&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;abbrevs.head()&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;state&lt;/th&gt;
      &lt;th&gt;abbreviation&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;AL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Alaska&lt;/td&gt;
      &lt;td&gt;AK&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Arizona&lt;/td&gt;
      &lt;td&gt;AZ&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Arkansas&lt;/td&gt;
      &lt;td&gt;AR&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;California&lt;/td&gt;
      &lt;td&gt;CA&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;Given this information, say we want to compute a relatively straightforward result: rank US states and territories by their 2010 population density.
We clearly have the data here to find this result, but we&amp;rsquo;ll have to combine the datasets to find the result.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll start with a many-to-one merge that will give us the full state name within the population &lt;code&gt;DataFrame&lt;/code&gt;.
We want to merge based on the &lt;code&gt;state/region&lt;/code&gt;  column of &lt;code&gt;pop&lt;/code&gt;, and the &lt;code&gt;abbreviation&lt;/code&gt; column of &lt;code&gt;abbrevs&lt;/code&gt;.
We&amp;rsquo;ll use &lt;code&gt;how=&#39;outer&#39;&lt;/code&gt; to make sure no data is thrown away due to mismatched labels.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;merged = pd.merge(pop, abbrevs, how=&#39;outer&#39;,
                  left_on=&#39;state/region&#39;, right_on=&#39;abbreviation&#39;)
merged = merged.drop(&#39;abbreviation&#39;, 1) # drop duplicate info
merged.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;state/region&lt;/th&gt;
      &lt;th&gt;ages&lt;/th&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;population&lt;/th&gt;
      &lt;th&gt;state&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;under18&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;1117489.0&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;4817528.0&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;under18&lt;/td&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;1130966.0&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;4785570.0&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;under18&lt;/td&gt;
      &lt;td&gt;2011&lt;/td&gt;
      &lt;td&gt;1125763.0&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Let&amp;rsquo;s double-check whether there were any mismatches here, which we can do by looking for rows with nulls:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;merged.isnull().any()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;state/region    False
ages            False
year            False
population       True
state            True
dtype: bool
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Some of the &lt;code&gt;population&lt;/code&gt; info is null; let&amp;rsquo;s figure out which these are!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;merged[merged[&#39;population&#39;].isnull()].head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;state/region&lt;/th&gt;
      &lt;th&gt;ages&lt;/th&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;population&lt;/th&gt;
      &lt;th&gt;state&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2448&lt;/th&gt;
      &lt;td&gt;PR&lt;/td&gt;
      &lt;td&gt;under18&lt;/td&gt;
      &lt;td&gt;1990&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2449&lt;/th&gt;
      &lt;td&gt;PR&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td&gt;1990&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2450&lt;/th&gt;
      &lt;td&gt;PR&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td&gt;1991&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2451&lt;/th&gt;
      &lt;td&gt;PR&lt;/td&gt;
      &lt;td&gt;under18&lt;/td&gt;
      &lt;td&gt;1991&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2452&lt;/th&gt;
      &lt;td&gt;PR&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td&gt;1993&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;It appears that all the null population values are from Puerto Rico prior to the year 2000; this is likely due to this data not being available from the original source.&lt;/p&gt;

&lt;p&gt;More importantly, we see also that some of the new &lt;code&gt;state&lt;/code&gt; entries are also null, which means that there was no corresponding entry in the &lt;code&gt;abbrevs&lt;/code&gt; key!
Let&amp;rsquo;s figure out which regions lack this match:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;merged.loc[merged[&#39;state&#39;].isnull(), &#39;state/region&#39;].unique()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([&#39;PR&#39;, &#39;USA&#39;], dtype=object)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can quickly infer the issue: our population data includes entries for Puerto Rico (PR) and the United States as a whole (USA), while these entries do not appear in the state abbreviation key.
We can fix these quickly by filling in appropriate entries:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;merged.loc[merged[&#39;state/region&#39;] == &#39;PR&#39;, &#39;state&#39;] = &#39;Puerto Rico&#39;
merged.loc[merged[&#39;state/region&#39;] == &#39;USA&#39;, &#39;state&#39;] = &#39;United States&#39;
merged.isnull().any()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;state/region    False
ages            False
year            False
population       True
state           False
dtype: bool
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;No more nulls in the &lt;code&gt;state&lt;/code&gt; column: we&amp;rsquo;re all set!&lt;/p&gt;

&lt;p&gt;Now we can merge the result with the area data using a similar procedure.
Examining our results, we will want to join on the &lt;code&gt;state&lt;/code&gt; column in both:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;final = pd.merge(merged, areas, on=&#39;state&#39;, how=&#39;left&#39;)
final.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;state/region&lt;/th&gt;
      &lt;th&gt;ages&lt;/th&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;population&lt;/th&gt;
      &lt;th&gt;state&lt;/th&gt;
      &lt;th&gt;area (sq. mi)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;under18&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;1117489.0&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;52423.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;4817528.0&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;52423.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;under18&lt;/td&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;1130966.0&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;52423.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;4785570.0&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;52423.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;under18&lt;/td&gt;
      &lt;td&gt;2011&lt;/td&gt;
      &lt;td&gt;1125763.0&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;52423.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Again, let&amp;rsquo;s check for nulls to see if there were any mismatches:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;final.isnull().any()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;state/region     False
ages             False
year             False
population        True
state            False
area (sq. mi)     True
dtype: bool
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are nulls in the &lt;code&gt;area&lt;/code&gt; column; we can take a look to see which regions were ignored here:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;final[&#39;state&#39;][final[&#39;area (sq. mi)&#39;].isnull()].unique()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([&#39;United States&#39;], dtype=object)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We see that our &lt;code&gt;areas&lt;/code&gt; &lt;code&gt;DataFrame&lt;/code&gt; does not contain the area of the United States as a whole.
We could insert the appropriate value (using the sum of all state areas, for instance), but in this case we&amp;rsquo;ll just drop the null values because the population density of the entire United States is not relevant to our current discussion:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;final.dropna(inplace=True)
final.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;state/region&lt;/th&gt;
      &lt;th&gt;ages&lt;/th&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;population&lt;/th&gt;
      &lt;th&gt;state&lt;/th&gt;
      &lt;th&gt;area (sq. mi)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;under18&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;1117489.0&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;52423.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;4817528.0&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;52423.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;under18&lt;/td&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;1130966.0&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;52423.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;4785570.0&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;52423.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;under18&lt;/td&gt;
      &lt;td&gt;2011&lt;/td&gt;
      &lt;td&gt;1125763.0&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;52423.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Now we have all the data we need. To answer the question of interest, let&amp;rsquo;s first select the portion of the data corresponding with the year 2000, and the total population.
We&amp;rsquo;ll use the &lt;code&gt;query()&lt;/code&gt; function to do this quickly (this requires the &lt;code&gt;numexpr&lt;/code&gt; package to be installed; see &lt;a href=&#34;03.12-Performance-Eval-and-Query.ipynb&#34; target=&#34;_blank&#34;&gt;High-Performance Pandas: &lt;code&gt;eval()&lt;/code&gt; and &lt;code&gt;query()&lt;/code&gt;&lt;/a&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data2010 = final.query(&amp;quot;year == 2010 &amp;amp; ages == &#39;total&#39;&amp;quot;)
data2010.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;state/region&lt;/th&gt;
      &lt;th&gt;ages&lt;/th&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;population&lt;/th&gt;
      &lt;th&gt;state&lt;/th&gt;
      &lt;th&gt;area (sq. mi)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;AL&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;4785570.0&lt;/td&gt;
      &lt;td&gt;Alabama&lt;/td&gt;
      &lt;td&gt;52423.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;91&lt;/th&gt;
      &lt;td&gt;AK&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;713868.0&lt;/td&gt;
      &lt;td&gt;Alaska&lt;/td&gt;
      &lt;td&gt;656425.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;101&lt;/th&gt;
      &lt;td&gt;AZ&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;6408790.0&lt;/td&gt;
      &lt;td&gt;Arizona&lt;/td&gt;
      &lt;td&gt;114006.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;189&lt;/th&gt;
      &lt;td&gt;AR&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;2922280.0&lt;/td&gt;
      &lt;td&gt;Arkansas&lt;/td&gt;
      &lt;td&gt;53182.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;197&lt;/th&gt;
      &lt;td&gt;CA&lt;/td&gt;
      &lt;td&gt;total&lt;/td&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;37333601.0&lt;/td&gt;
      &lt;td&gt;California&lt;/td&gt;
      &lt;td&gt;163707.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Now let&amp;rsquo;s compute the population density and display it in order.
We&amp;rsquo;ll start by re-indexing our data on the state, and then compute the result:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data2010.set_index(&#39;state&#39;, inplace=True)
density = data2010[&#39;population&#39;] / data2010[&#39;area (sq. mi)&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;density.sort_values(ascending=False, inplace=True)
density.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;state
District of Columbia    8898.897059
Puerto Rico             1058.665149
New Jersey              1009.253268
Rhode Island             681.339159
Connecticut              645.600649
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The result is a ranking of US states plus Washington, DC, and Puerto Rico in order of their 2010 population density, in residents per square mile.
We can see that by far the densest region in this dataset is Washington, DC (i.e., the District of Columbia); among states, the densest is New Jersey.&lt;/p&gt;

&lt;p&gt;We can also check the end of the list:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;density.tail()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;state
South Dakota    10.583512
North Dakota     9.537565
Montana          6.736171
Wyoming          5.768079
Alaska           1.087509
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We see that the least dense state, by far, is Alaska, averaging slightly over one resident per square mile.&lt;/p&gt;

&lt;p&gt;This type of messy data merging is a common task when trying to answer questions using real-world data sources.
I hope that this example has given you an idea of the ways you can combine tools we&amp;rsquo;ve covered in order to gain insight from your data!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Aggregation and Grouping</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.08-aggregation-and-grouping/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.08-aggregation-and-grouping/</guid>
      <description>

&lt;p&gt;An essential piece of analysis of large data is efficient summarization: computing aggregations like &lt;code&gt;sum()&lt;/code&gt;, &lt;code&gt;mean()&lt;/code&gt;, &lt;code&gt;median()&lt;/code&gt;, &lt;code&gt;min()&lt;/code&gt;, and &lt;code&gt;max()&lt;/code&gt;, in which a single number gives insight into the nature of a potentially large dataset.
In this section, we&amp;rsquo;ll explore aggregations in Pandas, from simple operations akin to what we&amp;rsquo;ve seen on NumPy arrays, to more sophisticated operations based on the concept of a &lt;code&gt;groupby&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;For convenience, we&amp;rsquo;ll use the same &lt;code&gt;display&lt;/code&gt; magic function that we&amp;rsquo;ve seen in previous sections:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
import pandas as pd

class display(object):
    &amp;quot;&amp;quot;&amp;quot;Display HTML representation of multiple objects&amp;quot;&amp;quot;&amp;quot;
    template = &amp;quot;&amp;quot;&amp;quot;&amp;lt;div style=&amp;quot;float: left; padding: 10px;&amp;quot;&amp;gt;
    &amp;lt;p style=&#39;font-family:&amp;quot;Courier New&amp;quot;, Courier, monospace&#39;&amp;gt;{0}&amp;lt;/p&amp;gt;{1}
    &amp;lt;/div&amp;gt;&amp;quot;&amp;quot;&amp;quot;
    def __init__(self, *args):
        self.args = args
        
    def _repr_html_(self):
        return &#39;\n&#39;.join(self.template.format(a, eval(a)._repr_html_())
                         for a in self.args)
    
    def __repr__(self):
        return &#39;\n\n&#39;.join(a + &#39;\n&#39; + repr(eval(a))
                           for a in self.args)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;planets-data&#34;&gt;Planets Data&lt;/h2&gt;

&lt;p&gt;Here we will use the Planets dataset, available via the &lt;a href=&#34;http://seaborn.pydata.org/&#34; target=&#34;_blank&#34;&gt;Seaborn package&lt;/a&gt; (see &lt;a href=&#34;04.14-Visualization-With-Seaborn.ipynb&#34; target=&#34;_blank&#34;&gt;Visualization With Seaborn&lt;/a&gt;).
It gives information on planets that astronomers have discovered around other stars (known as &lt;em&gt;extrasolar planets&lt;/em&gt; or &lt;em&gt;exoplanets&lt;/em&gt; for short). It can be downloaded with a simple Seaborn command:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import seaborn as sns
planets = sns.load_dataset(&#39;planets&#39;)
planets.shape
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(1035, 6)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;planets.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;method&lt;/th&gt;
      &lt;th&gt;number&lt;/th&gt;
      &lt;th&gt;orbital_period&lt;/th&gt;
      &lt;th&gt;mass&lt;/th&gt;
      &lt;th&gt;distance&lt;/th&gt;
      &lt;th&gt;year&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Radial Velocity&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;269.300&lt;/td&gt;
      &lt;td&gt;7.10&lt;/td&gt;
      &lt;td&gt;77.40&lt;/td&gt;
      &lt;td&gt;2006&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Radial Velocity&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;874.774&lt;/td&gt;
      &lt;td&gt;2.21&lt;/td&gt;
      &lt;td&gt;56.95&lt;/td&gt;
      &lt;td&gt;2008&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Radial Velocity&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;763.000&lt;/td&gt;
      &lt;td&gt;2.60&lt;/td&gt;
      &lt;td&gt;19.84&lt;/td&gt;
      &lt;td&gt;2011&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Radial Velocity&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;326.030&lt;/td&gt;
      &lt;td&gt;19.40&lt;/td&gt;
      &lt;td&gt;110.62&lt;/td&gt;
      &lt;td&gt;2007&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;Radial Velocity&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;516.220&lt;/td&gt;
      &lt;td&gt;10.50&lt;/td&gt;
      &lt;td&gt;119.47&lt;/td&gt;
      &lt;td&gt;2009&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;This has some details on the 1,000+ extrasolar planets discovered up to 2014.&lt;/p&gt;

&lt;h2 id=&#34;simple-aggregation-in-pandas&#34;&gt;Simple Aggregation in Pandas&lt;/h2&gt;

&lt;p&gt;Earlier, we explored some of the data aggregations available for NumPy arrays (&lt;a href=&#34;02.04-Computation-on-arrays-aggregates.ipynb&#34; target=&#34;_blank&#34;&gt;&amp;laquo;Aggregations: Min, Max, and Everything In Between&amp;raquo;&lt;/a&gt;).
As with a one-dimensional NumPy array, for a Pandas &lt;code&gt;Series&lt;/code&gt; the aggregates return a single value:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;rng = np.random.RandomState(42)
ser = pd.Series(rng.rand(5))
ser
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    0.374540
1    0.950714
2    0.731994
3    0.598658
4    0.156019
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ser.sum()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;2.8119254917081569
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ser.mean()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0.56238509834163142
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For a &lt;code&gt;DataFrame&lt;/code&gt;, by default the aggregates return results within each column:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df = pd.DataFrame({&#39;A&#39;: rng.rand(5),
                   &#39;B&#39;: rng.rand(5)})
df
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0.155995&lt;/td&gt;
      &lt;td&gt;0.020584&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;0.058084&lt;/td&gt;
      &lt;td&gt;0.969910&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;0.866176&lt;/td&gt;
      &lt;td&gt;0.832443&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;0.601115&lt;/td&gt;
      &lt;td&gt;0.212339&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;0.708073&lt;/td&gt;
      &lt;td&gt;0.181825&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.mean()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;A    0.477888
B    0.443420
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By specifying the &lt;code&gt;axis&lt;/code&gt; argument, you can instead aggregate within each row:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.mean(axis=&#39;columns&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    0.088290
1    0.513997
2    0.849309
3    0.406727
4    0.444949
dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Pandas &lt;code&gt;Series&lt;/code&gt; and &lt;code&gt;DataFrame&lt;/code&gt;s include all of the common aggregates mentioned in &lt;a href=&#34;02.04-Computation-on-arrays-aggregates.ipynb&#34; target=&#34;_blank&#34;&gt;Aggregations: Min, Max, and Everything In Between&lt;/a&gt;; in addition, there is a convenience method &lt;code&gt;describe()&lt;/code&gt; that computes several common aggregates for each column and returns the result.
Let&amp;rsquo;s use this on the Planets data, for now dropping rows with missing values:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;planets.dropna().describe()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;number&lt;/th&gt;
      &lt;th&gt;orbital_period&lt;/th&gt;
      &lt;th&gt;mass&lt;/th&gt;
      &lt;th&gt;distance&lt;/th&gt;
      &lt;th&gt;year&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;count&lt;/th&gt;
      &lt;td&gt;498.00000&lt;/td&gt;
      &lt;td&gt;498.000000&lt;/td&gt;
      &lt;td&gt;498.000000&lt;/td&gt;
      &lt;td&gt;498.000000&lt;/td&gt;
      &lt;td&gt;498.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;mean&lt;/th&gt;
      &lt;td&gt;1.73494&lt;/td&gt;
      &lt;td&gt;835.778671&lt;/td&gt;
      &lt;td&gt;2.509320&lt;/td&gt;
      &lt;td&gt;52.068213&lt;/td&gt;
      &lt;td&gt;2007.377510&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;std&lt;/th&gt;
      &lt;td&gt;1.17572&lt;/td&gt;
      &lt;td&gt;1469.128259&lt;/td&gt;
      &lt;td&gt;3.636274&lt;/td&gt;
      &lt;td&gt;46.596041&lt;/td&gt;
      &lt;td&gt;4.167284&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;min&lt;/th&gt;
      &lt;td&gt;1.00000&lt;/td&gt;
      &lt;td&gt;1.328300&lt;/td&gt;
      &lt;td&gt;0.003600&lt;/td&gt;
      &lt;td&gt;1.350000&lt;/td&gt;
      &lt;td&gt;1989.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;25%&lt;/th&gt;
      &lt;td&gt;1.00000&lt;/td&gt;
      &lt;td&gt;38.272250&lt;/td&gt;
      &lt;td&gt;0.212500&lt;/td&gt;
      &lt;td&gt;24.497500&lt;/td&gt;
      &lt;td&gt;2005.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;50%&lt;/th&gt;
      &lt;td&gt;1.00000&lt;/td&gt;
      &lt;td&gt;357.000000&lt;/td&gt;
      &lt;td&gt;1.245000&lt;/td&gt;
      &lt;td&gt;39.940000&lt;/td&gt;
      &lt;td&gt;2009.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;75%&lt;/th&gt;
      &lt;td&gt;2.00000&lt;/td&gt;
      &lt;td&gt;999.600000&lt;/td&gt;
      &lt;td&gt;2.867500&lt;/td&gt;
      &lt;td&gt;59.332500&lt;/td&gt;
      &lt;td&gt;2011.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;max&lt;/th&gt;
      &lt;td&gt;6.00000&lt;/td&gt;
      &lt;td&gt;17337.500000&lt;/td&gt;
      &lt;td&gt;25.000000&lt;/td&gt;
      &lt;td&gt;354.000000&lt;/td&gt;
      &lt;td&gt;2014.000000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;This can be a useful way to begin understanding the overall properties of a dataset.
For example, we see in the &lt;code&gt;year&lt;/code&gt; column that although exoplanets were discovered as far back as 1989, half of all known expolanets were not discovered until 2010 or after.
This is largely thanks to the &lt;em&gt;Kepler&lt;/em&gt; mission, which is a space-based telescope specifically designed for finding eclipsing planets around other stars.&lt;/p&gt;

&lt;p&gt;The following table summarizes some other built-in Pandas aggregations:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Aggregation&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;count()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Total number of items&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;first()&lt;/code&gt;, &lt;code&gt;last()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;First and last item&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;mean()&lt;/code&gt;, &lt;code&gt;median()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Mean and median&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;min()&lt;/code&gt;, &lt;code&gt;max()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Minimum and maximum&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;std()&lt;/code&gt;, &lt;code&gt;var()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Standard deviation and variance&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;mad()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Mean absolute deviation&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;prod()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Product of all items&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;sum()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Sum of all items&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;These are all methods of &lt;code&gt;DataFrame&lt;/code&gt; and &lt;code&gt;Series&lt;/code&gt; objects.&lt;/p&gt;

&lt;p&gt;To go deeper into the data, however, simple aggregates are often not enough.
The next level of data summarization is the &lt;code&gt;groupby&lt;/code&gt; operation, which allows you to quickly and efficiently compute aggregates on subsets of data.&lt;/p&gt;

&lt;h2 id=&#34;groupby-split-apply-combine&#34;&gt;GroupBy: Split, Apply, Combine&lt;/h2&gt;

&lt;p&gt;Simple aggregations can give you a flavor of your dataset, but often we would prefer to aggregate conditionally on some label or index: this is implemented in the so-called &lt;code&gt;groupby&lt;/code&gt; operation.
The name &amp;laquo;group by&amp;raquo; comes from a command in the SQL database language, but it is perhaps more illuminative to think of it in the terms first coined by Hadley Wickham of Rstats fame: &lt;em&gt;split, apply, combine&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&#34;split-apply-combine&#34;&gt;Split, apply, combine&lt;/h3&gt;

&lt;p&gt;A canonical example of this split-apply-combine operation, where the &amp;laquo;apply&amp;raquo; is a summation aggregation, is illustrated in this figure:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;figures/03.08-split-apply-combine.png&#34; alt=&#34;&#34; /&gt;
&lt;a href=&#34;06.00-Figure-Code.ipynb#Split-Apply-Combine&#34; target=&#34;_blank&#34;&gt;figure source in Appendix&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This makes clear what the &lt;code&gt;groupby&lt;/code&gt; accomplishes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;em&gt;split&lt;/em&gt; step involves breaking up and grouping a &lt;code&gt;DataFrame&lt;/code&gt; depending on the value of the specified key.&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;apply&lt;/em&gt; step involves computing some function, usually an aggregate, transformation, or filtering, within the individual groups.&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;combine&lt;/em&gt; step merges the results of these operations into an output array.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While this could certainly be done manually using some combination of the masking, aggregation, and merging commands covered earlier, an important realization is that &lt;em&gt;the intermediate splits do not need to be explicitly instantiated&lt;/em&gt;. Rather, the &lt;code&gt;GroupBy&lt;/code&gt; can (often) do this in a single pass over the data, updating the sum, mean, count, min, or other aggregate for each group along the way.
The power of the &lt;code&gt;GroupBy&lt;/code&gt; is that it abstracts away these steps: the user need not think about &lt;em&gt;how&lt;/em&gt; the computation is done under the hood, but rather thinks about the &lt;em&gt;operation as a whole&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;As a concrete example, let&amp;rsquo;s take a look at using Pandas for the computation shown in this diagram.
We&amp;rsquo;ll start by creating the input &lt;code&gt;DataFrame&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df = pd.DataFrame({&#39;key&#39;: [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;],
                   &#39;data&#39;: range(6)}, columns=[&#39;key&#39;, &#39;data&#39;])
df
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;data&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The most basic split-apply-combine operation can be computed with the &lt;code&gt;groupby()&lt;/code&gt; method of &lt;code&gt;DataFrame&lt;/code&gt;s, passing the name of the desired key column:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.groupby(&#39;key&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;pandas.core.groupby.DataFrameGroupBy object at 0x117272160&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice that what is returned is not a set of &lt;code&gt;DataFrame&lt;/code&gt;s, but a &lt;code&gt;DataFrameGroupBy&lt;/code&gt; object.
This object is where the magic is: you can think of it as a special view of the &lt;code&gt;DataFrame&lt;/code&gt;, which is poised to dig into the groups but does no actual computation until the aggregation is applied.
This &amp;laquo;lazy evaluation&amp;raquo; approach means that common aggregates can be implemented very efficiently in a way that is almost transparent to the user.&lt;/p&gt;

&lt;p&gt;To produce a result, we can apply an aggregate to this &lt;code&gt;DataFrameGroupBy&lt;/code&gt; object, which will perform the appropriate apply/combine steps to produce the desired result:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.groupby(&#39;key&#39;).sum()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;data&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;sum()&lt;/code&gt; method is just one possibility here; you can apply virtually any common Pandas or NumPy aggregation function, as well as virtually any valid &lt;code&gt;DataFrame&lt;/code&gt; operation, as we will see in the following discussion.&lt;/p&gt;

&lt;h3 id=&#34;the-groupby-object&#34;&gt;The GroupBy object&lt;/h3&gt;

&lt;p&gt;The &lt;code&gt;GroupBy&lt;/code&gt; object is a very flexible abstraction.
In many ways, you can simply treat it as if it&amp;rsquo;s a collection of &lt;code&gt;DataFrame&lt;/code&gt;s, and it does the difficult things under the hood. Let&amp;rsquo;s see some examples using the Planets data.&lt;/p&gt;

&lt;p&gt;Perhaps the most important operations made available by a &lt;code&gt;GroupBy&lt;/code&gt; are &lt;em&gt;aggregate&lt;/em&gt;, &lt;em&gt;filter&lt;/em&gt;, &lt;em&gt;transform&lt;/em&gt;, and &lt;em&gt;apply&lt;/em&gt;.
We&amp;rsquo;ll discuss each of these more fully in &lt;a href=&#34;#Aggregate,-Filter,-Transform,-Apply&#34;&gt;&amp;laquo;Aggregate, Filter, Transform, Apply&amp;raquo;&lt;/a&gt;, but before that let&amp;rsquo;s introduce some of the other functionality that can be used with the basic &lt;code&gt;GroupBy&lt;/code&gt; operation.&lt;/p&gt;

&lt;h4 id=&#34;column-indexing&#34;&gt;Column indexing&lt;/h4&gt;

&lt;p&gt;The &lt;code&gt;GroupBy&lt;/code&gt; object supports column indexing in the same way as the &lt;code&gt;DataFrame&lt;/code&gt;, and returns a modified &lt;code&gt;GroupBy&lt;/code&gt; object.
For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;planets.groupby(&#39;method&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;pandas.core.groupby.DataFrameGroupBy object at 0x1172727b8&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;planets.groupby(&#39;method&#39;)[&#39;orbital_period&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;pandas.core.groupby.SeriesGroupBy object at 0x117272da0&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we&amp;rsquo;ve selected a particular &lt;code&gt;Series&lt;/code&gt; group from the original &lt;code&gt;DataFrame&lt;/code&gt; group by reference to its column name.
As with the &lt;code&gt;GroupBy&lt;/code&gt; object, no computation is done until we call some aggregate on the object:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;planets.groupby(&#39;method&#39;)[&#39;orbital_period&#39;].median()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;method
Astrometry                         631.180000
Eclipse Timing Variations         4343.500000
Imaging                          27500.000000
Microlensing                      3300.000000
Orbital Brightness Modulation        0.342887
Pulsar Timing                       66.541900
Pulsation Timing Variations       1170.000000
Radial Velocity                    360.200000
Transit                              5.714932
Transit Timing Variations           57.011000
Name: orbital_period, dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This gives an idea of the general scale of orbital periods (in days) that each method is sensitive to.&lt;/p&gt;

&lt;h4 id=&#34;iteration-over-groups&#34;&gt;Iteration over groups&lt;/h4&gt;

&lt;p&gt;The &lt;code&gt;GroupBy&lt;/code&gt; object supports direct iteration over the groups, returning each group as a &lt;code&gt;Series&lt;/code&gt; or &lt;code&gt;DataFrame&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for (method, group) in planets.groupby(&#39;method&#39;):
    print(&amp;quot;{0:30s} shape={1}&amp;quot;.format(method, group.shape))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Astrometry                     shape=(2, 6)
Eclipse Timing Variations      shape=(9, 6)
Imaging                        shape=(38, 6)
Microlensing                   shape=(23, 6)
Orbital Brightness Modulation  shape=(3, 6)
Pulsar Timing                  shape=(5, 6)
Pulsation Timing Variations    shape=(1, 6)
Radial Velocity                shape=(553, 6)
Transit                        shape=(397, 6)
Transit Timing Variations      shape=(4, 6)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This can be useful for doing certain things manually, though it is often much faster to use the built-in &lt;code&gt;apply&lt;/code&gt; functionality, which we will discuss momentarily.&lt;/p&gt;

&lt;h4 id=&#34;dispatch-methods&#34;&gt;Dispatch methods&lt;/h4&gt;

&lt;p&gt;Through some Python class magic, any method not explicitly implemented by the &lt;code&gt;GroupBy&lt;/code&gt; object will be passed through and called on the groups, whether they are &lt;code&gt;DataFrame&lt;/code&gt; or &lt;code&gt;Series&lt;/code&gt; objects.
For example, you can use the &lt;code&gt;describe()&lt;/code&gt; method of &lt;code&gt;DataFrame&lt;/code&gt;s to perform a set of aggregations that describe each group in the data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;planets.groupby(&#39;method&#39;)[&#39;year&#39;].describe().unstack()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;count&lt;/th&gt;
      &lt;th&gt;mean&lt;/th&gt;
      &lt;th&gt;std&lt;/th&gt;
      &lt;th&gt;min&lt;/th&gt;
      &lt;th&gt;25%&lt;/th&gt;
      &lt;th&gt;50%&lt;/th&gt;
      &lt;th&gt;75%&lt;/th&gt;
      &lt;th&gt;max&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;method&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Astrometry&lt;/th&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;2011.500000&lt;/td&gt;
      &lt;td&gt;2.121320&lt;/td&gt;
      &lt;td&gt;2010.0&lt;/td&gt;
      &lt;td&gt;2010.75&lt;/td&gt;
      &lt;td&gt;2011.5&lt;/td&gt;
      &lt;td&gt;2012.25&lt;/td&gt;
      &lt;td&gt;2013.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Eclipse Timing Variations&lt;/th&gt;
      &lt;td&gt;9.0&lt;/td&gt;
      &lt;td&gt;2010.000000&lt;/td&gt;
      &lt;td&gt;1.414214&lt;/td&gt;
      &lt;td&gt;2008.0&lt;/td&gt;
      &lt;td&gt;2009.00&lt;/td&gt;
      &lt;td&gt;2010.0&lt;/td&gt;
      &lt;td&gt;2011.00&lt;/td&gt;
      &lt;td&gt;2012.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Imaging&lt;/th&gt;
      &lt;td&gt;38.0&lt;/td&gt;
      &lt;td&gt;2009.131579&lt;/td&gt;
      &lt;td&gt;2.781901&lt;/td&gt;
      &lt;td&gt;2004.0&lt;/td&gt;
      &lt;td&gt;2008.00&lt;/td&gt;
      &lt;td&gt;2009.0&lt;/td&gt;
      &lt;td&gt;2011.00&lt;/td&gt;
      &lt;td&gt;2013.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Microlensing&lt;/th&gt;
      &lt;td&gt;23.0&lt;/td&gt;
      &lt;td&gt;2009.782609&lt;/td&gt;
      &lt;td&gt;2.859697&lt;/td&gt;
      &lt;td&gt;2004.0&lt;/td&gt;
      &lt;td&gt;2008.00&lt;/td&gt;
      &lt;td&gt;2010.0&lt;/td&gt;
      &lt;td&gt;2012.00&lt;/td&gt;
      &lt;td&gt;2013.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Orbital Brightness Modulation&lt;/th&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;2011.666667&lt;/td&gt;
      &lt;td&gt;1.154701&lt;/td&gt;
      &lt;td&gt;2011.0&lt;/td&gt;
      &lt;td&gt;2011.00&lt;/td&gt;
      &lt;td&gt;2011.0&lt;/td&gt;
      &lt;td&gt;2012.00&lt;/td&gt;
      &lt;td&gt;2013.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Pulsar Timing&lt;/th&gt;
      &lt;td&gt;5.0&lt;/td&gt;
      &lt;td&gt;1998.400000&lt;/td&gt;
      &lt;td&gt;8.384510&lt;/td&gt;
      &lt;td&gt;1992.0&lt;/td&gt;
      &lt;td&gt;1992.00&lt;/td&gt;
      &lt;td&gt;1994.0&lt;/td&gt;
      &lt;td&gt;2003.00&lt;/td&gt;
      &lt;td&gt;2011.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Pulsation Timing Variations&lt;/th&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;2007.000000&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;2007.0&lt;/td&gt;
      &lt;td&gt;2007.00&lt;/td&gt;
      &lt;td&gt;2007.0&lt;/td&gt;
      &lt;td&gt;2007.00&lt;/td&gt;
      &lt;td&gt;2007.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Radial Velocity&lt;/th&gt;
      &lt;td&gt;553.0&lt;/td&gt;
      &lt;td&gt;2007.518987&lt;/td&gt;
      &lt;td&gt;4.249052&lt;/td&gt;
      &lt;td&gt;1989.0&lt;/td&gt;
      &lt;td&gt;2005.00&lt;/td&gt;
      &lt;td&gt;2009.0&lt;/td&gt;
      &lt;td&gt;2011.00&lt;/td&gt;
      &lt;td&gt;2014.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Transit&lt;/th&gt;
      &lt;td&gt;397.0&lt;/td&gt;
      &lt;td&gt;2011.236776&lt;/td&gt;
      &lt;td&gt;2.077867&lt;/td&gt;
      &lt;td&gt;2002.0&lt;/td&gt;
      &lt;td&gt;2010.00&lt;/td&gt;
      &lt;td&gt;2012.0&lt;/td&gt;
      &lt;td&gt;2013.00&lt;/td&gt;
      &lt;td&gt;2014.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Transit Timing Variations&lt;/th&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;2012.500000&lt;/td&gt;
      &lt;td&gt;1.290994&lt;/td&gt;
      &lt;td&gt;2011.0&lt;/td&gt;
      &lt;td&gt;2011.75&lt;/td&gt;
      &lt;td&gt;2012.5&lt;/td&gt;
      &lt;td&gt;2013.25&lt;/td&gt;
      &lt;td&gt;2014.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Looking at this table helps us to better understand the data: for example, the vast majority of planets have been discovered by the Radial Velocity and Transit methods, though the latter only became common (due to new, more accurate telescopes) in the last decade.
The newest methods seem to be Transit Timing Variation and Orbital Brightness Modulation, which were not used to discover a new planet until 2011.&lt;/p&gt;

&lt;p&gt;This is just one example of the utility of dispatch methods.
Notice that they are applied &lt;em&gt;to each individual group&lt;/em&gt;, and the results are then combined within &lt;code&gt;GroupBy&lt;/code&gt; and returned.
Again, any valid &lt;code&gt;DataFrame&lt;/code&gt;/&lt;code&gt;Series&lt;/code&gt; method can be used on the corresponding &lt;code&gt;GroupBy&lt;/code&gt; object, which allows for some very flexible and powerful operations!&lt;/p&gt;

&lt;h3 id=&#34;aggregate-filter-transform-apply&#34;&gt;Aggregate, filter, transform, apply&lt;/h3&gt;

&lt;p&gt;The preceding discussion focused on aggregation for the combine operation, but there are more options available.
In particular, &lt;code&gt;GroupBy&lt;/code&gt; objects have &lt;code&gt;aggregate()&lt;/code&gt;, &lt;code&gt;filter()&lt;/code&gt;, &lt;code&gt;transform()&lt;/code&gt;, and &lt;code&gt;apply()&lt;/code&gt; methods that efficiently implement a variety of useful operations before combining the grouped data.&lt;/p&gt;

&lt;p&gt;For the purpose of the following subsections, we&amp;rsquo;ll use this &lt;code&gt;DataFrame&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;rng = np.random.RandomState(0)
df = pd.DataFrame({&#39;key&#39;: [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;],
                   &#39;data1&#39;: range(6),
                   &#39;data2&#39;: rng.randint(0, 10, 6)},
                   columns = [&#39;key&#39;, &#39;data1&#39;, &#39;data2&#39;])
df
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h4 id=&#34;aggregation&#34;&gt;Aggregation&lt;/h4&gt;

&lt;p&gt;We&amp;rsquo;re now familiar with &lt;code&gt;GroupBy&lt;/code&gt; aggregations with &lt;code&gt;sum()&lt;/code&gt;, &lt;code&gt;median()&lt;/code&gt;, and the like, but the &lt;code&gt;aggregate()&lt;/code&gt; method allows for even more flexibility.
It can take a string, a function, or a list thereof, and compute all the aggregates at once.
Here is a quick example combining all these:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.groupby(&#39;key&#39;).aggregate([&#39;min&#39;, np.median, max])
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th colspan=&#34;3&#34; halign=&#34;left&#34;&gt;data1&lt;/th&gt;
      &lt;th colspan=&#34;3&#34; halign=&#34;left&#34;&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;min&lt;/th&gt;
      &lt;th&gt;median&lt;/th&gt;
      &lt;th&gt;max&lt;/th&gt;
      &lt;th&gt;min&lt;/th&gt;
      &lt;th&gt;median&lt;/th&gt;
      &lt;th&gt;max&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1.5&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2.5&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;3.5&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;3.5&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;6.0&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Another useful pattern is to pass a dictionary mapping column names to operations to be applied on that column:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.groupby(&#39;key&#39;).aggregate({&#39;data1&#39;: &#39;min&#39;,
                             &#39;data2&#39;: &#39;max&#39;})
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h4 id=&#34;filtering&#34;&gt;Filtering&lt;/h4&gt;

&lt;p&gt;A filtering operation allows you to drop data based on the group properties.
For example, we might want to keep all groups in which the standard deviation is larger than some critical value:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def filter_func(x):
    return x[&#39;data2&#39;].std() &amp;gt; 4

display(&#39;df&#39;, &amp;quot;df.groupby(&#39;key&#39;).std()&amp;quot;, &amp;quot;df.groupby(&#39;key&#39;).filter(filter_func)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df.groupby(&#39;key&#39;).std()&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;td&gt;2.12132&lt;/td&gt;
      &lt;td&gt;1.414214&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;td&gt;2.12132&lt;/td&gt;
      &lt;td&gt;4.949747&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;td&gt;2.12132&lt;/td&gt;
      &lt;td&gt;4.242641&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df.groupby(&#39;key&#39;).filter(filter_func)&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;The filter function should return a Boolean value specifying whether the group passes the filtering. Here because group A does not have a standard deviation greater than 4, it is dropped from the result.&lt;/p&gt;

&lt;h4 id=&#34;transformation&#34;&gt;Transformation&lt;/h4&gt;

&lt;p&gt;While aggregation must return a reduced version of the data, transformation can return some transformed version of the full data to recombine.
For such a transformation, the output is the same shape as the input.
A common example is to center the data by subtracting the group-wise mean:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.groupby(&#39;key&#39;).transform(lambda x: x - x.mean())
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;-1.5&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;-1.5&lt;/td&gt;
      &lt;td&gt;-3.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;-1.5&lt;/td&gt;
      &lt;td&gt;-3.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1.5&lt;/td&gt;
      &lt;td&gt;-1.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1.5&lt;/td&gt;
      &lt;td&gt;3.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;1.5&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h4 id=&#34;the-apply-method&#34;&gt;The apply() method&lt;/h4&gt;

&lt;p&gt;The &lt;code&gt;apply()&lt;/code&gt; method lets you apply an arbitrary function to the group results.
The function should take a &lt;code&gt;DataFrame&lt;/code&gt;, and return either a Pandas object (e.g., &lt;code&gt;DataFrame&lt;/code&gt;, &lt;code&gt;Series&lt;/code&gt;) or a scalar; the combine operation will be tailored to the type of output returned.&lt;/p&gt;

&lt;p&gt;For example, here is an &lt;code&gt;apply()&lt;/code&gt; that normalizes the first column by the sum of the second:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def norm_by_data2(x):
    # x is a DataFrame of group values
    x[&#39;data1&#39;] /= x[&#39;data2&#39;].sum()
    return x

display(&#39;df&#39;, &amp;quot;df.groupby(&#39;key&#39;).apply(norm_by_data2)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df.groupby(&#39;key&#39;).apply(norm_by_data2)&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;0.142857&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;0.166667&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;0.375000&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;0.571429&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;0.416667&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;&lt;code&gt;apply()&lt;/code&gt; within a &lt;code&gt;GroupBy&lt;/code&gt; is quite flexible: the only criterion is that the function takes a &lt;code&gt;DataFrame&lt;/code&gt; and returns a Pandas object or scalar; what you do in the middle is up to you!&lt;/p&gt;

&lt;h3 id=&#34;specifying-the-split-key&#34;&gt;Specifying the split key&lt;/h3&gt;

&lt;p&gt;In the simple examples presented before, we split the &lt;code&gt;DataFrame&lt;/code&gt; on a single column name.
This is just one of many options by which the groups can be defined, and we&amp;rsquo;ll go through some other options for group specification here.&lt;/p&gt;

&lt;h4 id=&#34;a-list-array-series-or-index-providing-the-grouping-keys&#34;&gt;A list, array, series, or index providing the grouping keys&lt;/h4&gt;

&lt;p&gt;The key can be any series or list with a length matching that of the &lt;code&gt;DataFrame&lt;/code&gt;. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;L = [0, 1, 0, 1, 2, 0]
display(&#39;df&#39;, &#39;df.groupby(L).sum()&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df.groupby(L).sum()&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;17&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;p&gt;Of course, this means there&amp;rsquo;s another, more verbose way of accomplishing the &lt;code&gt;df.groupby(&#39;key&#39;)&lt;/code&gt; from before:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;display(&#39;df&#39;, &amp;quot;df.groupby(df[&#39;key&#39;]).sum()&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df.groupby(df[&#39;key&#39;]).sum()&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;h4 id=&#34;a-dictionary-or-series-mapping-index-to-group&#34;&gt;A dictionary or series mapping index to group&lt;/h4&gt;

&lt;p&gt;Another method is to provide a dictionary that maps index values to the group keys:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df2 = df.set_index(&#39;key&#39;)
mapping = {&#39;A&#39;: &#39;vowel&#39;, &#39;B&#39;: &#39;consonant&#39;, &#39;C&#39;: &#39;consonant&#39;}
display(&#39;df2&#39;, &#39;df2.groupby(mapping).sum()&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df2&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df2.groupby(mapping).sum()&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;consonant&lt;/th&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;19&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;vowel&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;h4 id=&#34;any-python-function&#34;&gt;Any Python function&lt;/h4&gt;

&lt;p&gt;Similar to mapping, you can pass any Python function that will input the index value and output the group:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;display(&#39;df2&#39;, &#39;df2.groupby(str.lower).mean()&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df2&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;key&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;div style=&#34;float: left; padding: 10px;&#34;&gt;
    &lt;p style=&#39;font-family:&#34;Courier New&#34;, Courier, monospace&#39;&gt;df2.groupby(str.lower).mean()&lt;/p&gt;&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;a&lt;/th&gt;
      &lt;td&gt;1.5&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;b&lt;/th&gt;
      &lt;td&gt;2.5&lt;/td&gt;
      &lt;td&gt;3.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;c&lt;/th&gt;
      &lt;td&gt;3.5&lt;/td&gt;
      &lt;td&gt;6.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    &lt;/div&gt;

&lt;h4 id=&#34;a-list-of-valid-keys&#34;&gt;A list of valid keys&lt;/h4&gt;

&lt;p&gt;Further, any of the preceding key choices can be combined to group on a multi-index:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df2.groupby([str.lower, mapping]).mean()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;data1&lt;/th&gt;
      &lt;th&gt;data2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;a&lt;/th&gt;
      &lt;th&gt;vowel&lt;/th&gt;
      &lt;td&gt;1.5&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;b&lt;/th&gt;
      &lt;th&gt;consonant&lt;/th&gt;
      &lt;td&gt;2.5&lt;/td&gt;
      &lt;td&gt;3.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;c&lt;/th&gt;
      &lt;th&gt;consonant&lt;/th&gt;
      &lt;td&gt;3.5&lt;/td&gt;
      &lt;td&gt;6.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&#34;grouping-example&#34;&gt;Grouping example&lt;/h3&gt;

&lt;p&gt;As an example of this, in a couple lines of Python code we can put all these together and count discovered planets by method and by decade:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;decade = 10 * (planets[&#39;year&#39;] // 10)
decade = decade.astype(str) + &#39;s&#39;
decade.name = &#39;decade&#39;
planets.groupby([&#39;method&#39;, decade])[&#39;number&#39;].sum().unstack().fillna(0)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;decade&lt;/th&gt;
      &lt;th&gt;1980s&lt;/th&gt;
      &lt;th&gt;1990s&lt;/th&gt;
      &lt;th&gt;2000s&lt;/th&gt;
      &lt;th&gt;2010s&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;method&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Astrometry&lt;/th&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;2.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Eclipse Timing Variations&lt;/th&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
      &lt;td&gt;10.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Imaging&lt;/th&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;29.0&lt;/td&gt;
      &lt;td&gt;21.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Microlensing&lt;/th&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;12.0&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Orbital Brightness Modulation&lt;/th&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Pulsar Timing&lt;/th&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;9.0&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Pulsation Timing Variations&lt;/th&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Radial Velocity&lt;/th&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;52.0&lt;/td&gt;
      &lt;td&gt;475.0&lt;/td&gt;
      &lt;td&gt;424.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Transit&lt;/th&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;64.0&lt;/td&gt;
      &lt;td&gt;712.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Transit Timing Variations&lt;/th&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;9.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;This shows the power of combining many of the operations we&amp;rsquo;ve discussed up to this point when looking at realistic datasets.
We immediately gain a coarse understanding of when and how planets have been discovered over the past several decades!&lt;/p&gt;

&lt;p&gt;Here I would suggest digging into these few lines of code, and evaluating the individual steps to make sure you understand exactly what they are doing to the result.
It&amp;rsquo;s certainly a somewhat complicated example, but understanding these pieces will give you the means to similarly explore your own data.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pivot Tables</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.09-pivot-tables/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.09-pivot-tables/</guid>
      <description>

&lt;p&gt;We have seen how the &lt;code&gt;GroupBy&lt;/code&gt; abstraction lets us explore relationships within a dataset.
A &lt;em&gt;pivot table&lt;/em&gt; is a similar operation that is commonly seen in spreadsheets and other programs that operate on tabular data.
The pivot table takes simple column-wise data as input, and groups the entries into a two-dimensional table that provides a multidimensional summarization of the data.
The difference between pivot tables and &lt;code&gt;GroupBy&lt;/code&gt; can sometimes cause confusion; it helps me to think of pivot tables as essentially a &lt;em&gt;multidimensional&lt;/em&gt; version of &lt;code&gt;GroupBy&lt;/code&gt; aggregation.
That is, you split-apply-combine, but both the split and the combine happen across not a one-dimensional index, but across a two-dimensional grid.&lt;/p&gt;

&lt;h2 id=&#34;motivating-pivot-tables&#34;&gt;Motivating Pivot Tables&lt;/h2&gt;

&lt;p&gt;For the examples in this section, we&amp;rsquo;ll use the database of passengers on the &lt;em&gt;Titanic&lt;/em&gt;, available through the Seaborn library (see &lt;a href=&#34;04.14-Visualization-With-Seaborn.ipynb&#34; target=&#34;_blank&#34;&gt;Visualization With Seaborn&lt;/a&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
import pandas as pd
import seaborn as sns
titanic = sns.load_dataset(&#39;titanic&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;titanic.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;survived&lt;/th&gt;
      &lt;th&gt;pclass&lt;/th&gt;
      &lt;th&gt;sex&lt;/th&gt;
      &lt;th&gt;age&lt;/th&gt;
      &lt;th&gt;sibsp&lt;/th&gt;
      &lt;th&gt;parch&lt;/th&gt;
      &lt;th&gt;fare&lt;/th&gt;
      &lt;th&gt;embarked&lt;/th&gt;
      &lt;th&gt;class&lt;/th&gt;
      &lt;th&gt;who&lt;/th&gt;
      &lt;th&gt;adult_male&lt;/th&gt;
      &lt;th&gt;deck&lt;/th&gt;
      &lt;th&gt;embark_town&lt;/th&gt;
      &lt;th&gt;alive&lt;/th&gt;
      &lt;th&gt;alone&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;male&lt;/td&gt;
      &lt;td&gt;22.0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;7.2500&lt;/td&gt;
      &lt;td&gt;S&lt;/td&gt;
      &lt;td&gt;Third&lt;/td&gt;
      &lt;td&gt;man&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;Southampton&lt;/td&gt;
      &lt;td&gt;no&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;female&lt;/td&gt;
      &lt;td&gt;38.0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;71.2833&lt;/td&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;First&lt;/td&gt;
      &lt;td&gt;woman&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;Cherbourg&lt;/td&gt;
      &lt;td&gt;yes&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;female&lt;/td&gt;
      &lt;td&gt;26.0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;7.9250&lt;/td&gt;
      &lt;td&gt;S&lt;/td&gt;
      &lt;td&gt;Third&lt;/td&gt;
      &lt;td&gt;woman&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;Southampton&lt;/td&gt;
      &lt;td&gt;yes&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;female&lt;/td&gt;
      &lt;td&gt;35.0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;53.1000&lt;/td&gt;
      &lt;td&gt;S&lt;/td&gt;
      &lt;td&gt;First&lt;/td&gt;
      &lt;td&gt;woman&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;C&lt;/td&gt;
      &lt;td&gt;Southampton&lt;/td&gt;
      &lt;td&gt;yes&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;male&lt;/td&gt;
      &lt;td&gt;35.0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;8.0500&lt;/td&gt;
      &lt;td&gt;S&lt;/td&gt;
      &lt;td&gt;Third&lt;/td&gt;
      &lt;td&gt;man&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;Southampton&lt;/td&gt;
      &lt;td&gt;no&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;This contains a wealth of information on each passenger of that ill-fated voyage, including gender, age, class, fare paid, and much more.&lt;/p&gt;

&lt;h2 id=&#34;pivot-tables-by-hand&#34;&gt;Pivot Tables by Hand&lt;/h2&gt;

&lt;p&gt;To start learning more about this data, we might begin by grouping according to gender, survival status, or some combination thereof.
If you have read the previous section, you might be tempted to apply a &lt;code&gt;GroupBy&lt;/code&gt; operation–for example, let&amp;rsquo;s look at survival rate by gender:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;titanic.groupby(&#39;sex&#39;)[[&#39;survived&#39;]].mean()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;survived&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;sex&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;female&lt;/th&gt;
      &lt;td&gt;0.742038&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;male&lt;/th&gt;
      &lt;td&gt;0.188908&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;This immediately gives us some insight: overall, three of every four females on board survived, while only one in five males survived!&lt;/p&gt;

&lt;p&gt;This is useful, but we might like to go one step deeper and look at survival by both sex and, say, class.
Using the vocabulary of &lt;code&gt;GroupBy&lt;/code&gt;, we might proceed using something like this:
we &lt;em&gt;group by&lt;/em&gt; class and gender, &lt;em&gt;select&lt;/em&gt; survival, &lt;em&gt;apply&lt;/em&gt; a mean aggregate, &lt;em&gt;combine&lt;/em&gt; the resulting groups, and then &lt;em&gt;unstack&lt;/em&gt; the hierarchical index to reveal the hidden multidimensionality. In code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;titanic.groupby([&#39;sex&#39;, &#39;class&#39;])[&#39;survived&#39;].aggregate(&#39;mean&#39;).unstack()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;class&lt;/th&gt;
      &lt;th&gt;First&lt;/th&gt;
      &lt;th&gt;Second&lt;/th&gt;
      &lt;th&gt;Third&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;sex&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;female&lt;/th&gt;
      &lt;td&gt;0.968085&lt;/td&gt;
      &lt;td&gt;0.921053&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;male&lt;/th&gt;
      &lt;td&gt;0.368852&lt;/td&gt;
      &lt;td&gt;0.157407&lt;/td&gt;
      &lt;td&gt;0.135447&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;This gives us a better idea of how both gender and class affected survival, but the code is starting to look a bit garbled.
While each step of this pipeline makes sense in light of the tools we&amp;rsquo;ve previously discussed, the long string of code is not particularly easy to read or use.
This two-dimensional &lt;code&gt;GroupBy&lt;/code&gt; is common enough that Pandas includes a convenience routine, &lt;code&gt;pivot_table&lt;/code&gt;, which succinctly handles this type of multi-dimensional aggregation.&lt;/p&gt;

&lt;h2 id=&#34;pivot-table-syntax&#34;&gt;Pivot Table Syntax&lt;/h2&gt;

&lt;p&gt;Here is the equivalent to the preceding operation using the &lt;code&gt;pivot_table&lt;/code&gt; method of &lt;code&gt;DataFrame&lt;/code&gt;s:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;titanic.pivot_table(&#39;survived&#39;, index=&#39;sex&#39;, columns=&#39;class&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;class&lt;/th&gt;
      &lt;th&gt;First&lt;/th&gt;
      &lt;th&gt;Second&lt;/th&gt;
      &lt;th&gt;Third&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;sex&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;female&lt;/th&gt;
      &lt;td&gt;0.968085&lt;/td&gt;
      &lt;td&gt;0.921053&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;male&lt;/th&gt;
      &lt;td&gt;0.368852&lt;/td&gt;
      &lt;td&gt;0.157407&lt;/td&gt;
      &lt;td&gt;0.135447&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;This is eminently more readable than the &lt;code&gt;groupby&lt;/code&gt; approach, and produces the same result.
As you might expect of an early 20th-century transatlantic cruise, the survival gradient favors both women and higher classes.
First-class women survived with near certainty (hi, Rose!), while only one in ten third-class men survived (sorry, Jack!).&lt;/p&gt;

&lt;h3 id=&#34;multi-level-pivot-tables&#34;&gt;Multi-level pivot tables&lt;/h3&gt;

&lt;p&gt;Just as in the &lt;code&gt;GroupBy&lt;/code&gt;, the grouping in pivot tables can be specified with multiple levels, and via a number of options.
For example, we might be interested in looking at age as a third dimension.
We&amp;rsquo;ll bin the age using the &lt;code&gt;pd.cut&lt;/code&gt; function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;age = pd.cut(titanic[&#39;age&#39;], [0, 18, 80])
titanic.pivot_table(&#39;survived&#39;, [&#39;sex&#39;, age], &#39;class&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;class&lt;/th&gt;
      &lt;th&gt;First&lt;/th&gt;
      &lt;th&gt;Second&lt;/th&gt;
      &lt;th&gt;Third&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;sex&lt;/th&gt;
      &lt;th&gt;age&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;female&lt;/th&gt;
      &lt;th&gt;(0, 18]&lt;/th&gt;
      &lt;td&gt;0.909091&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.511628&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;(18, 80]&lt;/th&gt;
      &lt;td&gt;0.972973&lt;/td&gt;
      &lt;td&gt;0.900000&lt;/td&gt;
      &lt;td&gt;0.423729&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;male&lt;/th&gt;
      &lt;th&gt;(0, 18]&lt;/th&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;0.600000&lt;/td&gt;
      &lt;td&gt;0.215686&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;(18, 80]&lt;/th&gt;
      &lt;td&gt;0.375000&lt;/td&gt;
      &lt;td&gt;0.071429&lt;/td&gt;
      &lt;td&gt;0.133663&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We can apply the same strategy when working with the columns as well; let&amp;rsquo;s add info on the fare paid using &lt;code&gt;pd.qcut&lt;/code&gt; to automatically compute quantiles:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fare = pd.qcut(titanic[&#39;fare&#39;], 2)
titanic.pivot_table(&#39;survived&#39;, [&#39;sex&#39;, age], [fare, &#39;class&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;fare&lt;/th&gt;
      &lt;th colspan=&#34;3&#34; halign=&#34;left&#34;&gt;[0, 14.454]&lt;/th&gt;
      &lt;th colspan=&#34;3&#34; halign=&#34;left&#34;&gt;(14.454, 512.329]&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;class&lt;/th&gt;
      &lt;th&gt;First&lt;/th&gt;
      &lt;th&gt;Second&lt;/th&gt;
      &lt;th&gt;Third&lt;/th&gt;
      &lt;th&gt;First&lt;/th&gt;
      &lt;th&gt;Second&lt;/th&gt;
      &lt;th&gt;Third&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;sex&lt;/th&gt;
      &lt;th&gt;age&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;female&lt;/th&gt;
      &lt;th&gt;(0, 18]&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.714286&lt;/td&gt;
      &lt;td&gt;0.909091&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.318182&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;(18, 80]&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;0.880000&lt;/td&gt;
      &lt;td&gt;0.444444&lt;/td&gt;
      &lt;td&gt;0.972973&lt;/td&gt;
      &lt;td&gt;0.914286&lt;/td&gt;
      &lt;td&gt;0.391304&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th rowspan=&#34;2&#34; valign=&#34;top&#34;&gt;male&lt;/th&gt;
      &lt;th&gt;(0, 18]&lt;/th&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.260870&lt;/td&gt;
      &lt;td&gt;0.800000&lt;/td&gt;
      &lt;td&gt;0.818182&lt;/td&gt;
      &lt;td&gt;0.178571&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;(18, 80]&lt;/th&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;0.098039&lt;/td&gt;
      &lt;td&gt;0.125000&lt;/td&gt;
      &lt;td&gt;0.391304&lt;/td&gt;
      &lt;td&gt;0.030303&lt;/td&gt;
      &lt;td&gt;0.192308&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The result is a four-dimensional aggregation with hierarchical indices (see &lt;a href=&#34;03.05-Hierarchical-Indexing.ipynb&#34; target=&#34;_blank&#34;&gt;Hierarchical Indexing&lt;/a&gt;), shown in a grid demonstrating the relationship between the values.&lt;/p&gt;

&lt;h3 id=&#34;additional-pivot-table-options&#34;&gt;Additional pivot table options&lt;/h3&gt;

&lt;p&gt;The full call signature of the &lt;code&gt;pivot_table&lt;/code&gt; method of &lt;code&gt;DataFrame&lt;/code&gt;s is as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# call signature as of Pandas 0.18
DataFrame.pivot_table(data, values=None, index=None, columns=None,
                      aggfunc=&#39;mean&#39;, fill_value=None, margins=False,
                      dropna=True, margins_name=&#39;All&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;ve already seen examples of the first three arguments; here we&amp;rsquo;ll take a quick look at the remaining ones.
Two of the options, &lt;code&gt;fill_value&lt;/code&gt; and &lt;code&gt;dropna&lt;/code&gt;, have to do with missing data and are fairly straightforward; we will not show examples of them here.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;aggfunc&lt;/code&gt; keyword controls what type of aggregation is applied, which is a mean by default.
As in the GroupBy, the aggregation specification can be a string representing one of several common choices (e.g., &lt;code&gt;&#39;sum&#39;&lt;/code&gt;, &lt;code&gt;&#39;mean&#39;&lt;/code&gt;, &lt;code&gt;&#39;count&#39;&lt;/code&gt;, &lt;code&gt;&#39;min&#39;&lt;/code&gt;, &lt;code&gt;&#39;max&#39;&lt;/code&gt;, etc.) or a function that implements an aggregation (e.g., &lt;code&gt;np.sum()&lt;/code&gt;, &lt;code&gt;min()&lt;/code&gt;, &lt;code&gt;sum()&lt;/code&gt;, etc.).
Additionally, it can be specified as a dictionary mapping a column to any of the above desired options:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;titanic.pivot_table(index=&#39;sex&#39;, columns=&#39;class&#39;,
                    aggfunc={&#39;survived&#39;:sum, &#39;fare&#39;:&#39;mean&#39;})
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th colspan=&#34;3&#34; halign=&#34;left&#34;&gt;fare&lt;/th&gt;
      &lt;th colspan=&#34;3&#34; halign=&#34;left&#34;&gt;survived&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;class&lt;/th&gt;
      &lt;th&gt;First&lt;/th&gt;
      &lt;th&gt;Second&lt;/th&gt;
      &lt;th&gt;Third&lt;/th&gt;
      &lt;th&gt;First&lt;/th&gt;
      &lt;th&gt;Second&lt;/th&gt;
      &lt;th&gt;Third&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;sex&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;female&lt;/th&gt;
      &lt;td&gt;106.125798&lt;/td&gt;
      &lt;td&gt;21.970121&lt;/td&gt;
      &lt;td&gt;16.118810&lt;/td&gt;
      &lt;td&gt;91.0&lt;/td&gt;
      &lt;td&gt;70.0&lt;/td&gt;
      &lt;td&gt;72.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;male&lt;/th&gt;
      &lt;td&gt;67.226127&lt;/td&gt;
      &lt;td&gt;19.741782&lt;/td&gt;
      &lt;td&gt;12.661633&lt;/td&gt;
      &lt;td&gt;45.0&lt;/td&gt;
      &lt;td&gt;17.0&lt;/td&gt;
      &lt;td&gt;47.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Notice also here that we&amp;rsquo;ve omitted the &lt;code&gt;values&lt;/code&gt; keyword; when specifying a mapping for &lt;code&gt;aggfunc&lt;/code&gt;, this is determined automatically.&lt;/p&gt;

&lt;p&gt;At times it&amp;rsquo;s useful to compute totals along each grouping.
This can be done via the &lt;code&gt;margins&lt;/code&gt; keyword:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;titanic.pivot_table(&#39;survived&#39;, index=&#39;sex&#39;, columns=&#39;class&#39;, margins=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;class&lt;/th&gt;
      &lt;th&gt;First&lt;/th&gt;
      &lt;th&gt;Second&lt;/th&gt;
      &lt;th&gt;Third&lt;/th&gt;
      &lt;th&gt;All&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;sex&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;female&lt;/th&gt;
      &lt;td&gt;0.968085&lt;/td&gt;
      &lt;td&gt;0.921053&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;0.742038&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;male&lt;/th&gt;
      &lt;td&gt;0.368852&lt;/td&gt;
      &lt;td&gt;0.157407&lt;/td&gt;
      &lt;td&gt;0.135447&lt;/td&gt;
      &lt;td&gt;0.188908&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;All&lt;/th&gt;
      &lt;td&gt;0.629630&lt;/td&gt;
      &lt;td&gt;0.472826&lt;/td&gt;
      &lt;td&gt;0.242363&lt;/td&gt;
      &lt;td&gt;0.383838&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Here this automatically gives us information about the class-agnostic survival rate by gender, the gender-agnostic survival rate by class, and the overall survival rate of 38%.
The margin label can be specified with the &lt;code&gt;margins_name&lt;/code&gt; keyword, which defaults to &lt;code&gt;&amp;quot;All&amp;quot;&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;example-birthrate-data&#34;&gt;Example: Birthrate Data&lt;/h2&gt;

&lt;p&gt;As a more interesting example, let&amp;rsquo;s take a look at the freely available data on births in the United States, provided by the Centers for Disease Control (CDC).
This data can be found at &lt;a href=&#34;https://raw.githubusercontent.com/jakevdp/data-CDCbirths/master/births.csv&#34; target=&#34;_blank&#34;&gt;https://raw.githubusercontent.com/jakevdp/data-CDCbirths/master/births.csv&lt;/a&gt;
(this dataset has been analyzed rather extensively by Andrew Gelman and his group; see, for example, &lt;a href=&#34;http://andrewgelman.com/2012/06/14/cool-ass-signal-processing-using-gaussian-processes/&#34; target=&#34;_blank&#34;&gt;this blog post&lt;/a&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# shell command to download the data:
# !curl -O https://raw.githubusercontent.com/jakevdp/data-CDCbirths/master/births.csv
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;births = pd.read_csv(&#39;data/births.csv&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Taking a look at the data, we see that it&amp;rsquo;s relatively simple–it contains the number of births grouped by date and gender:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;births.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;year&lt;/th&gt;
      &lt;th&gt;month&lt;/th&gt;
      &lt;th&gt;day&lt;/th&gt;
      &lt;th&gt;gender&lt;/th&gt;
      &lt;th&gt;births&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;1969&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;F&lt;/td&gt;
      &lt;td&gt;4046&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1969&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;M&lt;/td&gt;
      &lt;td&gt;4440&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1969&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;F&lt;/td&gt;
      &lt;td&gt;4454&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;1969&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;M&lt;/td&gt;
      &lt;td&gt;4548&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1969&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;F&lt;/td&gt;
      &lt;td&gt;4548&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We can start to understand this data a bit more by using a pivot table.
Let&amp;rsquo;s add a decade column, and take a look at male and female births as a function of decade:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;births[&#39;decade&#39;] = 10 * (births[&#39;year&#39;] // 10)
births.pivot_table(&#39;births&#39;, index=&#39;decade&#39;, columns=&#39;gender&#39;, aggfunc=&#39;sum&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;gender&lt;/th&gt;
      &lt;th&gt;F&lt;/th&gt;
      &lt;th&gt;M&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;decade&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1960&lt;/th&gt;
      &lt;td&gt;1753634&lt;/td&gt;
      &lt;td&gt;1846572&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1970&lt;/th&gt;
      &lt;td&gt;16263075&lt;/td&gt;
      &lt;td&gt;17121550&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1980&lt;/th&gt;
      &lt;td&gt;18310351&lt;/td&gt;
      &lt;td&gt;19243452&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1990&lt;/th&gt;
      &lt;td&gt;19479454&lt;/td&gt;
      &lt;td&gt;20420553&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2000&lt;/th&gt;
      &lt;td&gt;18229309&lt;/td&gt;
      &lt;td&gt;19106428&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We immediately see that male births outnumber female births in every decade.
To see this trend a bit more clearly, we can use the built-in plotting tools in Pandas to visualize the total number of births by year (see &lt;a href=&#34;04.00-Introduction-To-Matplotlib.ipynb&#34; target=&#34;_blank&#34;&gt;Introduction to Matplotlib&lt;/a&gt; for a discussion of plotting with Matplotlib):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import matplotlib.pyplot as plt
sns.set()  # use Seaborn styles
births.pivot_table(&#39;births&#39;, index=&#39;year&#39;, columns=&#39;gender&#39;, aggfunc=&#39;sum&#39;).plot()
plt.ylabel(&#39;total births per year&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../img/output_35_0.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;With a simple pivot table and &lt;code&gt;plot()&lt;/code&gt; method, we can immediately see the annual trend in births by gender. By eye, it appears that over the past 50 years male births have outnumbered female births by around 5%.&lt;/p&gt;

&lt;h3 id=&#34;further-data-exploration&#34;&gt;Further data exploration&lt;/h3&gt;

&lt;p&gt;Though this doesn&amp;rsquo;t necessarily relate to the pivot table, there are a few more interesting features we can pull out of this dataset using the Pandas tools covered up to this point.
We must start by cleaning the data a bit, removing outliers caused by mistyped dates (e.g., June 31st) or missing values (e.g., June 99th).
One easy way to remove these all at once is to cut outliers; we&amp;rsquo;ll do this via a robust sigma-clipping operation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;quartiles = np.percentile(births[&#39;births&#39;], [25, 50, 75])
mu = quartiles[1]
sig = 0.74 * (quartiles[2] - quartiles[0])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This final line is a robust estimate of the sample mean, where the 0.74 comes from the interquartile range of a Gaussian distribution (You can learn more about sigma-clipping operations in a book I coauthored with Željko Ivezić, Andrew J. Connolly, and Alexander Gray: &lt;a href=&#34;http://press.princeton.edu/titles/10159.html&#34; target=&#34;_blank&#34;&gt;&amp;laquo;Statistics, Data Mining, and Machine Learning in Astronomy&amp;raquo;&lt;/a&gt; (Princeton University Press, 2014)).&lt;/p&gt;

&lt;p&gt;With this we can use the &lt;code&gt;query()&lt;/code&gt; method (discussed further in &lt;a href=&#34;03.12-Performance-Eval-and-Query.ipynb&#34; target=&#34;_blank&#34;&gt;High-Performance Pandas: &lt;code&gt;eval()&lt;/code&gt; and &lt;code&gt;query()&lt;/code&gt;&lt;/a&gt;) to filter-out rows with births outside these values:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;births = births.query(&#39;(births &amp;gt; @mu - 5 * @sig) &amp;amp; (births &amp;lt; @mu + 5 * @sig)&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we set the &lt;code&gt;day&lt;/code&gt; column to integers; previously it had been a string because some columns in the dataset contained the value &lt;code&gt;&#39;null&#39;&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# set &#39;day&#39; column to integer; it originally was a string due to nulls
births[&#39;day&#39;] = births[&#39;day&#39;].astype(int)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, we can combine the day, month, and year to create a Date index (see &lt;a href=&#34;03.11-Working-with-Time-Series.ipynb&#34; target=&#34;_blank&#34;&gt;Working with Time Series&lt;/a&gt;).
This allows us to quickly compute the weekday corresponding to each row:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# create a datetime index from the year, month, day
births.index = pd.to_datetime(10000 * births.year +
                              100 * births.month +
                              births.day, format=&#39;%Y%m%d&#39;)

births[&#39;dayofweek&#39;] = births.index.dayofweek
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using this we can plot births by weekday for several decades:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import matplotlib.pyplot as plt
import matplotlib as mpl

births.pivot_table(&#39;births&#39;, index=&#39;dayofweek&#39;,
                    columns=&#39;decade&#39;, aggfunc=&#39;mean&#39;).plot()
plt.gca().set_xticklabels([&#39;Mon&#39;, &#39;Tues&#39;, &#39;Wed&#39;, &#39;Thurs&#39;, &#39;Fri&#39;, &#39;Sat&#39;, &#39;Sun&#39;])
plt.ylabel(&#39;mean births by day&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./img/output_46_0.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Apparently births are slightly less common on weekends than on weekdays! Note that the 1990s and 2000s are missing because the CDC data contains only the month of birth starting in 1989.&lt;/p&gt;

&lt;p&gt;Another intersting view is to plot the mean number of births by the day of the &lt;em&gt;year&lt;/em&gt;.
Let&amp;rsquo;s first group the data by month and day separately:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;births_by_date = births.pivot_table(&#39;births&#39;, 
                                    [births.index.month, births.index.day])
births_by_date.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;   1    4009.225
   2    4247.400
   3    4500.900
   4    4571.350
   5    4603.625
Name: births, dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The result is a multi-index over months and days.
To make this easily plottable, let&amp;rsquo;s turn these months and days into a date by associating them with a dummy year variable (making sure to choose a leap year so February 29th is correctly handled!)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;births_by_date.index = [pd.datetime(2012, month, day)
                        for (month, day) in births_by_date.index]
births_by_date.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;2012-01-01    4009.225
2012-01-02    4247.400
2012-01-03    4500.900
2012-01-04    4571.350
2012-01-05    4603.625
Name: births, dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Focusing on the month and day only, we now have a time series reflecting the average number of births by date of the year.
From this, we can use the &lt;code&gt;plot&lt;/code&gt; method to plot the data. It reveals some interesting trends:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Plot the results
fig, ax = plt.subplots(figsize=(12, 4))
births_by_date.plot(ax=ax);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../output_52_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In particular, the striking feature of this graph is the dip in birthrate on US holidays (e.g., Independence Day, Labor Day, Thanksgiving, Christmas, New Year&amp;rsquo;s Day) although this likely reflects trends in scheduled/induced births rather than some deep psychosomatic effect on natural births.
For more discussion on this trend, see the analysis and links in &lt;a href=&#34;http://andrewgelman.com/2012/06/14/cool-ass-signal-processing-using-gaussian-processes/&#34; target=&#34;_blank&#34;&gt;Andrew Gelman&amp;rsquo;s blog post&lt;/a&gt; on the subject.
We&amp;rsquo;ll return to this figure in &lt;a href=&#34;04.09-Text-and-Annotation.ipynb#Example:-Effect-of-Holidays-on-US-Births&#34; target=&#34;_blank&#34;&gt;Example:-Effect-of-Holidays-on-US-Births&lt;/a&gt;, where we will use Matplotlib&amp;rsquo;s tools to annotate this plot.&lt;/p&gt;

&lt;p&gt;Looking at this short example, you can see that many of the Python and Pandas tools we&amp;rsquo;ve seen to this point can be combined and used to gain insight from a variety of datasets.
We will see some more sophisticated applications of these data manipulations in future sections!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Vectorized String Operations</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.10-working-with-strings/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.10-working-with-strings/</guid>
      <description>

&lt;p&gt;One strength of Python is its relative ease in handling and manipulating string data.
Pandas builds on this and provides a comprehensive set of &lt;em&gt;vectorized string operations&lt;/em&gt; that become an essential piece of the type of munging required when working with (read: cleaning up) real-world data.
In this section, we&amp;rsquo;ll walk through some of the Pandas string operations, and then take a look at using them to partially clean up a very messy dataset of recipes collected from the Internet.&lt;/p&gt;

&lt;h2 id=&#34;introducing-pandas-string-operations&#34;&gt;Introducing Pandas String Operations&lt;/h2&gt;

&lt;p&gt;We saw in previous sections how tools like NumPy and Pandas generalize arithmetic operations so that we can easily and quickly perform the same operation on many array elements. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
x = np.array([2, 3, 5, 7, 11, 13])
x * 2
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([ 4,  6, 10, 14, 22, 26])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This &lt;em&gt;vectorization&lt;/em&gt; of operations simplifies the syntax of operating on arrays of data: we no longer have to worry about the size or shape of the array, but just about what operation we want done.
For arrays of strings, NumPy does not provide such simple access, and thus you&amp;rsquo;re stuck using a more verbose loop syntax:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data = [&#39;peter&#39;, &#39;Paul&#39;, &#39;MARY&#39;, &#39;gUIDO&#39;]
[s.capitalize() for s in data]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[&#39;Peter&#39;, &#39;Paul&#39;, &#39;Mary&#39;, &#39;Guido&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is perhaps sufficient to work with some data, but it will break if there are any missing values.
For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data = [&#39;peter&#39;, &#39;Paul&#39;, None, &#39;MARY&#39;, &#39;gUIDO&#39;]
[s.capitalize() for s in data]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;---------------------------------------------------------------------------

AttributeError                            Traceback (most recent call last)

&amp;lt;ipython-input-3-fc1d891ab539&amp;gt; in &amp;lt;module&amp;gt;()
      1 data = [&#39;peter&#39;, &#39;Paul&#39;, None, &#39;MARY&#39;, &#39;gUIDO&#39;]
----&amp;gt; 2 [s.capitalize() for s in data]


&amp;lt;ipython-input-3-fc1d891ab539&amp;gt; in &amp;lt;listcomp&amp;gt;(.0)
      1 data = [&#39;peter&#39;, &#39;Paul&#39;, None, &#39;MARY&#39;, &#39;gUIDO&#39;]
----&amp;gt; 2 [s.capitalize() for s in data]


AttributeError: &#39;NoneType&#39; object has no attribute &#39;capitalize&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Pandas includes features to address both this need for vectorized string operations and for correctly handling missing data via the &lt;code&gt;str&lt;/code&gt; attribute of Pandas Series and Index objects containing strings.
So, for example, suppose we create a Pandas Series with this data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
names = pd.Series(data)
names
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    peter
1     Paul
2     None
3     MARY
4    gUIDO
dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can now call a single method that will capitalize all the entries, while skipping over any missing values:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;names.str.capitalize()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    Peter
1     Paul
2     None
3     Mary
4    Guido
dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using tab completion on this &lt;code&gt;str&lt;/code&gt; attribute will list all the vectorized string methods available to Pandas.&lt;/p&gt;

&lt;h2 id=&#34;tables-of-pandas-string-methods&#34;&gt;Tables of Pandas String Methods&lt;/h2&gt;

&lt;p&gt;If you have a good understanding of string manipulation in Python, most of Pandas string syntax is intuitive enough that it&amp;rsquo;s probably sufficient to just list a table of available methods; we will start with that here, before diving deeper into a few of the subtleties.
The examples in this section use the following series of names:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;monte = pd.Series([&#39;Graham Chapman&#39;, &#39;John Cleese&#39;, &#39;Terry Gilliam&#39;,
                   &#39;Eric Idle&#39;, &#39;Terry Jones&#39;, &#39;Michael Palin&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;methods-similar-to-python-string-methods&#34;&gt;Methods similar to Python string methods&lt;/h3&gt;

&lt;p&gt;Nearly all Python&amp;rsquo;s built-in string methods are mirrored by a Pandas vectorized string method. Here is a list of Pandas &lt;code&gt;str&lt;/code&gt; methods that mirror Python string methods:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;len()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;lower()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;translate()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;islower()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ljust()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;upper()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;startswith()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;isupper()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;rjust()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;find()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;endswith()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;isnumeric()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;center()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;rfind()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;isalnum()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;isdecimal()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;zfill()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;index()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;isalpha()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;split()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;strip()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;rindex()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;isdigit()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;rsplit()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;rstrip()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;capitalize()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;isspace()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;partition()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;lstrip()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;swapcase()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;istitle()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;rpartition()&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Notice that these have various return values. Some, like &lt;code&gt;lower()&lt;/code&gt;, return a series of strings:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;monte.str.lower()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    graham chapman
1       john cleese
2     terry gilliam
3         eric idle
4       terry jones
5     michael palin
dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But some others return numbers:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;monte.str.len()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    14
1    11
2    13
3     9
4    11
5    13
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or Boolean values:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;monte.str.startswith(&#39;T&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    False
1    False
2     True
3    False
4     True
5    False
dtype: bool
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Still others return lists or other compound values for each element:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;monte.str.split()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    [Graham, Chapman]
1       [John, Cleese]
2     [Terry, Gilliam]
3         [Eric, Idle]
4       [Terry, Jones]
5     [Michael, Palin]
dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;ll see further manipulations of this kind of series-of-lists object as we continue our discussion.&lt;/p&gt;

&lt;h3 id=&#34;methods-using-regular-expressions&#34;&gt;Methods using regular expressions&lt;/h3&gt;

&lt;p&gt;In addition, there are several methods that accept regular expressions to examine the content of each string element, and follow some of the API conventions of Python&amp;rsquo;s built-in &lt;code&gt;re&lt;/code&gt; module:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Method&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;match()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Call &lt;code&gt;re.match()&lt;/code&gt; on each element, returning a boolean.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;extract()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Call &lt;code&gt;re.match()&lt;/code&gt; on each element, returning matched groups as strings.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;findall()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Call &lt;code&gt;re.findall()&lt;/code&gt; on each element&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;replace()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Replace occurrences of pattern with some other string&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;contains()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Call &lt;code&gt;re.search()&lt;/code&gt; on each element, returning a boolean&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;count()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Count occurrences of pattern&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;split()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Equivalent to &lt;code&gt;str.split()&lt;/code&gt;, but accepts regexps&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;rsplit()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Equivalent to &lt;code&gt;str.rsplit()&lt;/code&gt;, but accepts regexps&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;With these, you can do a wide range of interesting operations.
For example, we can extract the first name from each by asking for a contiguous group of characters at the beginning of each element:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;monte.str.extract(&#39;([A-Za-z]+)&#39;, expand=False)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0     Graham
1       John
2      Terry
3       Eric
4      Terry
5    Michael
dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or we can do something more complicated, like finding all names that start and end with a consonant, making use of the start-of-string (&lt;code&gt;^&lt;/code&gt;) and end-of-string (&lt;code&gt;$&lt;/code&gt;) regular expression characters:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;monte.str.findall(r&#39;^[^AEIOU].*[^aeiou]$&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    [Graham Chapman]
1                  []
2     [Terry Gilliam]
3                  []
4       [Terry Jones]
5     [Michael Palin]
dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The ability to concisely apply regular expressions across &lt;code&gt;Series&lt;/code&gt; or &lt;code&gt;Dataframe&lt;/code&gt; entries opens up many possibilities for analysis and cleaning of data.&lt;/p&gt;

&lt;h3 id=&#34;miscellaneous-methods&#34;&gt;Miscellaneous methods&lt;/h3&gt;

&lt;p&gt;Finally, there are some miscellaneous methods that enable other convenient operations:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Method&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;get()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Index each element&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;slice()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Slice each element&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;slice_replace()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Replace slice in each element with passed value&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;cat()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Concatenate strings&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;repeat()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Repeat values&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;normalize()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Return Unicode form of string&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;pad()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add whitespace to left, right, or both sides of strings&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;wrap()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Split long strings into lines with length less than a given width&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;join()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Join strings in each element of the Series with passed separator&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;get_dummies()&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;extract dummy variables as a dataframe&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;vectorized-item-access-and-slicing&#34;&gt;Vectorized item access and slicing&lt;/h4&gt;

&lt;p&gt;The &lt;code&gt;get()&lt;/code&gt; and &lt;code&gt;slice()&lt;/code&gt; operations, in particular, enable vectorized element access from each array.
For example, we can get a slice of the first three characters of each array using &lt;code&gt;str.slice(0, 3)&lt;/code&gt;.
Note that this behavior is also available through Python&amp;rsquo;s normal indexing syntax–for example, &lt;code&gt;df.str.slice(0, 3)&lt;/code&gt; is equivalent to &lt;code&gt;df.str[0:3]&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;monte.str[0:3]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    Gra
1    Joh
2    Ter
3    Eri
4    Ter
5    Mic
dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Indexing via &lt;code&gt;df.str.get(i)&lt;/code&gt; and &lt;code&gt;df.str[i]&lt;/code&gt; is likewise similar.&lt;/p&gt;

&lt;p&gt;These &lt;code&gt;get()&lt;/code&gt; and &lt;code&gt;slice()&lt;/code&gt; methods also let you access elements of arrays returned by &lt;code&gt;split()&lt;/code&gt;.
For example, to extract the last name of each entry, we can combine &lt;code&gt;split()&lt;/code&gt; and &lt;code&gt;get()&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;monte.str.split().str.get(-1)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0    Chapman
1     Cleese
2    Gilliam
3       Idle
4      Jones
5      Palin
dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;indicator-variables&#34;&gt;Indicator variables&lt;/h4&gt;

&lt;p&gt;Another method that requires a bit of extra explanation is the &lt;code&gt;get_dummies()&lt;/code&gt; method.
This is useful when your data has a column containing some sort of coded indicator.
For example, we might have a dataset that contains information in the form of codes, such as A=&amp;laquo;born in America,&amp;raquo; B=&amp;laquo;born in the United Kingdom,&amp;raquo; C=&amp;laquo;likes cheese,&amp;raquo; D=&amp;laquo;likes spam&amp;raquo;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;full_monte = pd.DataFrame({&#39;name&#39;: monte,
                           &#39;info&#39;: [&#39;B|C|D&#39;, &#39;B|D&#39;, &#39;A|C&#39;,
                                    &#39;B|D&#39;, &#39;B|C&#39;, &#39;B|C|D&#39;]})
full_monte
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;info&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;B|C|D&lt;/td&gt;
      &lt;td&gt;Graham Chapman&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;B|D&lt;/td&gt;
      &lt;td&gt;John Cleese&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;A|C&lt;/td&gt;
      &lt;td&gt;Terry Gilliam&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;B|D&lt;/td&gt;
      &lt;td&gt;Eric Idle&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;B|C&lt;/td&gt;
      &lt;td&gt;Terry Jones&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;B|C|D&lt;/td&gt;
      &lt;td&gt;Michael Palin&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;get_dummies()&lt;/code&gt; routine lets you quickly split-out these indicator variables into a &lt;code&gt;DataFrame&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;full_monte[&#39;info&#39;].str.get_dummies(&#39;|&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;th&gt;D&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;With these operations as building blocks, you can construct an endless range of string processing procedures when cleaning your data.&lt;/p&gt;

&lt;p&gt;We won&amp;rsquo;t dive further into these methods here, but I encourage you to read through &lt;a href=&#34;http://pandas.pydata.org/pandas-docs/stable/text.html&#34; target=&#34;_blank&#34;&gt;&amp;laquo;Working with Text Data&amp;raquo;&lt;/a&gt; in the Pandas online documentation, or to refer to the resources listed in &lt;a href=&#34;03.13-Further-Resources.ipynb&#34; target=&#34;_blank&#34;&gt;Further Resources&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;example-recipe-database&#34;&gt;Example: Recipe Database&lt;/h2&gt;

&lt;p&gt;These vectorized string operations become most useful in the process of cleaning up messy, real-world data.
Here I&amp;rsquo;ll walk through an example of that, using an open recipe database compiled from various sources on the Web.
Our goal will be to parse the recipe data into ingredient lists, so we can quickly find a recipe based on some ingredients we have on hand.&lt;/p&gt;

&lt;p&gt;The scripts used to compile this can be found at &lt;a href=&#34;https://github.com/fictivekin/openrecipes&#34; target=&#34;_blank&#34;&gt;https://github.com/fictivekin/openrecipes&lt;/a&gt;, and the link to the current version of the database is found there as well.&lt;/p&gt;

&lt;p&gt;As of Spring 2016, this database is about 30 MB, and can be downloaded and unzipped with these commands:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# !curl -O http://openrecipes.s3.amazonaws.com/recipeitems-latest.json.gz
# !gunzip recipeitems-latest.json.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The database is in JSON format, so we will try &lt;code&gt;pd.read_json&lt;/code&gt; to read it:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;try:
    recipes = pd.read_json(&#39;recipeitems-latest.json&#39;)
except ValueError as e:
    print(&amp;quot;ValueError:&amp;quot;, e)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;ValueError: Trailing data
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Oops! We get a &lt;code&gt;ValueError&lt;/code&gt; mentioning that there is &amp;laquo;trailing data.&amp;raquo;
Searching for the text of this error on the Internet, it seems that it&amp;rsquo;s due to using a file in which &lt;em&gt;each line&lt;/em&gt; is itself a valid JSON, but the full file is not.
Let&amp;rsquo;s check if this interpretation is true:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;with open(&#39;recipeitems-latest.json&#39;) as f:
    line = f.readline()
pd.read_json(line).shape
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(2, 12)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Yes, apparently each line is a valid JSON, so we&amp;rsquo;ll need to string them together.
One way we can do this is to actually construct a string representation containing all these JSON entries, and then load the whole thing with &lt;code&gt;pd.read_json&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# read the entire file into a Python array
with open(&#39;recipeitems-latest.json&#39;, &#39;r&#39;) as f:
    # Extract each line
    data = (line.strip() for line in f)
    # Reformat so each line is the element of a list
    data_json = &amp;quot;[{0}]&amp;quot;.format(&#39;,&#39;.join(data))
# read the result as a JSON
recipes = pd.read_json(data_json)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;recipes.shape
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(173278, 17)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We see there are nearly 200,000 recipes, and 17 columns.
Let&amp;rsquo;s take a look at one row to see what we have:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;recipes.iloc[0]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;_id                                {&#39;$oid&#39;: &#39;5160756b96cc62079cc2db15&#39;}
cookTime                                                          PT30M
creator                                                             NaN
dateModified                                                        NaN
datePublished                                                2013-03-11
description           Late Saturday afternoon, after Marlboro Man ha...
image                 http://static.thepioneerwoman.com/cooking/file...
ingredients           Biscuits\n3 cups All-purpose Flour\n2 Tablespo...
name                                    Drop Biscuits and Sausage Gravy
prepTime                                                          PT10M
recipeCategory                                                      NaN
recipeInstructions                                                  NaN
recipeYield                                                          12
source                                                  thepioneerwoman
totalTime                                                           NaN
ts                                             {&#39;$date&#39;: 1365276011104}
url                   http://thepioneerwoman.com/cooking/2013/03/dro...
Name: 0, dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There is a lot of information there, but much of it is in a very messy form, as is typical of data scraped from the Web.
In particular, the ingredient list is in string format; we&amp;rsquo;re going to have to carefully extract the information we&amp;rsquo;re interested in.
Let&amp;rsquo;s start by taking a closer look at the ingredients:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;recipes.ingredients.str.len().describe()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;count    173278.000000
mean        244.617926
std         146.705285
min           0.000000
25%         147.000000
50%         221.000000
75%         314.000000
max        9067.000000
Name: ingredients, dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The ingredient lists average 250 characters long, with a minimum of 0 and a maximum of nearly 10,000 characters!&lt;/p&gt;

&lt;p&gt;Just out of curiousity, let&amp;rsquo;s see which recipe has the longest ingredient list:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;recipes.name[np.argmax(recipes.ingredients.str.len())]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&#39;Carrot Pineapple Spice &amp;amp;amp; Brownie Layer Cake with Whipped Cream &amp;amp;amp; Cream Cheese Frosting and Marzipan Carrots&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That certainly looks like an involved recipe.&lt;/p&gt;

&lt;p&gt;We can do other aggregate explorations; for example, let&amp;rsquo;s see how many of the recipes are for breakfast food:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;recipes.description.str.contains(&#39;[Bb]reakfast&#39;).sum()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;3524
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or how many of the recipes list cinnamon as an ingredient:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;recipes.ingredients.str.contains(&#39;[Cc]innamon&#39;).sum()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;10526
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We could even look to see whether any recipes misspell the ingredient as &amp;laquo;cinamon&amp;raquo;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;recipes.ingredients.str.contains(&#39;[Cc]inamon&#39;).sum()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;11
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is the type of essential data exploration that is possible with Pandas string tools.
It is data munging like this that Python really excels at.&lt;/p&gt;

&lt;h3 id=&#34;a-simple-recipe-recommender&#34;&gt;A simple recipe recommender&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s go a bit further, and start working on a simple recipe recommendation system: given a list of ingredients, find a recipe that uses all those ingredients.
While conceptually straightforward, the task is complicated by the heterogeneity of the data: there is no easy operation, for example, to extract a clean list of ingredients from each row.
So we will cheat a bit: we&amp;rsquo;ll start with a list of common ingredients, and simply search to see whether they are in each recipe&amp;rsquo;s ingredient list.
For simplicity, let&amp;rsquo;s just stick with herbs and spices for the time being:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;spice_list = [&#39;salt&#39;, &#39;pepper&#39;, &#39;oregano&#39;, &#39;sage&#39;, &#39;parsley&#39;,
              &#39;rosemary&#39;, &#39;tarragon&#39;, &#39;thyme&#39;, &#39;paprika&#39;, &#39;cumin&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then build a Boolean &lt;code&gt;DataFrame&lt;/code&gt; consisting of True and False values, indicating whether this ingredient appears in the list:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import re
spice_df = pd.DataFrame(dict((spice, recipes.ingredients.str.contains(spice, re.IGNORECASE))
                             for spice in spice_list))
spice_df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;cumin&lt;/th&gt;
      &lt;th&gt;oregano&lt;/th&gt;
      &lt;th&gt;paprika&lt;/th&gt;
      &lt;th&gt;parsley&lt;/th&gt;
      &lt;th&gt;pepper&lt;/th&gt;
      &lt;th&gt;rosemary&lt;/th&gt;
      &lt;th&gt;sage&lt;/th&gt;
      &lt;th&gt;salt&lt;/th&gt;
      &lt;th&gt;tarragon&lt;/th&gt;
      &lt;th&gt;thyme&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Now, as an example, let&amp;rsquo;s say we&amp;rsquo;d like to find a recipe that uses parsley, paprika, and tarragon.
We can compute this very quickly using the &lt;code&gt;query()&lt;/code&gt; method of &lt;code&gt;DataFrame&lt;/code&gt;s, discussed in &lt;a href=&#34;03.12-Performance-Eval-and-Query.ipynb&#34; target=&#34;_blank&#34;&gt;High-Performance Pandas: &lt;code&gt;eval()&lt;/code&gt; and &lt;code&gt;query()&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;selection = spice_df.query(&#39;parsley &amp;amp; paprika &amp;amp; tarragon&#39;)
len(selection)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;10
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We find only 10 recipes with this combination; let&amp;rsquo;s use the index returned by this selection to discover the names of the recipes that have this combination:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;recipes.name[selection.index]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;2069      All cremat with a Little Gem, dandelion and wa...
74964                         Lobster with Thermidor butter
93768      Burton&#39;s Southern Fried Chicken with White Gravy
113926                     Mijo&#39;s Slow Cooker Shredded Beef
137686                     Asparagus Soup with Poached Eggs
140530                                 Fried Oyster Po’boys
158475                Lamb shank tagine with herb tabbouleh
158486                 Southern fried chicken in buttermilk
163175            Fried Chicken Sliders with Pickles + Slaw
165243                        Bar Tartine Cauliflower Salad
Name: name, dtype: object
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that we have narrowed down our recipe selection by a factor of almost 20,000, we are in a position to make a more informed decision about what we&amp;rsquo;d like to cook for dinner.&lt;/p&gt;

&lt;h3 id=&#34;going-further-with-recipes&#34;&gt;Going further with recipes&lt;/h3&gt;

&lt;p&gt;Hopefully this example has given you a bit of a flavor (ba-dum!) for the types of data cleaning operations that are efficiently enabled by Pandas string methods.
Of course, building a very robust recipe recommendation system would require a &lt;em&gt;lot&lt;/em&gt; more work!
Extracting full ingredient lists from each recipe would be an important piece of the task; unfortunately, the wide variety of formats used makes this a relatively time-consuming process.
This points to the truism that in data science, cleaning and munging of real-world data often comprises the majority of the work, and Pandas provides the tools that can help you do this efficiently.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Working with Time Series</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.11-working-with-time-series/03.11-working-with-time-series/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.11-working-with-time-series/03.11-working-with-time-series/</guid>
      <description>

&lt;p&gt;Pandas was developed in the context of financial modeling, so as you might expect, it contains a fairly extensive set of tools for working with dates, times, and time-indexed data.
Date and time data comes in a few flavors, which we will discuss here:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Time stamps&lt;/em&gt; reference particular moments in time (e.g., July 4th, 2015 at 7:00am).&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Time intervals&lt;/em&gt; and &lt;em&gt;periods&lt;/em&gt; reference a length of time between a particular beginning and end point; for example, the year 2015. Periods usually reference a special case of time intervals in which each interval is of uniform length and does not overlap (e.g., 24 hour-long periods comprising days).&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Time deltas&lt;/em&gt; or &lt;em&gt;durations&lt;/em&gt; reference an exact length of time (e.g., a duration of 22.56 seconds).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this section, we will introduce how to work with each of these types of date/time data in Pandas.
This short section is by no means a complete guide to the time series tools available in Python or Pandas, but instead is intended as a broad overview of how you as a user should approach working with time series.
We will start with a brief discussion of tools for dealing with dates and times in Python, before moving more specifically to a discussion of the tools provided by Pandas.
After listing some resources that go into more depth, we will review some short examples of working with time series data in Pandas.&lt;/p&gt;

&lt;h2 id=&#34;dates-and-times-in-python&#34;&gt;Dates and Times in Python&lt;/h2&gt;

&lt;p&gt;The Python world has a number of available representations of dates, times, deltas, and timespans.
While the time series tools provided by Pandas tend to be the most useful for data science applications, it is helpful to see their relationship to other packages used in Python.&lt;/p&gt;

&lt;h3 id=&#34;native-python-dates-and-times-datetime-and-dateutil&#34;&gt;Native Python dates and times: &lt;code&gt;datetime&lt;/code&gt; and &lt;code&gt;dateutil&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;Python&amp;rsquo;s basic objects for working with dates and times reside in the built-in &lt;code&gt;datetime&lt;/code&gt; module.
Along with the third-party &lt;code&gt;dateutil&lt;/code&gt; module, you can use it to quickly perform a host of useful functionalities on dates and times.
For example, you can manually build a date using the &lt;code&gt;datetime&lt;/code&gt; type:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from datetime import datetime
datetime(year=2015, month=7, day=4)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;datetime.datetime(2015, 7, 4, 0, 0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or, using the &lt;code&gt;dateutil&lt;/code&gt; module, you can parse dates from a variety of string formats:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from dateutil import parser
date = parser.parse(&amp;quot;4th of July, 2015&amp;quot;)
date
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;datetime.datetime(2015, 7, 4, 0, 0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once you have a &lt;code&gt;datetime&lt;/code&gt; object, you can do things like printing the day of the week:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;date.strftime(&#39;%A&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&#39;Saturday&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the final line, we&amp;rsquo;ve used one of the standard string format codes for printing dates (&lt;code&gt;&amp;quot;%A&amp;quot;&lt;/code&gt;), which you can read about in the &lt;a href=&#34;https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior&#34; target=&#34;_blank&#34;&gt;strftime section&lt;/a&gt; of Python&amp;rsquo;s &lt;a href=&#34;https://docs.python.org/3/library/datetime.html&#34; target=&#34;_blank&#34;&gt;datetime documentation&lt;/a&gt;.
Documentation of other useful date utilities can be found in &lt;a href=&#34;http://labix.org/python-dateutil&#34; target=&#34;_blank&#34;&gt;dateutil&amp;rsquo;s online documentation&lt;/a&gt;.
A related package to be aware of is &lt;a href=&#34;http://pytz.sourceforge.net/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;pytz&lt;/code&gt;&lt;/a&gt;, which contains tools for working with the most migrane-inducing piece of time series data: time zones.&lt;/p&gt;

&lt;p&gt;The power of &lt;code&gt;datetime&lt;/code&gt; and &lt;code&gt;dateutil&lt;/code&gt; lie in their flexibility and easy syntax: you can use these objects and their built-in methods to easily perform nearly any operation you might be interested in.
Where they break down is when you wish to work with large arrays of dates and times:
just as lists of Python numerical variables are suboptimal compared to NumPy-style typed numerical arrays, lists of Python datetime objects are suboptimal compared to typed arrays of encoded dates.&lt;/p&gt;

&lt;h3 id=&#34;typed-arrays-of-times-numpy-s-datetime64&#34;&gt;Typed arrays of times: NumPy&amp;rsquo;s &lt;code&gt;datetime64&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;The weaknesses of Python&amp;rsquo;s datetime format inspired the NumPy team to add a set of native time series data type to NumPy.
The &lt;code&gt;datetime64&lt;/code&gt; dtype encodes dates as 64-bit integers, and thus allows arrays of dates to be represented very compactly.
The &lt;code&gt;datetime64&lt;/code&gt; requires a very specific input format:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
date = np.array(&#39;2015-07-04&#39;, dtype=np.datetime64)
date
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array(datetime.date(2015, 7, 4), dtype=&#39;datetime64[D]&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once we have this date formatted, however, we can quickly do vectorized operations on it:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;date + np.arange(12)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([&#39;2015-07-04&#39;, &#39;2015-07-05&#39;, &#39;2015-07-06&#39;, &#39;2015-07-07&#39;,
       &#39;2015-07-08&#39;, &#39;2015-07-09&#39;, &#39;2015-07-10&#39;, &#39;2015-07-11&#39;,
       &#39;2015-07-12&#39;, &#39;2015-07-13&#39;, &#39;2015-07-14&#39;, &#39;2015-07-15&#39;], dtype=&#39;datetime64[D]&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Because of the uniform type in NumPy &lt;code&gt;datetime64&lt;/code&gt; arrays, this type of operation can be accomplished much more quickly than if we were working directly with Python&amp;rsquo;s &lt;code&gt;datetime&lt;/code&gt; objects, especially as arrays get large
(we introduced this type of vectorization in &lt;a href=&#34;02.03-Computation-on-arrays-ufuncs.ipynb&#34; target=&#34;_blank&#34;&gt;Computation on NumPy Arrays: Universal Functions&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;One detail of the &lt;code&gt;datetime64&lt;/code&gt; and &lt;code&gt;timedelta64&lt;/code&gt; objects is that they are built on a &lt;em&gt;fundamental time unit&lt;/em&gt;.
Because the &lt;code&gt;datetime64&lt;/code&gt; object is limited to 64-bit precision, the range of encodable times is $2^{64}$ times this fundamental unit.
In other words, &lt;code&gt;datetime64&lt;/code&gt; imposes a trade-off between &lt;em&gt;time resolution&lt;/em&gt; and &lt;em&gt;maximum time span&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;For example, if you want a time resolution of one nanosecond, you only have enough information to encode a range of $2^{64}$ nanoseconds, or just under 600 years.
NumPy will infer the desired unit from the input; for example, here is a day-based datetime:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;np.datetime64(&#39;2015-07-04&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;numpy.datetime64(&#39;2015-07-04&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here is a minute-based datetime:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;np.datetime64(&#39;2015-07-04 12:00&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;numpy.datetime64(&#39;2015-07-04T12:00&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice that the time zone is automatically set to the local time on the computer executing the code.
You can force any desired fundamental unit using one of many format codes; for example, here we&amp;rsquo;ll force a nanosecond-based time:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;np.datetime64(&#39;2015-07-04 12:59:59.50&#39;, &#39;ns&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;numpy.datetime64(&#39;2015-07-04T12:59:59.500000000&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The following table, drawn from the &lt;a href=&#34;http://docs.scipy.org/doc/numpy/reference/arrays.datetime.html&#34; target=&#34;_blank&#34;&gt;NumPy datetime64 documentation&lt;/a&gt;, lists the available format codes along with the relative and absolute timespans that they can encode:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Code&lt;/th&gt;
&lt;th&gt;Meaning&lt;/th&gt;
&lt;th&gt;Time span (relative)&lt;/th&gt;
&lt;th&gt;Time span (absolute)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Y&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Year&lt;/td&gt;
&lt;td&gt;± 9.2e18 years&lt;/td&gt;
&lt;td&gt;[9.2e18 BC, 9.2e18 AD]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;M&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Month&lt;/td&gt;
&lt;td&gt;± 7.6e17 years&lt;/td&gt;
&lt;td&gt;[7.6e17 BC, 7.6e17 AD]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;W&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Week&lt;/td&gt;
&lt;td&gt;± 1.7e17 years&lt;/td&gt;
&lt;td&gt;[1.7e17 BC, 1.7e17 AD]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;D&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Day&lt;/td&gt;
&lt;td&gt;± 2.5e16 years&lt;/td&gt;
&lt;td&gt;[2.5e16 BC, 2.5e16 AD]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;h&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Hour&lt;/td&gt;
&lt;td&gt;± 1.0e15 years&lt;/td&gt;
&lt;td&gt;[1.0e15 BC, 1.0e15 AD]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;m&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Minute&lt;/td&gt;
&lt;td&gt;± 1.7e13 years&lt;/td&gt;
&lt;td&gt;[1.7e13 BC, 1.7e13 AD]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;s&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Second&lt;/td&gt;
&lt;td&gt;± 2.9e12 years&lt;/td&gt;
&lt;td&gt;[ 2.9e9 BC, 2.9e9 AD]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ms&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Millisecond&lt;/td&gt;
&lt;td&gt;± 2.9e9 years&lt;/td&gt;
&lt;td&gt;[ 2.9e6 BC, 2.9e6 AD]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;us&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Microsecond&lt;/td&gt;
&lt;td&gt;± 2.9e6 years&lt;/td&gt;
&lt;td&gt;[290301 BC, 294241 AD]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ns&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Nanosecond&lt;/td&gt;
&lt;td&gt;± 292 years&lt;/td&gt;
&lt;td&gt;[ 1678 AD, 2262 AD]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ps&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Picosecond&lt;/td&gt;
&lt;td&gt;± 106 days&lt;/td&gt;
&lt;td&gt;[ 1969 AD, 1970 AD]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;fs&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Femtosecond&lt;/td&gt;
&lt;td&gt;± 2.6 hours&lt;/td&gt;
&lt;td&gt;[ 1969 AD, 1970 AD]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;as&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Attosecond&lt;/td&gt;
&lt;td&gt;± 9.2 seconds&lt;/td&gt;
&lt;td&gt;[ 1969 AD, 1970 AD]&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;For the types of data we see in the real world, a useful default is &lt;code&gt;datetime64[ns]&lt;/code&gt;, as it can encode a useful range of modern dates with a suitably fine precision.&lt;/p&gt;

&lt;p&gt;Finally, we will note that while the &lt;code&gt;datetime64&lt;/code&gt; data type addresses some of the deficiencies of the built-in Python &lt;code&gt;datetime&lt;/code&gt; type, it lacks many of the convenient methods and functions provided by &lt;code&gt;datetime&lt;/code&gt; and especially &lt;code&gt;dateutil&lt;/code&gt;.
More information can be found in &lt;a href=&#34;http://docs.scipy.org/doc/numpy/reference/arrays.datetime.html&#34; target=&#34;_blank&#34;&gt;NumPy&amp;rsquo;s datetime64 documentation&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;dates-and-times-in-pandas-best-of-both-worlds&#34;&gt;Dates and times in pandas: best of both worlds&lt;/h3&gt;

&lt;p&gt;Pandas builds upon all the tools just discussed to provide a &lt;code&gt;Timestamp&lt;/code&gt; object, which combines the ease-of-use of &lt;code&gt;datetime&lt;/code&gt; and &lt;code&gt;dateutil&lt;/code&gt; with the efficient storage and vectorized interface of &lt;code&gt;numpy.datetime64&lt;/code&gt;.
From a group of these &lt;code&gt;Timestamp&lt;/code&gt; objects, Pandas can construct a &lt;code&gt;DatetimeIndex&lt;/code&gt; that can be used to index data in a &lt;code&gt;Series&lt;/code&gt; or &lt;code&gt;DataFrame&lt;/code&gt;; we&amp;rsquo;ll see many examples of this below.&lt;/p&gt;

&lt;p&gt;For example, we can use Pandas tools to repeat the demonstration from above.
We can parse a flexibly formatted string date, and use format codes to output the day of the week:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
date = pd.to_datetime(&amp;quot;4th of July, 2015&amp;quot;)
date
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Timestamp(&#39;2015-07-04 00:00:00&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;date.strftime(&#39;%A&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&#39;Saturday&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Additionally, we can do NumPy-style vectorized operations directly on this same object:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;date + pd.to_timedelta(np.arange(12), &#39;D&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;DatetimeIndex([&#39;2015-07-04&#39;, &#39;2015-07-05&#39;, &#39;2015-07-06&#39;, &#39;2015-07-07&#39;,
               &#39;2015-07-08&#39;, &#39;2015-07-09&#39;, &#39;2015-07-10&#39;, &#39;2015-07-11&#39;,
               &#39;2015-07-12&#39;, &#39;2015-07-13&#39;, &#39;2015-07-14&#39;, &#39;2015-07-15&#39;],
              dtype=&#39;datetime64[ns]&#39;, freq=None)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the next section, we will take a closer look at manipulating time series data with the tools provided by Pandas.&lt;/p&gt;

&lt;h2 id=&#34;pandas-time-series-indexing-by-time&#34;&gt;Pandas Time Series: Indexing by Time&lt;/h2&gt;

&lt;p&gt;Where the Pandas time series tools really become useful is when you begin to &lt;em&gt;index data by timestamps&lt;/em&gt;.
For example, we can construct a &lt;code&gt;Series&lt;/code&gt; object that has time indexed data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;index = pd.DatetimeIndex([&#39;2014-07-04&#39;, &#39;2014-08-04&#39;,
                          &#39;2015-07-04&#39;, &#39;2015-08-04&#39;])
data = pd.Series([0, 1, 2, 3], index=index)
data
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;2014-07-04    0
2014-08-04    1
2015-07-04    2
2015-08-04    3
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that we have this data in a &lt;code&gt;Series&lt;/code&gt;, we can make use of any of the &lt;code&gt;Series&lt;/code&gt; indexing patterns we discussed in previous sections, passing values that can be coerced into dates:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data[&#39;2014-07-04&#39;:&#39;2015-07-04&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;2014-07-04    0
2014-08-04    1
2015-07-04    2
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are additional special date-only indexing operations, such as passing a year to obtain a slice of all data from that year:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data[&#39;2015&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;2015-07-04    2
2015-08-04    3
dtype: int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Later, we will see additional examples of the convenience of dates-as-indices.
But first, a closer look at the available time series data structures.&lt;/p&gt;

&lt;h2 id=&#34;pandas-time-series-data-structures&#34;&gt;Pandas Time Series Data Structures&lt;/h2&gt;

&lt;p&gt;This section will introduce the fundamental Pandas data structures for working with time series data:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;For &lt;em&gt;time stamps&lt;/em&gt;, Pandas provides the &lt;code&gt;Timestamp&lt;/code&gt; type. As mentioned before, it is essentially a replacement for Python&amp;rsquo;s native &lt;code&gt;datetime&lt;/code&gt;, but is based on the more efficient &lt;code&gt;numpy.datetime64&lt;/code&gt; data type. The associated Index structure is &lt;code&gt;DatetimeIndex&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;For &lt;em&gt;time Periods&lt;/em&gt;, Pandas provides the &lt;code&gt;Period&lt;/code&gt; type. This encodes a fixed-frequency interval based on &lt;code&gt;numpy.datetime64&lt;/code&gt;. The associated index structure is &lt;code&gt;PeriodIndex&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;For &lt;em&gt;time deltas&lt;/em&gt; or &lt;em&gt;durations&lt;/em&gt;, Pandas provides the &lt;code&gt;Timedelta&lt;/code&gt; type. &lt;code&gt;Timedelta&lt;/code&gt; is a more efficient replacement for Python&amp;rsquo;s native &lt;code&gt;datetime.timedelta&lt;/code&gt; type, and is based on &lt;code&gt;numpy.timedelta64&lt;/code&gt;. The associated index structure is &lt;code&gt;TimedeltaIndex&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The most fundamental of these date/time objects are the &lt;code&gt;Timestamp&lt;/code&gt; and &lt;code&gt;DatetimeIndex&lt;/code&gt; objects.
While these class objects can be invoked directly, it is more common to use the &lt;code&gt;pd.to_datetime()&lt;/code&gt; function, which can parse a wide variety of formats.
Passing a single date to &lt;code&gt;pd.to_datetime()&lt;/code&gt; yields a &lt;code&gt;Timestamp&lt;/code&gt;; passing a series of dates by default yields a &lt;code&gt;DatetimeIndex&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dates = pd.to_datetime([datetime(2015, 7, 3), &#39;4th of July, 2015&#39;,
                       &#39;2015-Jul-6&#39;, &#39;07-07-2015&#39;, &#39;20150708&#39;])
dates
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;DatetimeIndex([&#39;2015-07-03&#39;, &#39;2015-07-04&#39;, &#39;2015-07-06&#39;, &#39;2015-07-07&#39;,
               &#39;2015-07-08&#39;],
              dtype=&#39;datetime64[ns]&#39;, freq=None)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Any &lt;code&gt;DatetimeIndex&lt;/code&gt; can be converted to a &lt;code&gt;PeriodIndex&lt;/code&gt; with the &lt;code&gt;to_period()&lt;/code&gt; function with the addition of a frequency code; here we&amp;rsquo;ll use &lt;code&gt;&#39;D&#39;&lt;/code&gt; to indicate daily frequency:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dates.to_period(&#39;D&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;PeriodIndex([&#39;2015-07-03&#39;, &#39;2015-07-04&#39;, &#39;2015-07-06&#39;, &#39;2015-07-07&#39;,
             &#39;2015-07-08&#39;],
            dtype=&#39;int64&#39;, freq=&#39;D&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A &lt;code&gt;TimedeltaIndex&lt;/code&gt; is created, for example, when a date is subtracted from another:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dates - dates[0]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;TimedeltaIndex([&#39;0 days&#39;, &#39;1 days&#39;, &#39;3 days&#39;, &#39;4 days&#39;, &#39;5 days&#39;], dtype=&#39;timedelta64[ns]&#39;, freq=None)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;regular-sequences-pd-date-range&#34;&gt;Regular sequences: &lt;code&gt;pd.date_range()&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;To make the creation of regular date sequences more convenient, Pandas offers a few functions for this purpose: &lt;code&gt;pd.date_range()&lt;/code&gt; for timestamps, &lt;code&gt;pd.period_range()&lt;/code&gt; for periods, and &lt;code&gt;pd.timedelta_range()&lt;/code&gt; for time deltas.
We&amp;rsquo;ve seen that Python&amp;rsquo;s &lt;code&gt;range()&lt;/code&gt; and NumPy&amp;rsquo;s &lt;code&gt;np.arange()&lt;/code&gt; turn a startpoint, endpoint, and optional stepsize into a sequence.
Similarly, &lt;code&gt;pd.date_range()&lt;/code&gt; accepts a start date, an end date, and an optional frequency code to create a regular sequence of dates.
By default, the frequency is one day:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.date_range(&#39;2015-07-03&#39;, &#39;2015-07-10&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;DatetimeIndex([&#39;2015-07-03&#39;, &#39;2015-07-04&#39;, &#39;2015-07-05&#39;, &#39;2015-07-06&#39;,
               &#39;2015-07-07&#39;, &#39;2015-07-08&#39;, &#39;2015-07-09&#39;, &#39;2015-07-10&#39;],
              dtype=&#39;datetime64[ns]&#39;, freq=&#39;D&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alternatively, the date range can be specified not with a start and endpoint, but with a startpoint and a number of periods:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.date_range(&#39;2015-07-03&#39;, periods=8)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;DatetimeIndex([&#39;2015-07-03&#39;, &#39;2015-07-04&#39;, &#39;2015-07-05&#39;, &#39;2015-07-06&#39;,
               &#39;2015-07-07&#39;, &#39;2015-07-08&#39;, &#39;2015-07-09&#39;, &#39;2015-07-10&#39;],
              dtype=&#39;datetime64[ns]&#39;, freq=&#39;D&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The spacing can be modified by altering the &lt;code&gt;freq&lt;/code&gt; argument, which defaults to &lt;code&gt;D&lt;/code&gt;.
For example, here we will construct a range of hourly timestamps:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.date_range(&#39;2015-07-03&#39;, periods=8, freq=&#39;H&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;DatetimeIndex([&#39;2015-07-03 00:00:00&#39;, &#39;2015-07-03 01:00:00&#39;,
               &#39;2015-07-03 02:00:00&#39;, &#39;2015-07-03 03:00:00&#39;,
               &#39;2015-07-03 04:00:00&#39;, &#39;2015-07-03 05:00:00&#39;,
               &#39;2015-07-03 06:00:00&#39;, &#39;2015-07-03 07:00:00&#39;],
              dtype=&#39;datetime64[ns]&#39;, freq=&#39;H&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To create regular sequences of &lt;code&gt;Period&lt;/code&gt; or &lt;code&gt;Timedelta&lt;/code&gt; values, the very similar &lt;code&gt;pd.period_range()&lt;/code&gt; and &lt;code&gt;pd.timedelta_range()&lt;/code&gt; functions are useful.
Here are some monthly periods:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.period_range(&#39;2015-07&#39;, periods=8, freq=&#39;M&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;PeriodIndex([&#39;2015-07&#39;, &#39;2015-08&#39;, &#39;2015-09&#39;, &#39;2015-10&#39;, &#39;2015-11&#39;, &#39;2015-12&#39;,
             &#39;2016-01&#39;, &#39;2016-02&#39;],
            dtype=&#39;int64&#39;, freq=&#39;M&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And a sequence of durations increasing by an hour:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.timedelta_range(0, periods=10, freq=&#39;H&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;TimedeltaIndex([&#39;00:00:00&#39;, &#39;01:00:00&#39;, &#39;02:00:00&#39;, &#39;03:00:00&#39;, &#39;04:00:00&#39;,
                &#39;05:00:00&#39;, &#39;06:00:00&#39;, &#39;07:00:00&#39;, &#39;08:00:00&#39;, &#39;09:00:00&#39;],
               dtype=&#39;timedelta64[ns]&#39;, freq=&#39;H&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All of these require an understanding of Pandas frequency codes, which we&amp;rsquo;ll summarize in the next section.&lt;/p&gt;

&lt;h2 id=&#34;frequencies-and-offsets&#34;&gt;Frequencies and Offsets&lt;/h2&gt;

&lt;p&gt;Fundamental to these Pandas time series tools is the concept of a frequency or date offset.
Just as we saw the &lt;code&gt;D&lt;/code&gt; (day) and &lt;code&gt;H&lt;/code&gt; (hour) codes above, we can use such codes to specify any desired frequency spacing.
The following table summarizes the main codes available:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Code&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Code&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;D&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Calendar day&lt;/td&gt;
&lt;td&gt;&lt;code&gt;B&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Business day&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;W&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Weekly&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;M&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Month end&lt;/td&gt;
&lt;td&gt;&lt;code&gt;BM&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Business month end&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Q&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Quarter end&lt;/td&gt;
&lt;td&gt;&lt;code&gt;BQ&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Business quarter end&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;A&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Year end&lt;/td&gt;
&lt;td&gt;&lt;code&gt;BA&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Business year end&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;H&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Hours&lt;/td&gt;
&lt;td&gt;&lt;code&gt;BH&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Business hours&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;T&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Minutes&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;S&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Seconds&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;L&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Milliseonds&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;U&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Microseconds&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;N&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;nanoseconds&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The monthly, quarterly, and annual frequencies are all marked at the end of the specified period.
By adding an &lt;code&gt;S&lt;/code&gt; suffix to any of these, they instead will be marked at the beginning:&lt;/p&gt;

&lt;p&gt;| Code    | Description            || Code    | Description            |
|&amp;mdash;&amp;mdash;&amp;mdash;|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;||&amp;mdash;&amp;mdash;&amp;mdash;|&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;|
| &lt;code&gt;MS&lt;/code&gt;  | Month start            ||&lt;code&gt;BMS&lt;/code&gt;  | Business month start   |
| &lt;code&gt;QS&lt;/code&gt;  | Quarter start          ||&lt;code&gt;BQS&lt;/code&gt;  | Business quarter start |
| &lt;code&gt;AS&lt;/code&gt;  | Year start             ||&lt;code&gt;BAS&lt;/code&gt;  | Business year start    |&lt;/p&gt;

&lt;p&gt;Additionally, you can change the month used to mark any quarterly or annual code by adding a three-letter month code as a suffix:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Q-JAN&lt;/code&gt;, &lt;code&gt;BQ-FEB&lt;/code&gt;, &lt;code&gt;QS-MAR&lt;/code&gt;, &lt;code&gt;BQS-APR&lt;/code&gt;, etc.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;A-JAN&lt;/code&gt;, &lt;code&gt;BA-FEB&lt;/code&gt;, &lt;code&gt;AS-MAR&lt;/code&gt;, &lt;code&gt;BAS-APR&lt;/code&gt;, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the same way, the split-point of the weekly frequency can be modified by adding a three-letter weekday code:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;W-SUN&lt;/code&gt;, &lt;code&gt;W-MON&lt;/code&gt;, &lt;code&gt;W-TUE&lt;/code&gt;, &lt;code&gt;W-WED&lt;/code&gt;, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On top of this, codes can be combined with numbers to specify other frequencies.
For example, for a frequency of 2 hours 30 minutes, we can combine the hour (&lt;code&gt;H&lt;/code&gt;) and minute (&lt;code&gt;T&lt;/code&gt;) codes as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.timedelta_range(0, periods=9, freq=&amp;quot;2H30T&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;TimedeltaIndex([&#39;00:00:00&#39;, &#39;02:30:00&#39;, &#39;05:00:00&#39;, &#39;07:30:00&#39;, &#39;10:00:00&#39;,
                &#39;12:30:00&#39;, &#39;15:00:00&#39;, &#39;17:30:00&#39;, &#39;20:00:00&#39;],
               dtype=&#39;timedelta64[ns]&#39;, freq=&#39;150T&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All of these short codes refer to specific instances of Pandas time series offsets, which can be found in the &lt;code&gt;pd.tseries.offsets&lt;/code&gt; module.
For example, we can create a business day offset directly as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pandas.tseries.offsets import BDay
pd.date_range(&#39;2015-07-01&#39;, periods=5, freq=BDay())
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;DatetimeIndex([&#39;2015-07-01&#39;, &#39;2015-07-02&#39;, &#39;2015-07-03&#39;, &#39;2015-07-06&#39;,
               &#39;2015-07-07&#39;],
              dtype=&#39;datetime64[ns]&#39;, freq=&#39;B&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For more discussion of the use of frequencies and offsets, see the &lt;a href=&#34;http://pandas.pydata.org/pandas-docs/stable/timeseries.html#dateoffset-objects&#34; target=&#34;_blank&#34;&gt;&amp;laquo;DateOffset&amp;raquo; section&lt;/a&gt; of the Pandas documentation.&lt;/p&gt;

&lt;h2 id=&#34;resampling-shifting-and-windowing&#34;&gt;Resampling, Shifting, and Windowing&lt;/h2&gt;

&lt;p&gt;The ability to use dates and times as indices to intuitively organize and access data is an important piece of the Pandas time series tools.
The benefits of indexed data in general (automatic alignment during operations, intuitive data slicing and access, etc.) still apply, and Pandas provides several additional time series-specific operations.&lt;/p&gt;

&lt;p&gt;We will take a look at a few of those here, using some stock price data as an example.
Because Pandas was developed largely in a finance context, it includes some very specific tools for financial data.
For example, the accompanying &lt;code&gt;pandas-datareader&lt;/code&gt; package (installable via &lt;code&gt;conda install pandas-datareader&lt;/code&gt;), knows how to import financial data from a number of available sources, including Yahoo finance, Google Finance, and others.
Here we will load Google&amp;rsquo;s closing price history:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pandas_datareader import data

goog = data.DataReader(&#39;GOOG&#39;, start=&#39;2004&#39;, end=&#39;2016&#39;,
                       data_source=&#39;google&#39;)
goog.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Open&lt;/th&gt;
      &lt;th&gt;High&lt;/th&gt;
      &lt;th&gt;Low&lt;/th&gt;
      &lt;th&gt;Close&lt;/th&gt;
      &lt;th&gt;Volume&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Date&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2004-08-19&lt;/th&gt;
      &lt;td&gt;49.96&lt;/td&gt;
      &lt;td&gt;51.98&lt;/td&gt;
      &lt;td&gt;47.93&lt;/td&gt;
      &lt;td&gt;50.12&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2004-08-20&lt;/th&gt;
      &lt;td&gt;50.69&lt;/td&gt;
      &lt;td&gt;54.49&lt;/td&gt;
      &lt;td&gt;50.20&lt;/td&gt;
      &lt;td&gt;54.10&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2004-08-23&lt;/th&gt;
      &lt;td&gt;55.32&lt;/td&gt;
      &lt;td&gt;56.68&lt;/td&gt;
      &lt;td&gt;54.47&lt;/td&gt;
      &lt;td&gt;54.65&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2004-08-24&lt;/th&gt;
      &lt;td&gt;55.56&lt;/td&gt;
      &lt;td&gt;55.74&lt;/td&gt;
      &lt;td&gt;51.73&lt;/td&gt;
      &lt;td&gt;52.38&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2004-08-25&lt;/th&gt;
      &lt;td&gt;52.43&lt;/td&gt;
      &lt;td&gt;53.95&lt;/td&gt;
      &lt;td&gt;51.89&lt;/td&gt;
      &lt;td&gt;52.95&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;For simplicity, we&amp;rsquo;ll use just the closing price:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;goog = goog[&#39;Close&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can visualize this using the &lt;code&gt;plot()&lt;/code&gt; method, after the normal Matplotlib setup boilerplate (see &lt;a href=&#34;04.00-Introduction-To-Matplotlib.ipynb&#34; target=&#34;_blank&#34;&gt;Chapter 4&lt;/a&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import matplotlib.pyplot as plt
import seaborn; seaborn.set()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;goog.plot();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../output_71_0.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;resampling-and-converting-frequencies&#34;&gt;Resampling and converting frequencies&lt;/h3&gt;

&lt;p&gt;One common need for time series data is resampling at a higher or lower frequency.
This can be done using the &lt;code&gt;resample()&lt;/code&gt; method, or the much simpler &lt;code&gt;asfreq()&lt;/code&gt; method.
The primary difference between the two is that &lt;code&gt;resample()&lt;/code&gt; is fundamentally a &lt;em&gt;data aggregation&lt;/em&gt;, while &lt;code&gt;asfreq()&lt;/code&gt; is fundamentally a &lt;em&gt;data selection&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Taking a look at the Google closing price, let&amp;rsquo;s compare what the two return when we down-sample the data.
Here we will resample the data at the end of business year:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;goog.plot(alpha=0.5, style=&#39;-&#39;)
goog.resample(&#39;BA&#39;).mean().plot(style=&#39;:&#39;)
goog.asfreq(&#39;BA&#39;).plot(style=&#39;--&#39;);
plt.legend([&#39;input&#39;, &#39;resample&#39;, &#39;asfreq&#39;],
           loc=&#39;upper left&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../output_73_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Notice the difference: at each point, &lt;code&gt;resample&lt;/code&gt; reports the &lt;em&gt;average of the previous year&lt;/em&gt;, while &lt;code&gt;asfreq&lt;/code&gt; reports the &lt;em&gt;value at the end of the year&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;For up-sampling, &lt;code&gt;resample()&lt;/code&gt; and &lt;code&gt;asfreq()&lt;/code&gt; are largely equivalent, though resample has many more options available.
In this case, the default for both methods is to leave the up-sampled points empty, that is, filled with NA values.
Just as with the &lt;code&gt;pd.fillna()&lt;/code&gt; function discussed previously, &lt;code&gt;asfreq()&lt;/code&gt; accepts a &lt;code&gt;method&lt;/code&gt; argument to specify how values are imputed.
Here, we will resample the business day data at a daily frequency (i.e., including weekends):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig, ax = plt.subplots(2, sharex=True)
data = goog.iloc[:10]

data.asfreq(&#39;D&#39;).plot(ax=ax[0], marker=&#39;o&#39;)

data.asfreq(&#39;D&#39;, method=&#39;bfill&#39;).plot(ax=ax[1], style=&#39;-o&#39;)
data.asfreq(&#39;D&#39;, method=&#39;ffill&#39;).plot(ax=ax[1], style=&#39;--o&#39;)
ax[1].legend([&amp;quot;back-fill&amp;quot;, &amp;quot;forward-fill&amp;quot;]);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../output_76_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The top panel is the default: non-business days are left as NA values and do not appear on the plot.
The bottom panel shows the differences between two strategies for filling the gaps: forward-filling and backward-filling.&lt;/p&gt;

&lt;h3 id=&#34;time-shifts&#34;&gt;Time-shifts&lt;/h3&gt;

&lt;p&gt;Another common time series-specific operation is shifting of data in time.
Pandas has two closely related methods for computing this: &lt;code&gt;shift()&lt;/code&gt; and &lt;code&gt;tshift()&lt;/code&gt;
In short, the difference between them is that &lt;code&gt;shift()&lt;/code&gt; &lt;em&gt;shifts the data&lt;/em&gt;, while &lt;code&gt;tshift()&lt;/code&gt; &lt;em&gt;shifts the index&lt;/em&gt;.
In both cases, the shift is specified in multiples of the frequency.&lt;/p&gt;

&lt;p&gt;Here we will both &lt;code&gt;shift()&lt;/code&gt; and &lt;code&gt;tshift()&lt;/code&gt; by 900 days;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig, ax = plt.subplots(3, sharey=True)

# apply a frequency to the data
goog = goog.asfreq(&#39;D&#39;, method=&#39;pad&#39;)

goog.plot(ax=ax[0])
goog.shift(900).plot(ax=ax[1])
goog.tshift(900).plot(ax=ax[2])

# legends and annotations
local_max = pd.to_datetime(&#39;2007-11-05&#39;)
offset = pd.Timedelta(900, &#39;D&#39;)

ax[0].legend([&#39;input&#39;], loc=2)
ax[0].get_xticklabels()[2].set(weight=&#39;heavy&#39;, color=&#39;red&#39;)
ax[0].axvline(local_max, alpha=0.3, color=&#39;red&#39;)

ax[1].legend([&#39;shift(900)&#39;], loc=2)
ax[1].get_xticklabels()[2].set(weight=&#39;heavy&#39;, color=&#39;red&#39;)
ax[1].axvline(local_max + offset, alpha=0.3, color=&#39;red&#39;)

ax[2].legend([&#39;tshift(900)&#39;], loc=2)
ax[2].get_xticklabels()[1].set(weight=&#39;heavy&#39;, color=&#39;red&#39;)
ax[2].axvline(local_max + offset, alpha=0.3, color=&#39;red&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_79_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We see here that &lt;code&gt;shift(900)&lt;/code&gt; shifts the &lt;em&gt;data&lt;/em&gt; by 900 days, pushing some of it off the end of the graph (and leaving NA values at the other end), while &lt;code&gt;tshift(900)&lt;/code&gt; shifts the &lt;em&gt;index values&lt;/em&gt; by 900 days.&lt;/p&gt;

&lt;p&gt;A common context for this type of shift is in computing differences over time. For example, we use shifted values to compute the one-year return on investment for Google stock over the course of the dataset:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ROI = 100 * (goog.tshift(-365) / goog - 1)
ROI.plot()
plt.ylabel(&#39;% Return on Investment&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_81_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This helps us to see the overall trend in Google stock: thus far, the most profitable times to invest in Google have been (unsurprisingly, in retrospect) shortly after its IPO, and in the middle of the 2009 recession.&lt;/p&gt;

&lt;h3 id=&#34;rolling-windows&#34;&gt;Rolling windows&lt;/h3&gt;

&lt;p&gt;Rolling statistics are a third type of time series-specific operation implemented by Pandas.
These can be accomplished via the &lt;code&gt;rolling()&lt;/code&gt; attribute of &lt;code&gt;Series&lt;/code&gt; and &lt;code&gt;DataFrame&lt;/code&gt; objects, which returns a view similar to what we saw with the &lt;code&gt;groupby&lt;/code&gt; operation (see &lt;a href=&#34;03.08-Aggregation-and-Grouping.ipynb&#34; target=&#34;_blank&#34;&gt;Aggregation and Grouping&lt;/a&gt;).
This rolling view makes available a number of aggregation operations by default.&lt;/p&gt;

&lt;p&gt;For example, here is the one-year centered rolling mean and standard deviation of the Google stock prices:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;rolling = goog.rolling(365, center=True)

data = pd.DataFrame({&#39;input&#39;: goog,
                     &#39;one-year rolling_mean&#39;: rolling.mean(),
                     &#39;one-year rolling_std&#39;: rolling.std()})
ax = data.plot(style=[&#39;-&#39;, &#39;--&#39;, &#39;:&#39;])
ax.lines[0].set_alpha(0.3)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_84_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;As with group-by operations, the &lt;code&gt;aggregate()&lt;/code&gt; and &lt;code&gt;apply()&lt;/code&gt; methods can be used for custom rolling computations.&lt;/p&gt;

&lt;h2 id=&#34;where-to-learn-more&#34;&gt;Where to Learn More&lt;/h2&gt;

&lt;p&gt;This section has provided only a brief summary of some of the most essential features of time series tools provided by Pandas; for a more complete discussion, you can refer to the &lt;a href=&#34;http://pandas.pydata.org/pandas-docs/stable/timeseries.html&#34; target=&#34;_blank&#34;&gt;&amp;laquo;Time Series/Date&amp;raquo; section&lt;/a&gt; of the Pandas online documentation.&lt;/p&gt;

&lt;p&gt;Another excellent resource is the textbook &lt;a href=&#34;http://shop.oreilly.com/product/0636920023784.do&#34; target=&#34;_blank&#34;&gt;Python for Data Analysis&lt;/a&gt; by Wes McKinney (OReilly, 2012).
Although it is now a few years old, it is an invaluable resource on the use of Pandas.
In particular, this book emphasizes time series tools in the context of business and finance, and focuses much more on particular details of business calendars, time zones, and related topics.&lt;/p&gt;

&lt;p&gt;As always, you can also use the IPython help functionality to explore and try further options available to the functions and methods discussed here. I find this often is the best way to learn a new Python tool.&lt;/p&gt;

&lt;h2 id=&#34;example-visualizing-seattle-bicycle-counts&#34;&gt;Example: Visualizing Seattle Bicycle Counts&lt;/h2&gt;

&lt;p&gt;As a more involved example of working with some time series data, let&amp;rsquo;s take a look at bicycle counts on Seattle&amp;rsquo;s &lt;a href=&#34;http://www.openstreetmap.org/#map=17/47.64813/-122.34965&#34; target=&#34;_blank&#34;&gt;Fremont Bridge&lt;/a&gt;.
This data comes from an automated bicycle counter, installed in late 2012, which has inductive sensors on the east and west sidewalks of the bridge.
The hourly bicycle counts can be downloaded from &lt;a href=&#34;http://data.seattle.gov/&#34; target=&#34;_blank&#34;&gt;http://data.seattle.gov/&lt;/a&gt;; here is the &lt;a href=&#34;https://data.seattle.gov/Transportation/Fremont-Bridge-Hourly-Bicycle-Counts-by-Month-Octo/65db-xm6k&#34; target=&#34;_blank&#34;&gt;direct link to the dataset&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As of summer 2016, the CSV can be downloaded as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!curl -o FremontBridge.csv https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once this dataset is downloaded, we can use Pandas to read the CSV output into a &lt;code&gt;DataFrame&lt;/code&gt;.
We will specify that we want the Date as an index, and we want these dates to be automatically parsed:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
data = pd.read_csv(&#39;FremontBridge.csv&#39;, index_col=&#39;Date&#39;, parse_dates=True)
data.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Fremont Bridge East Sidewalk&lt;/th&gt;
      &lt;th&gt;Fremont Bridge West Sidewalk&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Date&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;2015-02-24 02:00:00&lt;/th&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2019-01-01 00:00:00&lt;/th&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;9.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2019-01-01 01:00:00&lt;/th&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;22.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2016-02-15 00:00:00&lt;/th&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2019-01-01 02:00:00&lt;/th&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;For convenience, we&amp;rsquo;ll further process this dataset by shortening the column names and adding a &amp;laquo;Total&amp;raquo; column:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.columns = [&#39;West&#39;, &#39;East&#39;]
data[&#39;Total&#39;] = data.eval(&#39;West + East&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now let&amp;rsquo;s take a look at the summary statistics for this data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.dropna().describe()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;West&lt;/th&gt;
      &lt;th&gt;East&lt;/th&gt;
      &lt;th&gt;Total&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;count&lt;/th&gt;
      &lt;td&gt;59823.000000&lt;/td&gt;
      &lt;td&gt;59823.000000&lt;/td&gt;
      &lt;td&gt;59823.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;mean&lt;/th&gt;
      &lt;td&gt;52.619795&lt;/td&gt;
      &lt;td&gt;60.262324&lt;/td&gt;
      &lt;td&gt;112.882119&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;std&lt;/th&gt;
      &lt;td&gt;67.734326&lt;/td&gt;
      &lt;td&gt;87.871363&lt;/td&gt;
      &lt;td&gt;143.101423&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;min&lt;/th&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;25%&lt;/th&gt;
      &lt;td&gt;6.500000&lt;/td&gt;
      &lt;td&gt;7.000000&lt;/td&gt;
      &lt;td&gt;15.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;50%&lt;/th&gt;
      &lt;td&gt;29.000000&lt;/td&gt;
      &lt;td&gt;30.000000&lt;/td&gt;
      &lt;td&gt;61.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;75%&lt;/th&gt;
      &lt;td&gt;70.000000&lt;/td&gt;
      &lt;td&gt;73.000000&lt;/td&gt;
      &lt;td&gt;147.000000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;max&lt;/th&gt;
      &lt;td&gt;698.000000&lt;/td&gt;
      &lt;td&gt;850.000000&lt;/td&gt;
      &lt;td&gt;1097.000000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&#34;visualizing-the-data&#34;&gt;Visualizing the data&lt;/h3&gt;

&lt;p&gt;We can gain some insight into the dataset by visualizing it.
Let&amp;rsquo;s start by plotting the raw data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import seaborn; seaborn.set()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data.plot()
plt.ylabel(&#39;Hourly Bicycle Count&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_97_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The ~25,000 hourly samples are far too dense for us to make much sense of.
We can gain more insight by resampling the data to a coarser grid.
Let&amp;rsquo;s resample by week:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;weekly = data.resample(&#39;W&#39;).sum()
weekly.plot(style=[&#39;:&#39;, &#39;--&#39;, &#39;-&#39;])
plt.ylabel(&#39;Weekly bicycle count&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_99_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This shows us some interesting seasonal trends: as you might expect, people bicycle more in the summer than in the winter, and even within a particular season the bicycle use varies from week to week (likely dependent on weather; see &lt;a href=&#34;05.06-Linear-Regression.ipynb&#34; target=&#34;_blank&#34;&gt;In Depth: Linear Regression&lt;/a&gt; where we explore this further).&lt;/p&gt;

&lt;p&gt;Another way that comes in handy for aggregating the data is to use a rolling mean, utilizing the &lt;code&gt;pd.rolling_mean()&lt;/code&gt; function.
Here we&amp;rsquo;ll do a 30 day rolling mean of our data, making sure to center the window:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;daily = data.resample(&#39;D&#39;).sum()
daily.rolling(30, center=True).sum().plot(style=[&#39;:&#39;, &#39;--&#39;, &#39;-&#39;])
plt.ylabel(&#39;mean hourly count&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_101_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The jaggedness of the result is due to the hard cutoff of the window.
We can get a smoother version of a rolling mean using a window function–for example, a Gaussian window.
The following code specifies both the width of the window (we chose 50 days) and the width of the Gaussian within the window (we chose 10 days):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;daily.rolling(50, center=True,
              win_type=&#39;gaussian&#39;).sum(std=10).plot(style=[&#39;:&#39;, &#39;--&#39;, &#39;-&#39;]);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_103_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;digging-into-the-data&#34;&gt;Digging into the data&lt;/h3&gt;

&lt;p&gt;While these smoothed data views are useful to get an idea of the general trend in the data, they hide much of the interesting structure.
For example, we might want to look at the average traffic as a function of the time of day.
We can do this using the GroupBy functionality discussed in &lt;a href=&#34;03.08-Aggregation-and-Grouping.ipynb&#34; target=&#34;_blank&#34;&gt;Aggregation and Grouping&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;by_time = data.groupby(data.index.time).mean()
hourly_ticks = 4 * 60 * 60 * np.arange(6)
by_time.plot(xticks=hourly_ticks, style=[&#39;:&#39;, &#39;--&#39;, &#39;-&#39;]);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_105_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The hourly traffic is a strongly bimodal distribution, with peaks around 8:00 in the morning and 5:00 in the evening.
This is likely evidence of a strong component of commuter traffic crossing the bridge.
This is further evidenced by the differences between the western sidewalk (generally used going toward downtown Seattle), which peaks more strongly in the morning, and the eastern sidewalk (generally used going away from downtown Seattle), which peaks more strongly in the evening.&lt;/p&gt;

&lt;p&gt;We also might be curious about how things change based on the day of the week. Again, we can do this with a simple groupby:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;by_weekday = data.groupby(data.index.dayofweek).mean()
by_weekday.index = [&#39;Mon&#39;, &#39;Tues&#39;, &#39;Wed&#39;, &#39;Thurs&#39;, &#39;Fri&#39;, &#39;Sat&#39;, &#39;Sun&#39;]
by_weekday.plot(style=[&#39;:&#39;, &#39;--&#39;, &#39;-&#39;]);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_107_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This shows a strong distinction between weekday and weekend totals, with around twice as many average riders crossing the bridge on Monday through Friday than on Saturday and Sunday.&lt;/p&gt;

&lt;p&gt;With this in mind, let&amp;rsquo;s do a compound GroupBy and look at the hourly trend on weekdays versus weekends.
We&amp;rsquo;ll start by grouping by both a flag marking the weekend, and the time of day:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;weekend = np.where(data.index.weekday &amp;lt; 5, &#39;Weekday&#39;, &#39;Weekend&#39;)
by_time = data.groupby([weekend, data.index.time]).mean()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we&amp;rsquo;ll use some of the Matplotlib tools described in &lt;a href=&#34;04.08-Multiple-Subplots.ipynb&#34; target=&#34;_blank&#34;&gt;Multiple Subplots&lt;/a&gt; to plot two panels side by side:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import matplotlib.pyplot as plt
fig, ax = plt.subplots(1, 2, figsize=(14, 5))
by_time.ix[&#39;Weekday&#39;].plot(ax=ax[0], title=&#39;Weekdays&#39;,
                           xticks=hourly_ticks, style=[&#39;:&#39;, &#39;--&#39;, &#39;-&#39;])
by_time.ix[&#39;Weekend&#39;].plot(ax=ax[1], title=&#39;Weekends&#39;,
                           xticks=hourly_ticks, style=[&#39;:&#39;, &#39;--&#39;, &#39;-&#39;]);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;output_111_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The result is very interesting: we see a bimodal commute pattern during the work week, and a unimodal recreational pattern during the weekends.
It would be interesting to dig through this data in more detail, and examine the effect of weather, temperature, time of year, and other factors on people&amp;rsquo;s commuting patterns; for further discussion, see my blog post &lt;a href=&#34;https://jakevdp.github.io/blog/2014/06/10/is-seattle-really-seeing-an-uptick-in-cycling/&#34; target=&#34;_blank&#34;&gt;&amp;laquo;Is Seattle Really Seeing an Uptick In Cycling?&amp;raquo;&lt;/a&gt;, which uses a subset of this data.
We will also revisit this dataset in the context of modeling in &lt;a href=&#34;05.06-Linear-Regression.ipynb&#34; target=&#34;_blank&#34;&gt;In Depth: Linear Regression&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>High-Performance Pandas - eval() and query()</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.12-performance-eval-and-query/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.12-performance-eval-and-query/</guid>
      <description>

&lt;p&gt;As we&amp;rsquo;ve already seen in previous sections, the power of the PyData stack is built upon the ability of NumPy and Pandas to push basic operations into C via an intuitive syntax: examples are vectorized/broadcasted operations in NumPy, and grouping-type operations in Pandas.
While these abstractions are efficient and effective for many common use cases, they often rely on the creation of temporary intermediate objects, which can cause undue overhead in computational time and memory use.&lt;/p&gt;

&lt;p&gt;As of version 0.13 (released January 2014), Pandas includes some experimental tools that allow you to directly access C-speed operations without costly allocation of intermediate arrays.
These are the &lt;code&gt;eval()&lt;/code&gt; and &lt;code&gt;query()&lt;/code&gt; functions, which rely on the &lt;a href=&#34;https://github.com/pydata/numexpr&#34; target=&#34;_blank&#34;&gt;Numexpr&lt;/a&gt; package.
In this notebook we will walk through their use and give some rules-of-thumb about when you might think about using them.&lt;/p&gt;

&lt;h2 id=&#34;motivating-query-and-eval-compound-expressions&#34;&gt;Motivating &lt;code&gt;query()&lt;/code&gt; and &lt;code&gt;eval()&lt;/code&gt;: Compound Expressions&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ve seen previously that NumPy and Pandas support fast vectorized operations; for example, when adding the elements of two arrays:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
rng = np.random.RandomState(42)
x = rng.rand(1000000)
y = rng.rand(1000000)
%timeit x + y
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;100 loops, best of 3: 3.39 ms per loop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As discussed in &lt;a href=&#34;02.03-Computation-on-arrays-ufuncs.ipynb&#34; target=&#34;_blank&#34;&gt;Computation on NumPy Arrays: Universal Functions&lt;/a&gt;, this is much faster than doing the addition via a Python loop or comprehension:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%timeit np.fromiter((xi + yi for xi, yi in zip(x, y)), dtype=x.dtype, count=len(x))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1 loop, best of 3: 266 ms per loop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But this abstraction can become less efficient when computing compound expressions.
For example, consider the following expression:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;mask = (x &amp;gt; 0.5) &amp;amp; (y &amp;lt; 0.5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Because NumPy evaluates each subexpression, this is roughly equivalent to the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tmp1 = (x &amp;gt; 0.5)
tmp2 = (y &amp;lt; 0.5)
mask = tmp1 &amp;amp; tmp2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In other words, &lt;em&gt;every intermediate step is explicitly allocated in memory&lt;/em&gt;. If the &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; arrays are very large, this can lead to significant memory and computational overhead.
The Numexpr library gives you the ability to compute this type of compound expression element by element, without the need to allocate full intermediate arrays.
The &lt;a href=&#34;https://github.com/pydata/numexpr&#34; target=&#34;_blank&#34;&gt;Numexpr documentation&lt;/a&gt; has more details, but for the time being it is sufficient to say that the library accepts a &lt;em&gt;string&lt;/em&gt; giving the NumPy-style expression you&amp;rsquo;d like to compute:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numexpr
mask_numexpr = numexpr.evaluate(&#39;(x &amp;gt; 0.5) &amp;amp; (y &amp;lt; 0.5)&#39;)
np.allclose(mask, mask_numexpr)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The benefit here is that Numexpr evaluates the expression in a way that does not use full-sized temporary arrays, and thus can be much more efficient than NumPy, especially for large arrays.
The Pandas &lt;code&gt;eval()&lt;/code&gt; and &lt;code&gt;query()&lt;/code&gt; tools that we will discuss here are conceptually similar, and depend on the Numexpr package.&lt;/p&gt;

&lt;h2 id=&#34;pandas-eval-for-efficient-operations&#34;&gt;&lt;code&gt;pandas.eval()&lt;/code&gt; for Efficient Operations&lt;/h2&gt;

&lt;p&gt;The &lt;code&gt;eval()&lt;/code&gt; function in Pandas uses string expressions to efficiently compute operations using &lt;code&gt;DataFrame&lt;/code&gt;s.
For example, consider the following &lt;code&gt;DataFrame&lt;/code&gt;s:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
nrows, ncols = 100000, 100
rng = np.random.RandomState(42)
df1, df2, df3, df4 = (pd.DataFrame(rng.rand(nrows, ncols))
                      for i in range(4))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To compute the sum of all four &lt;code&gt;DataFrame&lt;/code&gt;s using the typical Pandas approach, we can just write the sum:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%timeit df1 + df2 + df3 + df4
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;10 loops, best of 3: 87.1 ms per loop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The same result can be computed via &lt;code&gt;pd.eval&lt;/code&gt; by constructing the expression as a string:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%timeit pd.eval(&#39;df1 + df2 + df3 + df4&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;10 loops, best of 3: 42.2 ms per loop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;eval()&lt;/code&gt; version of this expression is about 50% faster (and uses much less memory), while giving the same result:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;np.allclose(df1 + df2 + df3 + df4,
            pd.eval(&#39;df1 + df2 + df3 + df4&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;operations-supported-by-pd-eval&#34;&gt;Operations supported by &lt;code&gt;pd.eval()&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;As of Pandas v0.16, &lt;code&gt;pd.eval()&lt;/code&gt; supports a wide range of operations.
To demonstrate these, we&amp;rsquo;ll use the following integer &lt;code&gt;DataFrame&lt;/code&gt;s:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df1, df2, df3, df4, df5 = (pd.DataFrame(rng.randint(0, 1000, (100, 3)))
                           for i in range(5))
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;arithmetic-operators&#34;&gt;Arithmetic operators&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;pd.eval()&lt;/code&gt; supports all arithmetic operators. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;result1 = -df1 * df2 / (df3 + df4) - df5
result2 = pd.eval(&#39;-df1 * df2 / (df3 + df4) - df5&#39;)
np.allclose(result1, result2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;comparison-operators&#34;&gt;Comparison operators&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;pd.eval()&lt;/code&gt; supports all comparison operators, including chained expressions:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;result1 = (df1 &amp;lt; df2) &amp;amp; (df2 &amp;lt;= df3) &amp;amp; (df3 != df4)
result2 = pd.eval(&#39;df1 &amp;lt; df2 &amp;lt;= df3 != df4&#39;)
np.allclose(result1, result2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;bitwise-operators&#34;&gt;Bitwise operators&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;pd.eval()&lt;/code&gt; supports the &lt;code&gt;&amp;amp;&lt;/code&gt; and &lt;code&gt;|&lt;/code&gt; bitwise operators:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;result1 = (df1 &amp;lt; 0.5) &amp;amp; (df2 &amp;lt; 0.5) | (df3 &amp;lt; df4)
result2 = pd.eval(&#39;(df1 &amp;lt; 0.5) &amp;amp; (df2 &amp;lt; 0.5) | (df3 &amp;lt; df4)&#39;)
np.allclose(result1, result2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In addition, it supports the use of the literal &lt;code&gt;and&lt;/code&gt; and &lt;code&gt;or&lt;/code&gt; in Boolean expressions:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;result3 = pd.eval(&#39;(df1 &amp;lt; 0.5) and (df2 &amp;lt; 0.5) or (df3 &amp;lt; df4)&#39;)
np.allclose(result1, result3)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;object-attributes-and-indices&#34;&gt;Object attributes and indices&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;pd.eval()&lt;/code&gt; supports access to object attributes via the &lt;code&gt;obj.attr&lt;/code&gt; syntax, and indexes via the &lt;code&gt;obj[index]&lt;/code&gt; syntax:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;result1 = df2.T[0] + df3.iloc[1]
result2 = pd.eval(&#39;df2.T[0] + df3.iloc[1]&#39;)
np.allclose(result1, result2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;other-operations&#34;&gt;Other operations&lt;/h4&gt;

&lt;p&gt;Other operations such as function calls, conditional statements, loops, and other more involved constructs are currently &lt;em&gt;not&lt;/em&gt; implemented in &lt;code&gt;pd.eval()&lt;/code&gt;.
If you&amp;rsquo;d like to execute these more complicated types of expressions, you can use the Numexpr library itself.&lt;/p&gt;

&lt;h2 id=&#34;dataframe-eval-for-column-wise-operations&#34;&gt;&lt;code&gt;DataFrame.eval()&lt;/code&gt; for Column-Wise Operations&lt;/h2&gt;

&lt;p&gt;Just as Pandas has a top-level &lt;code&gt;pd.eval()&lt;/code&gt; function, &lt;code&gt;DataFrame&lt;/code&gt;s have an &lt;code&gt;eval()&lt;/code&gt; method that works in similar ways.
The benefit of the &lt;code&gt;eval()&lt;/code&gt; method is that columns can be referred to &lt;em&gt;by name&lt;/em&gt;.
We&amp;rsquo;ll use this labeled array as an example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df = pd.DataFrame(rng.rand(1000, 3), columns=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;])
df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0.375506&lt;/td&gt;
      &lt;td&gt;0.406939&lt;/td&gt;
      &lt;td&gt;0.069938&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;0.069087&lt;/td&gt;
      &lt;td&gt;0.235615&lt;/td&gt;
      &lt;td&gt;0.154374&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;0.677945&lt;/td&gt;
      &lt;td&gt;0.433839&lt;/td&gt;
      &lt;td&gt;0.652324&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;0.264038&lt;/td&gt;
      &lt;td&gt;0.808055&lt;/td&gt;
      &lt;td&gt;0.347197&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;0.589161&lt;/td&gt;
      &lt;td&gt;0.252418&lt;/td&gt;
      &lt;td&gt;0.557789&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Using &lt;code&gt;pd.eval()&lt;/code&gt; as above, we can compute expressions with the three columns like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;result1 = (df[&#39;A&#39;] + df[&#39;B&#39;]) / (df[&#39;C&#39;] - 1)
result2 = pd.eval(&amp;quot;(df.A + df.B) / (df.C - 1)&amp;quot;)
np.allclose(result1, result2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;DataFrame.eval()&lt;/code&gt; method allows much more succinct evaluation of expressions with the columns:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;result3 = df.eval(&#39;(A + B) / (C - 1)&#39;)
np.allclose(result1, result3)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice here that we treat &lt;em&gt;column names as variables&lt;/em&gt; within the evaluated expression, and the result is what we would wish.&lt;/p&gt;

&lt;h3 id=&#34;assignment-in-dataframe-eval&#34;&gt;Assignment in DataFrame.eval()&lt;/h3&gt;

&lt;p&gt;In addition to the options just discussed, &lt;code&gt;DataFrame.eval()&lt;/code&gt;  also allows assignment to any column.
Let&amp;rsquo;s use the &lt;code&gt;DataFrame&lt;/code&gt; from before, which has columns &lt;code&gt;&#39;A&#39;&lt;/code&gt;, &lt;code&gt;&#39;B&#39;&lt;/code&gt;, and &lt;code&gt;&#39;C&#39;&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0.375506&lt;/td&gt;
      &lt;td&gt;0.406939&lt;/td&gt;
      &lt;td&gt;0.069938&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;0.069087&lt;/td&gt;
      &lt;td&gt;0.235615&lt;/td&gt;
      &lt;td&gt;0.154374&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;0.677945&lt;/td&gt;
      &lt;td&gt;0.433839&lt;/td&gt;
      &lt;td&gt;0.652324&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;0.264038&lt;/td&gt;
      &lt;td&gt;0.808055&lt;/td&gt;
      &lt;td&gt;0.347197&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;0.589161&lt;/td&gt;
      &lt;td&gt;0.252418&lt;/td&gt;
      &lt;td&gt;0.557789&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;We can use &lt;code&gt;df.eval()&lt;/code&gt; to create a new column &lt;code&gt;&#39;D&#39;&lt;/code&gt; and assign to it a value computed from the other columns:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.eval(&#39;D = (A + B) / C&#39;, inplace=True)
df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;th&gt;D&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0.375506&lt;/td&gt;
      &lt;td&gt;0.406939&lt;/td&gt;
      &lt;td&gt;0.069938&lt;/td&gt;
      &lt;td&gt;11.187620&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;0.069087&lt;/td&gt;
      &lt;td&gt;0.235615&lt;/td&gt;
      &lt;td&gt;0.154374&lt;/td&gt;
      &lt;td&gt;1.973796&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;0.677945&lt;/td&gt;
      &lt;td&gt;0.433839&lt;/td&gt;
      &lt;td&gt;0.652324&lt;/td&gt;
      &lt;td&gt;1.704344&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;0.264038&lt;/td&gt;
      &lt;td&gt;0.808055&lt;/td&gt;
      &lt;td&gt;0.347197&lt;/td&gt;
      &lt;td&gt;3.087857&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;0.589161&lt;/td&gt;
      &lt;td&gt;0.252418&lt;/td&gt;
      &lt;td&gt;0.557789&lt;/td&gt;
      &lt;td&gt;1.508776&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;In the same way, any existing column can be modified:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.eval(&#39;D = (A - B) / C&#39;, inplace=True)
df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;A&lt;/th&gt;
      &lt;th&gt;B&lt;/th&gt;
      &lt;th&gt;C&lt;/th&gt;
      &lt;th&gt;D&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0.375506&lt;/td&gt;
      &lt;td&gt;0.406939&lt;/td&gt;
      &lt;td&gt;0.069938&lt;/td&gt;
      &lt;td&gt;-0.449425&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;0.069087&lt;/td&gt;
      &lt;td&gt;0.235615&lt;/td&gt;
      &lt;td&gt;0.154374&lt;/td&gt;
      &lt;td&gt;-1.078728&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;0.677945&lt;/td&gt;
      &lt;td&gt;0.433839&lt;/td&gt;
      &lt;td&gt;0.652324&lt;/td&gt;
      &lt;td&gt;0.374209&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;0.264038&lt;/td&gt;
      &lt;td&gt;0.808055&lt;/td&gt;
      &lt;td&gt;0.347197&lt;/td&gt;
      &lt;td&gt;-1.566886&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;0.589161&lt;/td&gt;
      &lt;td&gt;0.252418&lt;/td&gt;
      &lt;td&gt;0.557789&lt;/td&gt;
      &lt;td&gt;0.603708&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&#34;local-variables-in-dataframe-eval&#34;&gt;Local variables in DataFrame.eval()&lt;/h3&gt;

&lt;p&gt;The &lt;code&gt;DataFrame.eval()&lt;/code&gt; method supports an additional syntax that lets it work with local Python variables.
Consider the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;column_mean = df.mean(1)
result1 = df[&#39;A&#39;] + column_mean
result2 = df.eval(&#39;A + @column_mean&#39;)
np.allclose(result1, result2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;@&lt;/code&gt; character here marks a &lt;em&gt;variable name&lt;/em&gt; rather than a &lt;em&gt;column name&lt;/em&gt;, and lets you efficiently evaluate expressions involving the two &amp;laquo;namespaces&amp;raquo;: the namespace of columns, and the namespace of Python objects.
Notice that this &lt;code&gt;@&lt;/code&gt; character is only supported by the &lt;code&gt;DataFrame.eval()&lt;/code&gt; &lt;em&gt;method&lt;/em&gt;, not by the &lt;code&gt;pandas.eval()&lt;/code&gt; &lt;em&gt;function&lt;/em&gt;, because the &lt;code&gt;pandas.eval()&lt;/code&gt; function only has access to the one (Python) namespace.&lt;/p&gt;

&lt;h2 id=&#34;dataframe-query-method&#34;&gt;DataFrame.query() Method&lt;/h2&gt;

&lt;p&gt;The &lt;code&gt;DataFrame&lt;/code&gt; has another method based on evaluated strings, called the &lt;code&gt;query()&lt;/code&gt; method.
Consider the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;result1 = df[(df.A &amp;lt; 0.5) &amp;amp; (df.B &amp;lt; 0.5)]
result2 = pd.eval(&#39;df[(df.A &amp;lt; 0.5) &amp;amp; (df.B &amp;lt; 0.5)]&#39;)
np.allclose(result1, result2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As with the example used in our discussion of &lt;code&gt;DataFrame.eval()&lt;/code&gt;, this is an expression involving columns of the &lt;code&gt;DataFrame&lt;/code&gt;.
It cannot be expressed using the &lt;code&gt;DataFrame.eval()&lt;/code&gt; syntax, however!
Instead, for this type of filtering operation, you can use the &lt;code&gt;query()&lt;/code&gt; method:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;result2 = df.query(&#39;A &amp;lt; 0.5 and B &amp;lt; 0.5&#39;)
np.allclose(result1, result2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In addition to being a more efficient computation, compared to the masking expression this is much easier to read and understand.
Note that the &lt;code&gt;query()&lt;/code&gt; method also accepts the &lt;code&gt;@&lt;/code&gt; flag to mark local variables:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Cmean = df[&#39;C&#39;].mean()
result1 = df[(df.A &amp;lt; Cmean) &amp;amp; (df.B &amp;lt; Cmean)]
result2 = df.query(&#39;A &amp;lt; @Cmean and B &amp;lt; @Cmean&#39;)
np.allclose(result1, result2)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;True
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;performance-when-to-use-these-functions&#34;&gt;Performance: When to Use These Functions&lt;/h2&gt;

&lt;p&gt;When considering whether to use these functions, there are two considerations: &lt;em&gt;computation time&lt;/em&gt; and &lt;em&gt;memory use&lt;/em&gt;.
Memory use is the most predictable aspect. As already mentioned, every compound expression involving NumPy arrays or Pandas &lt;code&gt;DataFrame&lt;/code&gt;s will result in implicit creation of temporary arrays:
For example, this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x = df[(df.A &amp;lt; 0.5) &amp;amp; (df.B &amp;lt; 0.5)]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Is roughly equivalent to this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;tmp1 = df.A &amp;lt; 0.5
tmp2 = df.B &amp;lt; 0.5
tmp3 = tmp1 &amp;amp; tmp2
x = df[tmp3]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the size of the temporary &lt;code&gt;DataFrame&lt;/code&gt;s is significant compared to your available system memory (typically several gigabytes) then it&amp;rsquo;s a good idea to use an &lt;code&gt;eval()&lt;/code&gt; or &lt;code&gt;query()&lt;/code&gt; expression.
You can check the approximate size of your array in bytes using this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.values.nbytes
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;32000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;On the performance side, &lt;code&gt;eval()&lt;/code&gt; can be faster even when you are not maxing-out your system memory.
The issue is how your temporary &lt;code&gt;DataFrame&lt;/code&gt;s compare to the size of the L1 or L2 CPU cache on your system (typically a few megabytes in 2016); if they are much bigger, then &lt;code&gt;eval()&lt;/code&gt; can avoid some potentially slow movement of values between the different memory caches.
In practice, I find that the difference in computation time between the traditional methods and the &lt;code&gt;eval&lt;/code&gt;/&lt;code&gt;query&lt;/code&gt; method is usually not significant–if anything, the traditional method is faster for smaller arrays!
The benefit of &lt;code&gt;eval&lt;/code&gt;/&lt;code&gt;query&lt;/code&gt; is mainly in the saved memory, and the sometimes cleaner syntax they offer.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ve covered most of the details of &lt;code&gt;eval()&lt;/code&gt; and &lt;code&gt;query()&lt;/code&gt; here; for more information on these, you can refer to the Pandas documentation.
In particular, different parsers and engines can be specified for running these queries; for details on this, see the discussion within the &lt;a href=&#34;http://pandas.pydata.org/pandas-docs/dev/enhancingperf.html&#34; target=&#34;_blank&#34;&gt;&amp;laquo;Enhancing Performance&amp;raquo; section&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Further Resources</title>
      <link>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.13-further-resources/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dragon-library.github.io/coding/tutorials/data-science-handbook/3.pandas/03.13-further-resources/</guid>
      <description>&lt;p&gt;In this chapter, we&amp;rsquo;ve covered many of the basics of using Pandas effectively for data analysis.
Still, much has been omitted from our discussion.
To learn more about Pandas, I recommend the following resources:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://pandas.pydata.org/&#34; target=&#34;_blank&#34;&gt;Pandas online documentation&lt;/a&gt;: This is the go-to source for complete documentation of the package. While the examples in the documentation tend to be small generated datasets, the description of the options is complete and generally very useful for understanding the use of various functions.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://shop.oreilly.com/product/0636920023784.do&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Python for Data Analysis&lt;/em&gt;&lt;/a&gt; Written by Wes McKinney (the original creator of Pandas), this book contains much more detail on the Pandas package than we had room for in this chapter. In particular, he takes a deep dive into tools for time series, which were his bread and butter as a financial consultant. The book also has many entertaining examples of applying Pandas to gain insight from real-world datasets. Keep in mind, though, that the book is now several years old, and the Pandas package has quite a few new features that this book does not cover (but be on the lookout for a new edition in 2017).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://stackoverflow.com/questions/tagged/pandas&#34; target=&#34;_blank&#34;&gt;Stack Overflow&lt;/a&gt;: Pandas has so many users that any question you have has likely been asked and answered on Stack Overflow. Using Pandas is a case where some Google-Fu is your best friend. Simply go to your favorite search engine and type in the question, problem, or error you&amp;rsquo;re coming across–more than likely you&amp;rsquo;ll find your answer on a Stack Overflow page.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://pyvideo.org/search?q=pandas&#34; target=&#34;_blank&#34;&gt;Pandas on PyVideo&lt;/a&gt;: From PyCon to SciPy to PyData, many conferences have featured tutorials from Pandas developers and power users. The PyCon tutorials in particular tend to be given by very well-vetted presenters.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Using these resources, combined with the walk-through given in this chapter, my hope is that you&amp;rsquo;ll be poised to use Pandas to tackle any data analysis problem you come across!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
